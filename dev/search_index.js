var documenterSearchIndex = {"docs":
[{"location":"examples/modelingtoolkit/#ModelingToolkit-Example","page":"ModelingToolkit Example","title":"ModelingToolkit Example","text":"This example is also provided here as a Jupyter Notebook.","category":"section"},{"location":"examples/modelingtoolkit/#Using-ModelingToolkit-NonlinearSystem-models-with-EAGO","page":"ModelingToolkit Example","title":"Using ModelingToolkit NonlinearSystem models with EAGO","text":"This is a tutorial for exporting ModelingToolkit [1] NonlinearSystem models as standard Julia functions, which can then be used as EAGO-compatible equality constraints in JuMP models.","category":"section"},{"location":"examples/modelingtoolkit/#Defining-Nonlinear-System","page":"ModelingToolkit Example","title":"Defining Nonlinear System","text":"The system of interest is derived from an example originally presented by [2] that involves a continuous stirred-tank reactor (CSTR) and separator train (with recycle) for the chlorination of benzene with the following reactions taking place:\n\nbeginarrayrcl\ntextC_6 textH_6 + textCl_2 rightarrow textC_6 textH_5 textCl + textHCl\ntextC_6 textH_5 textCl + textCl_2 rightarrow textC_6 textH_4 textCl_2 + textHCl\nendarray\n\nwhere the rate constants k_1 and k_2 h^-1 are known and the reactor volume V m^3 and feed flow rate F_1 kmolh are considered free design variables. The CSTR is followed by a separation train for product purification and reactant recycle.\n\n(Image: mtk_pfd)\n\nFor simplicity, the reactions will be first-order (no dependence on textCl_2) with respect to benzene (A) and chlorobenzene (B). The molar volumes of each species are: V_A = 8937 times 10^-2  m^3kmol, V_B = 1018 times 10^-1   m^3kmol, and V_C = 113 times 10^-1  m^3kmol with dichlorobenzene as C. The feed is considered to be pure A (ignoring textCl_2). The rate constants are k_1 = 040  h^-1 and k_2 = 0055  h^-1. The steady-state model equations are:\n\nbeginarrayrclr\n    F_1 + F_7 = F_2  (textmixer)\t\n\ty_3A F_3 = F_2 - r_1 V  (textreactor)\n\ty_3B F_3 =  (r_1 - r_2) V  (textreactor)\n\ty_3C F_3 =  r_2 V  (textreactor)\n\tF_3 = F_4 + F_7  (textseparator 1)\n\ty_3B F_3 = y_4B F_4  (textseparator 1)\n\ty_3C F_3 = y_4C F_4  (textseparator 1)\n\tF_4 = F_5 + F_6  (textseparator 2)\n\ty_4B F_4 = F_5  (textseparator 2)\n\ty_3A + y_3B + y_3C = 1  (textrelationship)\n\ty_4B + y_4C = 1  (textrelationship)\nendarray\n\nwhere y_ij is the mole fraction of j in ABC in Stream i in 34 (with y_4A = 0) and r_1 and r_2 are the reaction rates kmol(m^3 h) defined as:\n\nbeginarrayrcl\nr_1 = k_1 y_3A(y_3A V_A + y_3B V_B + y_3C V_C)\nr_2 = k_2 y_3B(y_3A V_A + y_3B V_B + y_3C V_C)\nendarray\n\nwith the variable vector mathbfx in mathbbR^12:\n\nmathbfx = (V F_1 F_2 y_3A y_3B y_3C F_3 y_4B y_4C F_4 F_6 F_7)","category":"section"},{"location":"examples/modelingtoolkit/#Performance-Specifications","page":"ModelingToolkit Example","title":"Performance Specifications","text":"We must produce at least 25 kmolh of B (F_5 ge 25) and cannot have a reactor larger than 10 m^3 due to space limitations. From a laboratory study, it was found that the residence time tau h for the reactor must be at least 475 seconds. Residence time can be defined as:\n\ntau = fracVF_3 (y_3A V_A + y_3B V_B + y_3C V_C)","category":"section"},{"location":"examples/modelingtoolkit/#Design-Problem","page":"ModelingToolkit Example","title":"Design Problem","text":"We will consider an economic objective for our optimization problem as the total annualized costs of the unit operations. The total annualized cost of the CSTR is given by\n\nf_CSTR = (25764 + 8178V)25\n\nand the total annualized cost of the separator train is given by:\n\nbeginarrayrcl\ns_1^cap = 132718 + F_3 (369 y_3A - 11139 y_3B)\ns_2^cap = 25000 + F_4 (69845 y_4B - 386953 y_4C^2)\ns_1^op = F_3 (3 + 3611 y_3A + 771 y_3B) (2632 times 10^-3)\ns_2^op = F_4 (2621 + 2945 y_4B) (2632 times 10^-3)\nf_sep = (s_1^cap + s_2^cap)25 + 052 (s_1^op + s_2^op)\nendarray\n\nThe total annualized cost of the complete system is then given by\n\nf_total = f_CSTR + f_sep","category":"section"},{"location":"examples/modelingtoolkit/#Modeling-and-Simplifying-Using-ModelingToolkit","page":"ModelingToolkit Example","title":"Modeling and Simplifying Using ModelingToolkit","text":"using EAGO, GLPK, JuMP, ModelingToolkit\n\nFirst, we define the state variables with @variables and model parameters with @parameters. Note that the design variables V and F_1 are considered parameters so we have a square system (10 equations, 10 unknowns).\n\n# State variables\nModelingToolkit.@variables F₂ y_3A y_3B y_3C F₃ y_4B y_4C F₄ F₆ F₇\n\n# Model parameters and design variables\nModelingToolkit.@parameters k₁ k₂ V_A V_B V_C V F₁\n\nNext, we can write symbolic expressions for r_1, r_2, and F_5 to help simplify our model equations.\n\n# Symbolic expressions for reaction rates and F₅\nr₁ = (k₁*y_3A)/(y_3A*V_A + y_3B*V_B + y_3C*V_C)\nr₂ = (k₂*y_3B)/(y_3A*V_A + y_3B*V_B + y_3C*V_C)\nF₅ = (y_4B*F₄)\n\nThe variables, parameters, and steady-state model equations are then used to construct the NonlinearSystem.\n\n# Steady-state model equations\neqs = [\n    F₁ + F₇ ~ F₂\n    (y_3A*F₃) ~ F₂ - r₁*V\n    (y_3B*F₃) ~ (r₁ - r₂)*V\n    (y_3C*F₃) ~ r₂*V\n    F₃ ~ F₄ + F₇\n    (y_3B*F₃) ~ (y_4B*F₄)\n    (y_3C*F₃) ~ (y_4C*F₄)\n    F₄ ~ F₅ + F₆\n    y_3A + y_3B + y_3C ~ 1\n    y_4B + y_4C ~ 1\n]\n\n# Variables and parameters\nvars = [F₂, y_3A, y_3B, y_3C, F₃, y_4B, y_4C, F₄, F₆, F₇]\npars = [k₁, k₂, V_A, V_B, V_C, V, F₁]\n\n# Building and simplifying model\n@mtkbuild ns = NonlinearSystem(eqs, vars, pars)\n\n@mtkbuild simplifies the model down to 4 equations and 4 unknowns, significantly reducing the dimensionality of this system. The variables that were eliminated during the simplification process are called \"observed variables,\" and their expressions can be obtained using observed(::NonlinearSystem).","category":"section"},{"location":"examples/modelingtoolkit/#Converting-to-a-Standard-Function","page":"ModelingToolkit Example","title":"Converting to a Standard Function","text":"Now that we've simplified our model, we need to covert the symbolic model equations into standard Julia functions in order to use them with EAGO. This can be accomplished through the use of Symbolics.build_function, which generates a numerically-usable function from a symbolic expression. Since Symbolics.jl is already built into ModelingToolkit.jl, no additional packages need to be installed.\n\nTo simplify the use of build_function for our purposes, we first create the function ns_to_function() that takes in a NonlinearSystem, a vector of parameters, and a vector of function inputs, and returns a vector of standard Julia functions corresponding to the simplified model equations in the nonlinear system.\n\n# Converts symbolic model equations into standard Julia functions\nfunction ns_to_function(ns::NonlinearSystem, params::Vector{Pair{Num,Float64}}, vars::Vector{Num})\n    function_holder = []\n    # For each model equation, substitute parameter values and create function\n    for eqn in full_equations(ns)\n        expr = substitute(eqn.rhs, Dict{Num,Any}(params))\n        new_func = build_function(expr, vars..., expression = Val{false})\n        push!(function_holder, new_func)\n    end\n    return function_holder\nend\n\nTo use this function, we first assign values to our known parameters, define our function inputs, and then call ns_to_function() to obtain our desired functions.\n\n# Assign parameter values\nparams = [\n    k₁ => 0.40,\n    k₂ => 0.055,\n    V_A => 8.937e-2,\n    V_B => 1.018e-1,\n    V_C => 1.130e-1\n]\n\n# Function inputs (design and state variables)\nx = [V, F₁, y_3B, y_3C, F₃, y_4C]\n\n# Create functions for each model equation as a function of design and state variables\nf = ns_to_function(ns, params, x)\n\nWe now have standard Julia functions for each model equation which can be used as equality constraints in our JuMP [3] model. \n\nWe'll also create functions for our inequality constraints (F_5, tau) and objective function (f_total). Since these functions are not expressed in terms of the two design variables (V and F_1) and the four state variables (y_3B, y_3C, F_3, y_4C), we'll create a function expr_to_function() to substitute the NonlinearSystem observed variables into our input expression before calling build_function.\n\nAll we have to do now is write the symbolic expressions for F_5, tau, and f_total, then call expr_to_function() for each expression.\n\n# Converts symbolic expression into standard Julia function, substituting parameter and observed variable expressions\nfunction expr_to_function(expr::Num, ns::NonlinearSystem, params::Vector{Pair{Num,Float64}}, vars::Vector{Num})\n    # Creates a dictionary of parameter and observed variable substitutions\n    substitute_dict = Dict{Num,Any}(params)\n    for eqn in observed(ns)\n        substitute_dict[eqn.lhs] = eqn.rhs\n    end\n    # Makes substitutions until no substitutions can be made\n    while ~isempty(intersect(string.(get_variables(expr)), string.(keys(substitute_dict))))\n        expr = substitute(expr, substitute_dict)\n    end\n    return build_function(expr, vars..., expression = Val{false})\nend\n\n# Symbolic expression for F₅\nexprF5 = y_4B*F₄\n\n# Symbolic expression for τ\nexprTau = V/(F₃*(y_3A*V_A + y_3B*V_B + y_3C*V_C))\n\n# Symbolic expressions for CSTR and separator costs\nf_CSTR = (25764 + 8178*V)/2.5\ns1cap = 132718 + F₃*(369*y_3A - 1113.9*y_3B)\ns2cap = 25000 + F₄*(6984.5*y_4B - 3869.53*y_4C^2)\ns1op = F₃*(3+36.11*y_3A + 7.71*y_3B)*26.32e-3\ns2op = F₄*(26.21 + 29.45*y_4B)*26.32e-3;\nf_Sep = (s1cap+s2cap)/2.5 + 0.52*(s1op+s2op)\n\n# Symbolic expression for total cost (objective function)\nexprTotCost = f_CSTR + f_Sep\n\n# Create functions for each expression as a function of design and state variables\nF5 = expr_to_function(exprF5, ns, params, x)\nTau = expr_to_function(exprTau, ns, params, x)\nTotCost = expr_to_function(exprTotCost, ns, params, x)","category":"section"},{"location":"examples/modelingtoolkit/#Solving-the-Optimization-Problem-with-EAGO","page":"ModelingToolkit Example","title":"Solving the Optimization Problem with EAGO","text":"To formulate and solve the design problem, we'll begin by creating a JuMP model. We'll also use GLPK as a subsolver because it greatly accelerates convergence for this particular system.\n\n# Using GLPK subsolver for EAGO\nfactory = () -> EAGO.Optimizer(SubSolvers(; r = GLPK.Optimizer()))\nm = Model(optimizer_with_attributes(factory,\n                                    \"branch_cvx_factor\" => 0.75,\n                                    \"output_iterations\" => 200))\n\nNext, we need to define bounds for our design variables (V, F_1) and state variables (y_3B, y_3C, F_3, y_4C). This gives us a total of 6 decision variables in our optimization problem. \n\n# Define variable bounds\nxL = [5.0, 25.0, 0.1, 0.001, 75.0, 0.01]\nxU = [10.0, 50.0, 0.5, 0.1, 125.0, 0.1]\n# x = (V, F₁, y_3B, y_3C, F₃, y_4C)\n@variable(m, xL[i] <= x[i=1:6] <= xU[i])\n\nnote: Note\nIt's important to note that defining \"good\" bounds is especially important for deterministic global solvers like EAGO because of the set arithmetic and interval and convex analyses required to guarantee global optimality. Based on simple linear constraints and understanding what our variables physically represent, we can easily eliminate erroneous regions from the search space and drastically reduce computational cost. For example, we know the reactor volume must be less than or equal to 10 m^3, but we also know it should be at least a few cubic meters large, so we bound V between 5 and 10. Similarly, we know we must produce at least 25 kmolh of B, but this is only possible if there are at least 25 kmolh of A entering the system since we are operating under steady-state conditions with one influent and two effluent streams.\n\nOnce proper bounds are defined, we continue by registering our user-defined functions and defining our nonlinear constraints (model equations and performance specifications) and objective (minimizing total annualized costs).\n\n# Register user-defined functions\nJuMP.register(m, :f1, 6, f[1], autodiff=true)\nJuMP.register(m, :f2, 6, f[2], autodiff=true)\nJuMP.register(m, :f3, 6, f[3], autodiff=true)\nJuMP.register(m, :f4, 6, f[4], autodiff=true)\nJuMP.register(m, :F5, 6, F5, autodiff=true)\nJuMP.register(m, :Tau, 6, Tau, autodiff=true)\nJuMP.register(m, :TotCost, 6, TotCost, autodiff=true)\n\n# Define model equation constraints\n@NLconstraint(m, e1, f1(x...) == 0)\n@NLconstraint(m, e2, f2(x...) == 0)\n@NLconstraint(m, e3, f3(x...) == 0)\n@NLconstraint(m, e4, f4(x...) == 0)\n\n# Define performance specification constraints\n@NLconstraint(m, c1, F5(x...) ≥ 25.0)\n@NLconstraint(m, c2, Tau(x...) ≥ 475.0/3600.0)\n\n# Define objective to minimize total annualized costs\n@NLobjective(m, Min, TotCost(x...))\n\nWe're now ready to solve the optimal design problem. We'll @time the solver so we can compare convergence times for reduced-space vs full-space formulations later.\n\n# Solve optimization problem\n@time JuMP.optimize!(m)\n\nWe've identified a global optimal solution mathbfx^* = (84594 263167 02631 001386 950215 005003). Keep in mind that we can readily calculate values for the observed variables since we have their explicit expressions written in terms of these decision variables.","category":"section"},{"location":"examples/modelingtoolkit/#Full-Space-Formulation","page":"ModelingToolkit Example","title":"Full-Space Formulation","text":"To compare and showcase the full-space optimization formulation for this system, we'll quickly formulate and solve the design problem with all 10 model equations using the full variable vector\n\nmathbfx = (V F_1 F_2 y_3A y_3B y_3C F_3 y_4B y_4CF_4 F_6 F_7)\n\nWe can generate functions for each of the original model equations by first initializing the model using @named instead of @mtkbuild to exclude the structural simplification step.\n\n# Initialize model without structural simplification\n@named fns = NonlinearSystem(eqs, vars, pars)\n\nThen, we redefine our function inputs and generate our functions in the same way as before.\n\n# Full variable vector\nx = [V, F₁, F₂, y_3A, y_3B, y_3C, F₃, y_4B, y_4C, F₄, F₆, F₇]\n\n# Create functions for each model equation as a function of the full variable vector\nff = ns_to_function(fns, params, x)\n\n# Create functions for each expression as a function of the full variable vector\nfF5 = expr_to_function(exprF5, fns, params, x)\nfTau = expr_to_function(exprTau, fns, params, x)\nfTotCost = expr_to_function(exprTotCost, fns, params, x)\n\nWe'll define a new JuMP model with the same settings, define bounds for each variable, register functions, define constraints and objective, then solve the optimization problem.\n\nn = Model(optimizer_with_attributes(factory,\n                                    \"branch_cvx_factor\" => 0.75,\n                                    \"output_iterations\" => 200))\n\n# Define variable bounds\n# New variables:   v    v                      v           v    v     v\nxL = [ 5.0, 25.0, 75.0, 0.5, 0.1, 0.001, 75.0, 0.9, 0.01, 25.0, 0.0, 50.0]\nxU = [10.0, 50.0, 125.0, 1.0, 0.5, 0.1, 125.0, 1.0, 0.1, 50.0, 10.0, 100.0]\n# x = (V, F₁, F₂, y_3A, y_3B, y_3C, F₃, y_4B, y_4C, F₄, F₆, F₇)\n@variable(n, xL[i] <= x[i=1:12] <= xU[i])\n\n# Register user-defined functions\nJuMP.register(n, :f1, 12, ff[1], autodiff=true)\nJuMP.register(n, :f2, 12, ff[2], autodiff=true)\nJuMP.register(n, :f3, 12, ff[3], autodiff=true)\nJuMP.register(n, :f4, 12, ff[4], autodiff=true)\nJuMP.register(n, :f5, 12, ff[5], autodiff=true)\nJuMP.register(n, :f6, 12, ff[6], autodiff=true)\nJuMP.register(n, :f7, 12, ff[7], autodiff=true)\nJuMP.register(n, :f8, 12, ff[8], autodiff=true)\nJuMP.register(n, :f9, 12, ff[9], autodiff=true)\nJuMP.register(n, :f10, 12, ff[10], autodiff=true)\nJuMP.register(n, :F5, 12, fF5, autodiff=true)\nJuMP.register(n, :Tau, 12, fTau, autodiff=true)\nJuMP.register(n, :TotCost, 12, fTotCost, autodiff=true)\n\n# Define model equation constraints\n@NLconstraint(n, e1, f1(x...) == 0)\n@NLconstraint(n, e2, f2(x...) == 0)\n@NLconstraint(n, e3, f3(x...) == 0)\n@NLconstraint(n, e4, f4(x...) == 0)\n@NLconstraint(n, e5, f5(x...) == 0)\n@NLconstraint(n, e6, f6(x...) == 0)\n@NLconstraint(n, e7, f7(x...) == 0)\n@NLconstraint(n, e8, f8(x...) == 0)\n@NLconstraint(n, e9, f9(x...) == 0)\n@NLconstraint(n, e10, f10(x...) == 0)\n\n# Define performance specification constraints\n@NLconstraint(n, c1, F5(x...) ≥ 25.0)\n@NLconstraint(n, c2, Tau(x...) ≥ 475.0/3600.0)\n\n# Define objective to minimize total annualized costs\n@NLobjective(n, Min, TotCost(x...))\n\n# Solve optimization problem\n@time JuMP.optimize!(n)\n\nIt takes three times as many iterations and significantly more memory allocations for EAGO to converge with the full-space formulation, demonstrating the advantages of reduced-space formulations. Because global solvers suffer from the curse of dimensionality, reducing the number of decision variables through model simplifications can improve performance and therefore broaden the scope of problems for which global solvers can be applied.\n\nThis tutorial introduces user-defined functions that provide an easy way to use ModelingToolkit's intuitive modeling interface and model simplification features to create reduced-space formulations in a way that is compatible with EAGO.","category":"section"},{"location":"examples/modelingtoolkit/#References","page":"ModelingToolkit Example","title":"References","text":"Yingbo Ma and Shashi Gowda and Ranjan Anantharaman and Chris Laughman and Viral Shah and Chris Rackauckas, ModelingToolkit: A Composable Graph Transformation System For Equation-Based Modeling, arXiv, (2021).\nA. C. Kokossis, C. A. Floudas. Synthesis of isothermal reactor—separator—recycle systems, Chemical Engineering Science, 46:5-6 (1991), pp. 1361-1383.\nIain Dunning and Joey Huchette and Miles Lubin. JuMP: A Modeling Language for Mathematical Optimization, SIAM Review, 59 (2017), pp. 295-320.","category":"section"},{"location":"mccormick/usage/#Basic-Usage","page":"Basic Usage","title":"Basic Usage","text":"","category":"section"},{"location":"mccormick/usage/#Bounding-a-Univariate-Function","page":"Basic Usage","title":"Bounding a Univariate Function","text":"In order to bound a function using a McCormick relaxation, you first construct a McCormick object (x::MC) that bounds the input variables, and then you pass these variables to the desired function.\n\nIn the example below, convex/concave relaxations of the function f(x) = x (x - 5) sin(x) are calculated at x = 2 on the interval 1 4.\n\nusing McCormick\n\n# Create MC object for x = 2.0 on [1.0, 4.0] for relaxing\n# a function f(x) on the interval Intv\n\nf(x) = x*(x - 5.0)*sin(x)\n\nx = 2.0                          # Value of independent variable x\nIntv = Interval(1.0, 4.0)        # Define interval to relax over\n                                 # Note that McCormick.jl reexports IntervalArithmetic.jl\n                                 # and StaticArrays. So no using statement for these is\n                                 # necessary.\n# Create McCormick object\nxMC = MC{1,NS}(x, Intv, 1)\n\nfMC = f(xMC)             # Relax the function\n\ncv = fMC.cv              # Convex relaxation\ncc = fMC.cc              # Concave relaxation\ncvgrad = fMC.cv_grad     # Subgradient/gradient of convex relaxation\nccgrad = fMC.cc_grad     # Subgradient/gradient of concave relaxation\nIv = fMC.Intv            # Retrieve interval bounds of f(x) on Intv\n\nBy plotting the results we can easily visualize the convex and concave relaxations, interval bounds, and affine bounds constructed using the subgradient at the middle of X.\n\n(Image: Figure_1)\n\nIf we instead use the constructor xMC = MC{1,Diff}(x, Intv, 1) in the above code and re-plot, we arrive at the following graph. Note that these relaxations are differentiable, but not as tight as the nonsmooth relaxations.\n\n(Image: Figure_2)","category":"section"},{"location":"mccormick/usage/#Bounding-a-Multivariate-Function","page":"Basic Usage","title":"Bounding a Multivariate Function","text":"This can readily be extended to multivariate functions, for example:\n\nbeginaligned\nf(xy) = big(4 - 21 x^2 + fracx^46 big) x^2 + x y + (-4 + 4 y^2) y^2\nendaligned\n\nusing McCormick\n\n# Define function\nf(x, y) = (4.0 - 2.1*x^2 + (x^4)/6.0)*x^2 + x*y + (-4.0 + 4.0*y^2)*y^2\n\n# Define intervals for independent variables\nn = 30\nX = Interval{Float64}(-2,0)\nY = Interval{Float64}(-0.5, 0.5)\nxrange = range(X.lo, stop=X.hi, length=n)\nyrange = range(Y.lo, stop=Y.hi, length=n)\n\n# Calculate differentiable McCormick relaxation\nfor (i,x) in enumerate(xrange)\n    for (j,y) in enumerate(yrange)\n        z = f(x, y)                 # Calculate function values\n        xMC = MC{1,Diff}(x, X, 1)   # Differentiable relaxation for x\n        yMC = MC{1,Diff}(y, Y, 2)   # Differentiable relaxation for y\n        fMC = f(xMC, yMC)           # Relax the function\n        cv = fMC.cv                 # Convex relaxation\n        cc = fMC.cc                 # Concave relaxation\n    end\nend\n\n(Image: Figure_3)","category":"section"},{"location":"mccormick/operators/#Currently-Supported-Operators","page":"Currently Supported Operators","title":"Currently Supported Operators","text":"The operators currently supported are listed below. The operators with a check box have been subject to a large degree of scrutiny and have been implemented for both forward and reverse McCormick relaxations (Wechsung2015). Each McCormick object is associated with a parameter T <: RelaxTag which is either NS for nonsmooth relaxations (Mitsos2009, Scott2011), MV for multivariate relaxations (Tsoukalas2014, Najman2017), or Diff for differentiable relaxations (Khan2016, Khan2018, Khan2019). Conversion between NS, MV, and Diff relax tags is not currently supported. Convex and concave envelopes are used to compute relaxations of univariate functions.","category":"section"},{"location":"mccormick/operators/#Univariate-McCormick-Operators","page":"Currently Supported Operators","title":"Univariate McCormick Operators","text":"Arbitrarily differentiable relaxations can be constructed for the following operators:\n\nInverse (inv)\nLogarithms (log, log2, log10)\nExponential Functions (exp, exp2, exp10)\nSquare Root (sqrt)\nAbsolute Value (abs)\n\nBoth nonsmooth and Whitney-1 (once differentiable) relaxations are supported for the following operators:\n\nStep Functions (step, sign)\nTrigonometric Functions (sin, cos, tan)\nInverse Trigonometric Functions (asin, acos, atan)\nHyperbolic Functions (sinh, cosh, tanh)\nInverse Hyperbolic Functions (asinh, acosh, atanh)\nCommon Activation Functions (relu, leaky_relu, param_relu, sigmoid, bisigmoid,                                      softsign, softplus, maxtanh, pentanh,                                      gelu, elu, selu, swish)\nSpecial Functions (erf)","category":"section"},{"location":"mccormick/operators/#Bivariate-McCormick-Operators","page":"Currently Supported Operators","title":"Bivariate McCormick Operators","text":"The following bivariate operators are supported for two MC objects. Both nonsmooth and Whitney-1 (once differentiable) relaxations are supported.\n\nMultiplication (*)\nDivision (/)\n\nArbitrarily differentiable relaxations can be constructed for the following operators:\n\nAddition (+)\nSubtraction (-)\nMinimization (min)\nMaximization (max)","category":"section"},{"location":"mccormick/operators/#Common-Subexpressions","page":"Currently Supported Operators","title":"Common Subexpressions","text":"The following functions can be used in place of common subexpressions encountered in optimization and will result in improved performance (in each case, the standard McCormick composition rules are often more expansive).","category":"section"},{"location":"mccormick/operators/#Bound-Setting-Functions","page":"Currently Supported Operators","title":"Bound Setting Functions","text":"The following functions are used to specify that known bounds on a subexpression exist and that the relaxation/interval bounds propagated should make use of this information. The utility functions can be helpful in avoiding domain violations that arise due to the overly expansive nature of composite relaxations. Improper use of these functions may lead to cases in which the resulting relaxations are empty, so the user is encouraged to use discretion.","category":"section"},{"location":"mccormick/operators/#Specialized-Activation-Functions","page":"Currently Supported Operators","title":"Specialized Activation Functions","text":"","category":"section"},{"location":"mccormick/operators/#References","page":"Currently Supported Operators","title":"References","text":"Khan KA, Watson HAJ, Barton PI (2017). Differentiable McCormick relaxations. Journal of Global Optimization, 67(4): 687-729.\nKhan KA, Wilhelm ME, Stuber MD, Cao H, Watson HAJ, Barton PI (2018). Corrections to: Differentiable McCormick relaxations. Journal of Global Optimization, 70(3): 705-706.\nKhan KA (2019). Whitney differentiability of optimal-value functions for bound-constrained convex programming problems. Optimization, 68(2-3): 691-711\nMitsos A, Chachuat B, and Barton PI. (2009). McCormick-based relaxations of algorithms. SIAM Journal on Optimization, 20(2): 573–601.\nNajman J, Bongratz D, Tsoukalas A, and Mitsos A (2017). Erratum to: Multivariate McCormick relaxations. Journal of Global Optimization, 68: 219-225.\nScott JK,  Stuber MD, and Barton PI. (2011). Generalized McCormick relaxations. Journal of Global Optimization, 51(4): 569–606.\nStuber MD, Scott JK, Barton PI (2015). Convex and concave relaxations of implicit functions. Optim. Methods Softw., 30(3): 424–460\nTsoukalas A and Mitsos A (2014). Multivariate McCormick Relaxations. Journal of Global Optimization, 59:633–662.\nWechsung A, Scott JK, Watson HAJ, and Barton PI. (2015). Reverse propagation of McCormick relaxations. Journal of Global Optimization, 63(1): 1-36.","category":"section"},{"location":"mccormick/operators/#McCormick.xexpax","page":"Currently Supported Operators","title":"McCormick.xexpax","text":"expax\n\nThe expax function is defined as expax(x, a) = x*exp(a*x).\n\nForm defined in Najman, Jaromił, Dominik Bongartz, and Alexander Mitsos. \"Relaxations of thermodynamic property and costing models in process engineering.\" Computers & Chemical Engineering 130 (2019): 106571.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.arh","page":"Currently Supported Operators","title":"McCormick.arh","text":"arh\n\nThe arrhenius function arh is defined as arh(x) = exp(-k/x).\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.xlogx","page":"Currently Supported Operators","title":"McCormick.xlogx","text":"xlogx\n\nThe function xlogx is defined as xlogx(x) = x*log(x).\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.mm","page":"Currently Supported Operators","title":"McCormick.mm","text":"mm(X,v,K) = v*X / (X + K)\n\nA Michaelis-Menten rate function.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.positive","page":"Currently Supported Operators","title":"McCormick.positive","text":"positive(x::MC)\n\nSets the lower interval bound and the convex relaxation of x to a value of at least McCormick.MC_DOMAIN_TOL. (Sub)gradients are adjusted appropriately.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.negative","page":"Currently Supported Operators","title":"McCormick.negative","text":"negative(x::MC)\n\nSets the upper interval bound and the concave relaxation of x to a value of at most -McCormick.MC_DOMAIN_TOL. (Sub)gradients are adjusted appropriately.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.lower_bnd","page":"Currently Supported Operators","title":"McCormick.lower_bnd","text":"lower_bnd(x::MC, lb::Float64)\n\nSets the lower interval bound and the convex relaxation of x to a value of at least lb. (Sub)gradients are adjusted appropriately.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.upper_bnd","page":"Currently Supported Operators","title":"McCormick.upper_bnd","text":"upper_bnd(x::MC, ub)\n\nSets the upper interval bound and the concave relaxation of x to a value of at most ub. (Sub)gradients are adjusted appropriately.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.bnd","page":"Currently Supported Operators","title":"McCormick.bnd","text":"bnd(x::MC, lb, ub)\n\nSets the lower interval bound and the convex relaxation of x to a value of at least lb. Sets the upper interval bound and the concave relaxation of x to a value of at most ub. (Sub)gradients are adjusted appropriately.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.pentanh","page":"Currently Supported Operators","title":"McCormick.pentanh","text":"pentanh\n\nThe pentanh activation function pentanh(x) = x > 0.0 ? tanh(x) : tanh(0.25*x).\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.leaky_relu","page":"Currently Supported Operators","title":"McCormick.leaky_relu","text":"leaky_relu\n\nThe leaky Rectified Linear Unit activation function leaky_relu(x) = max(x, 0.01x).\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.param_relu","page":"Currently Supported Operators","title":"McCormick.param_relu","text":"param_relu\n\nThe parametric Rectified Linear Unit activation function param_relu(x, α) = (max(x, αx) with α in [0,1].\n\n\n\n\n\n","category":"function"},{"location":"mccormick/operators/#McCormick.maxtanh","page":"Currently Supported Operators","title":"McCormick.maxtanh","text":"maxtanh\n\nThe maxtanh activation function  maxtanh(x) = max(x, tanh(x)).\n\n\n\n\n\n","category":"function"},{"location":"quick_start/qs_landing/#Quick-Start","page":"Quick Start","title":"Quick Start","text":"EAGO is a global optimizer primarily meant to be used with the JuMP algebraic modeling language. Typical use will involve installing EAGO and JuMP, creating a problem using JuMP syntax, and passing the problem to the Optimizer. ","category":"section"},{"location":"quick_start/qs_landing/#Customization","page":"Quick Start","title":"Customization","text":"EAGO is designed to be easily extensible. Some of the examples that follow include use cases where the standard EAGO functionality is overloaded and readily incorporated into the main optimization routine. Information on how to extend the main branch-and-bound functions (including lower and upper-bounding routines) can be found in the Customization Guidelines section.","category":"section"},{"location":"quick_start/qs_landing/#Examples","page":"Quick Start","title":"Examples","text":"The following pages in this section include several representative examples of how EAGO can be used. Additional (and in some cases, shortened) examples can be found in the EAGO-notebooks repository. Examples and instructional pages in this section include:\n\nStandard-Use Example 1: A base-case optimization problem solved using the EAGO optimizer. No extensions or function overloading required.\nStandard-Use Example 2: An interval bounding example where the user redefines EAGO's lower and upper-bounding functions.\nAdvanced-Use Example 1: A quasiconvex optimization problem solved by overloading some of EAGO's functionality to implement a bisection-based algorithm instead of typical branch-and-bound.\nAdvanced-Use Example 2: Overloading the branch-and-bound algorithm with a custom extension type.","category":"section"},{"location":"optimizer/relax_back/#Nonlinear-Backend","page":"Nonlinear Backend","title":"Nonlinear Backend","text":"","category":"section"},{"location":"optimizer/relax_back/#Graphs,-Caches,-Forward-and-Reverse-Propagation","page":"Nonlinear Backend","title":"Graphs, Caches, Forward and Reverse Propagation","text":"EAGO makes use of a specialized tape structure for each function in order to compute valid composite bounds and relaxations. Each variable, constant, and expression is represented by a node in a directed graph structure. \n\nEach field of the ith EAGO.Node using a basic access function. For instance the ith node's ex_type for graph d may be accessed by ex_type(d, i). The sparsity of node i returns an ordered list of children nodes which form the argument tuple for the operator performed at node i. The sparsity of node i returns a list of parent nodes which form the argument tuple for the operator performed at node i. The parameter_values and constant_values functions are used to access the ith parameter values or ith constant values.\n\nEAGO organizes information associated with each node in a given graph structure using an EAGO.AbstractCache which stores the given information.\n\nInformation in a given EAGO.AbstractCache is populated by performing a series of forward and reverse passes of the graph structure which dispatch off of an EAGO.AbstractCacheAttribute which indicates what particular information is desired.\n\nThree included AbstractCacheAttributes are used to \n\nThe forward and reverse routines are overloaded as follows:\n\nForward and reverse subroutines are overloaded for individual operators using through functions of the forms  fprop!(t::AbstractCacheAttribute, v::Val{AtomType}, g::AbstractDirectedGraph, b::AbstractCache, k::Int) and rprop!(t::AbstractCacheAttribute, v::Val{AtomType}, g::AbstractDirectedGraph, b::AbstractCache, k::Int). ","category":"section"},{"location":"optimizer/relax_back/#Other-Routines","page":"Nonlinear Backend","title":"Other Routines","text":"","category":"section"},{"location":"optimizer/relax_back/#EAGO.Node","page":"Nonlinear Backend","title":"EAGO.Node","text":"struct Node <: EAGO.AbstractNode\n\nDescribes connectivity and expression represented by node.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.NodeClass","page":"Nonlinear Backend","title":"EAGO.NodeClass","text":"NodeType\n\nEach node in the directed graph can be classified into the following types\n\nVARIABLE: Denotes a decision variable.\nPARAMETER: An adjustable parameter value (not a decision variable).\nCONSTANT: A constant value\nEXPRESSION: Any other expression that isn't a subexpression\nSUBEXPRESSION: Any expression referencing a different graph representation.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.AtomType","page":"Nonlinear Backend","title":"EAGO.AtomType","text":"AtomType\n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.AbstractDirectedGraph","page":"Nonlinear Backend","title":"EAGO.AbstractDirectedGraph","text":"abstract type AbstractDirectedGraph\n\nAbstract supertype for generic directed graph structure.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.DirectedTree","page":"Nonlinear Backend","title":"EAGO.DirectedTree","text":"DirectedTree\n\nA tree graph with a single sink node.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.AbstractCache","page":"Nonlinear Backend","title":"EAGO.AbstractCache","text":"abstract type AbstractCache\n\nAbstract supertype used for information storage object the directed acyclic graph.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.initialize!-Tuple{AbstractCache, AbstractDirectedGraph}","page":"Nonlinear Backend","title":"EAGO.initialize!","text":"initialize!(_::AbstractCache, _::AbstractDirectedGraph)\n\n\nFunction used to initialize the storage cache d::AbstractCache  for a given type of directed acyclic graph g::AbstractDirectedGraph.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.AbstractCacheAttribute","page":"Nonlinear Backend","title":"EAGO.AbstractCacheAttribute","text":"abstract type AbstractCacheAttribute\n\nAbstract supertype used for attributes stored in a cache.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.Relax","page":"Nonlinear Backend","title":"EAGO.Relax","text":"Relax\n\nUsed to dispatch relaxations to a standard \n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.RelaxAA","page":"Nonlinear Backend","title":"EAGO.RelaxAA","text":"RelaxAA\n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.RelaxMulEnum","page":"Nonlinear Backend","title":"EAGO.RelaxMulEnum","text":"RelaxMulEnum\n\n\n\n\n\n","category":"type"},{"location":"optimizer/relax_back/#EAGO.f_init!-Tuple{AbstractCacheAttribute, AbstractDirectedGraph, AbstractCache}","page":"Nonlinear Backend","title":"EAGO.f_init!","text":"Initializes information in cache c for each node in g that may be used in a forward-pass of attribute t. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Variable, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a variable v at index k in  cache c associated with graph g using information at index k. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Subexpression, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a subexpression v at index k in  cache c associated with graph g using information taken from the children of k. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Expression, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a expression v at index k in  cache c associated with graph g using information taken from the children of k. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Parameter, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a parameter v at index k in  cache c associated with graph g using information at index k. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Constant, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a constant v at index k in  cache c associated with graph g using information at index k. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.r_init!-Tuple{AbstractCacheAttribute, AbstractDirectedGraph, AbstractCache}","page":"Nonlinear Backend","title":"EAGO.r_init!","text":"Initializes information in cache c for each node in g that may be used in a reverse-pass of attribute t. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Variable, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a variable v at index k in  cache c  associated with graph g using information at index k taken from the parents of k. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Subexpression, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a subexpressions v at index k in  cache c  associated with graph g using information at index k taken from the parents of k. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Expression, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a expressions v at index k in  cache c  associated with graph g using information at index k taken from the parents of k. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Parameter, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a parameters v at index k in  cache c  associated with graph g using information at index k taken from the parents of k. \n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Constant, AbstractDirectedGraph, AbstractCache, Int64}","page":"Nonlinear Backend","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a constant v at index k in  cache c  associated with graph g using information at index k taken from the parents of k.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/relax_back/#EAGO.is_safe_cut!-Tuple{GlobalOptimizer, MathOptInterface.ScalarAffineFunction{Float64}}","page":"Nonlinear Backend","title":"EAGO.is_safe_cut!","text":"is_safe_cut!(\n    m::GlobalOptimizer,\n    f::MathOptInterface.ScalarAffineFunction{Float64}\n) -> Bool\n\n\nApplies the safe cut checks detailed in Khajavirad, 2018 [Khajavirad, Aida, and Nikolaos V. Sahinidis. \"A hybrid LP/NLP paradigm for global optimization relaxations.\" Mathematical Programming Computation 10.3 (2018): 383-421] to ensure that only numerically safe affine relaxations are added. Checks that:\n\n|b| <= safe b, \nsafe_l <= abs(ai) <= safe u, and \nsafe_l <= abs(ai/aj) <= safe_u.\n\n\n\n\n\n","category":"method"},{"location":"mccormick/type/#Types","page":"Types","title":"Types","text":"","category":"section"},{"location":"mccormick/type/#Constructors-for-MC","page":"Types","title":"Constructors for MC","text":"","category":"section"},{"location":"mccormick/type/#Internal-Utilities","page":"Types","title":"Internal Utilities","text":"","category":"section"},{"location":"mccormick/type/#(Under-Development)-MCNoGrad","page":"Types","title":"(Under Development) MCNoGrad","text":"A handful of applications make use of McCormick relaxations directly without the need for subgradients. We are currently adding support for a McCormick struct which omits subgradient propagation in favor of return a MCNoGrad object and associated derivative information. This is currently under development and likely lacking key functionality.","category":"section"},{"location":"mccormick/type/#McCormick.MC","page":"Types","title":"McCormick.MC","text":"struct MC{N, T<:RelaxTag} <: Real\n\nMC{N, T <: RelaxTag} <: Real is the McCormick (w/ (sub)gradient) structure which is used to overload standard calculations. The fields are:\n\ncv::Float64: Convex relaxation\ncc::Float64: Concave relaxation\nIntv::Interval{Float64}: Interval bounds\ncv_grad::SVector{N, Float64} where N: (Sub)gradient of convex relaxation\ncc_grad::SVector{N, Float64} where N: (Sub)gradient of concave relaxation\ncnst::Bool: Boolean indicating whether the relaxations are constant over the domain. True if bounding an interval/constant.      False, otherwise. This may change over the course of a calculation cnst for zero(x) is true even if x.cnst      is false.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/type/#McCormick.RelaxTag","page":"Types","title":"McCormick.RelaxTag","text":"abstract type RelaxTag\n\nAn abstract type the subtypes of which define the manner of relaxation that will be performed for each operator applied to the MC object. Currently, the struct NS which specifies that standard (Mitsos 2009) are to be used is fully supported. Limited support is provided for differentiable McCormick relaxations specified by struct Diff (Khan 2017) and struct MV struct MV (Tsoukalas 2011.) A rounding-safe implementation of the standard McCormick relaxations is specified by the struct NSSafe which is work in progress.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/type/#McCormick.MC-Union{Tuple{Float64}, Tuple{T}, Tuple{N}} where {N, T}","page":"Types","title":"McCormick.MC","text":"MC{N,T}(y::Interval{Float64})\n\nConstructs a McCormick relaxation with the convex relaxation equal to y.lo and concave relaxation equal to y.hi.\n\n\n\n\n\nMC{N,T}(y::Float64)\n\nConstructs a McCormick relaxation with the convex relaxation equal to y and concave relaxation equal to y.\n\n\n\n\n\n","category":"method"},{"location":"mccormick/type/#McCormick.mid3","page":"Types","title":"McCormick.mid3","text":"mid3(\n    x::Float64,\n    y::Float64,\n    z::Float64\n) -> Tuple{Float64, Int64}\n\n\nCalculates the middle of three numbers returning the value and the index where x >= y.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.mid3v","page":"Types","title":"McCormick.mid3v","text":"mid3v(x::Float64, y::Float64, z::Float64) -> Float64\n\n\nCalculates the middle of three numbers (x,y,z) returning the value where x <= y.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.mid_grad","page":"Types","title":"McCormick.mid_grad","text":"mid_grad(\n    cc_grad::SArray{Tuple{N}, Float64, 1, N},\n    cv_grad::SArray{Tuple{N}, Float64, 1, N},\n    id::Int64\n) -> Any\n\n\nTakes the concave relaxation gradient cc_grad, the convex relaxation gradient cv_grad, and the index of the midpoint returned id and outputs the appropriate gradient according to McCormick relaxation rules.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.dline_seg","page":"Types","title":"McCormick.dline_seg","text":"dline_seg(\n    f::Function,\n    df::Function,\n    x::Float64,\n    xL::Float64,\n    xU::Float64\n) -> Tuple{Any, Any}\n\n\nCalculates the value and the slope of the line segment between (xL, f(xL)) and (xU, f(xU)). Defaults to evaluating the derivative of the function if the interval is tight.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.seed_gradient","page":"Types","title":"McCormick.seed_gradient","text":"seed_gradient(j::Int64, x::Val{N}) -> Any\n\n\nCreates a x::SVector{N,Float64} object that is one at x[j] and zero everywhere else.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.cut","page":"Types","title":"McCormick.cut","text":"cut(\n    xL::Float64,\n    xU::Float64,\n    cv::Float64,\n    cc::Float64,\n    cv_grad::SArray{Tuple{N}, Float64, 1, N},\n    cc_grad::SArray{Tuple{N}, Float64, 1, N}\n) -> Tuple{Float64, Float64, Any, Any}\n\n\nRefines convex/concave relaxations cv and cc with associated subgradients cv_grad and cc_grad by intersecting them with the interval bounds xL and xU.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.secant","page":"Types","title":"McCormick.secant","text":"secant(\n    x0::Float64,\n    x1::Float64,\n    xL::Float64,\n    xU::Float64,\n    f::Function,\n    envp1::Float64,\n    envp2::Float64\n) -> Tuple{Float64, Bool}\n\n\nDefines a local 1D secant method to solve for the root of f between the bounds xL and xU using x0 and x1 as a starting points. The inputs envp1 and envp2 are the envelope calculation parameters.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.newton","page":"Types","title":"McCormick.newton","text":"newton(\n    x0::Float64,\n    xL::Float64,\n    xU::Float64,\n    f::Function,\n    df::Function,\n    envp1::Float64,\n    envp2::Float64\n) -> Tuple{Any, Bool}\n\n\nDefines a local 1D newton method to solve for the root of f between the bounds xL and xU using x0 as a starting point. The derivative of f is df. The inputs envp1 and envp2 are the envelope calculation parameters.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.golden_section_it","page":"Types","title":"McCormick.golden_section_it","text":"golden_section_it(\n    init::Int64,\n    a::Float64,\n    fa::Float64,\n    b::Float64,\n    fb::Float64,\n    c::Float64,\n    fc::Float64,\n    f::Function,\n    envp1::Float64,\n    envp2::Float64\n) -> Float64\n\n\nDefine iteration used in golden section method. The inputs fa,fb, and fc, are the function f evaluated at a,b, and c respectively. The inputs envp1 and envp2 are the envelope calculation parameters. The value init is the iteration number of the golden section method.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.golden_section","page":"Types","title":"McCormick.golden_section","text":"golden_section(\n    xL::Float64,\n    xU::Float64,\n    f::Function,\n    envp1::Float64,\n    envp2::Float64\n) -> Float64\n\n\nDefines a local 1D golden section method to solve for the root of f between the bounds xL and xU using x0 as a starting point. Define iteration used in golden section method. The inputs envp1 and envp2 are the envelope calculation parameters.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/type/#McCormick.MCNoGrad","page":"Types","title":"McCormick.MCNoGrad","text":"struct MCNoGrad <: Real\n\nMCNoGrad <: Real is a McCormick structure without RelaxType Tag or subgradients. This structure is used for source-code transformation approaches to constructing McCormick relaxations. Methods definitions and calls should specify the relaxation type used (i.e.) +(::NS, x::MCNoGrad, y::MCNoGrad).... Moreover, the kernel associated with this returns all intermediate calculations necessary to compute subgradient information whereas the overloading calculation simply returns the MCNoGrad object. For univariate calculations without tiepoints such as we log2(::NS, x::MCNoGrad)::MCNoGrad whereas log2_kernel(::NS, x::MCNoGrad, ::Bool) = (::MCNoGrad, cv_id::Int, cc_id::Int, dcv, dcc). Univariate NS functions follow convention (MCNoGrad, cvid, ccid, dcv, dcc, tp1cv, tp1cc, .... tpncv, tpncc) where cv_id is the subgradient selected (1 = cv, 2 = cc, 3 = 0), dcv and dcc are derivatives (or elements of subdifferential) of the outside function evaluated per theorem at the point being evaluated and tpicv, tpicc are the ith tiepoints associated with computing the envelope of the outside function. .\n\ncv::Float64: Convex relaxation\ncc::Float64: Concave relaxation\nIntv::Interval{Float64}: Interval bounds\ncnst::Bool: Boolean indicating whether the relaxations are constant over the domain. True if bounding an interval/constant.      False, otherwise. This may change over the course of a calculation cnst for zero(x) is true even if x.cnst      is false.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/type/#McCormick.MCNoGrad-Tuple{Float64}","page":"Types","title":"McCormick.MCNoGrad","text":"MCNoGrad(y::Float64)\n\nConstructs McCormick relaxation with convex relaxation equal to y and concave relaxation equal to y.\n\n\n\n\n\n","category":"method"},{"location":"mccormick/type/#McCormick.MCNoGrad-Tuple{Interval{Float64}}","page":"Types","title":"McCormick.MCNoGrad","text":"MCNoGrad(y::Interval{Float64})\n\nConstructs McCormick relaxation with convex relaxation equal to y.lo and concave relaxation equal to y.hi.\n\n\n\n\n\n","category":"method"},{"location":"mccormick/type/#McCormick.MCNoGrad-Tuple{Float64, Float64}","page":"Types","title":"McCormick.MCNoGrad","text":"MCNoGrad(cv::Float64, cc::Float64)\n\nConstructs McCormick relaxation with convex relaxation equal to cv and concave relaxation equal to cc.\n\n\n\n\n\n","category":"method"},{"location":"examples/alpha_bb/#Advanced-Use-Example-2","page":"Advanced-Use Example 2","title":"Advanced-Use Example 2","text":"This example is also provided here as a Jupyter Notebook.","category":"section"},{"location":"examples/alpha_bb/#An-\\alphaBB-Example-for-a-QCQP.","page":"Advanced-Use Example 2","title":"An alphaBB Example for a QCQP.","text":"In this example, we will demonstrate the use of a user-defined lower-bounding problem that uses alphaBB convex relaxations. In this example, we wish to solve the nonconvex quadratically constrained quadratic program (QCQP):\n\nbeginaligned\n min_mathbf x in mathbbIR^2 frac12 mathbf x^rm T mathbf Q_f mathbf x + mathbf c_f^rm T mathbf x \nrm st    g_1(mathbf x) = frac12 mathbf x^rm T mathbf Q_g_1mathbf x + mathbf c_g_1^rm T mathbf x leq 0 \n g_2(mathbf x) = frac12 mathbf x^rm T mathbf Q_g_2 mathbf x + mathbf c_g_2^rm T mathbf x leq 0 \nendaligned\n\nwith mathbf Q_iinmathbb R^2times 2 not positive semidefinite for any i.\n\nusing JuMP, EAGO, Ipopt, LinearAlgebra","category":"section"},{"location":"examples/alpha_bb/#Custom-Function-Definitions","page":"Advanced-Use Example 2","title":"Custom Function Definitions","text":"For convenience, we'll define the following function that returns all the problem data mathbf Q_i and mathbf c_i.\n\nfunction QCQP_setup()\n\n    Qf = [3.0, 3/2; 3/2, -5.0]\n    cf = [3.0; 2.0]\n\n    Qg1 = [-2.0, 5.0; 5.0, -2.0]\n    cg1 = [1.0; 3.0]\n\n    Qg2 = [-6.0, 3.0; 3.0, 2.0]\n    cg2 = [2.0; 1.0]\n    \n    return Qf, cf, Qg1, cg1, Qg2, cg2\nend\n\nThe next function we'll define will take as input data for a particular quadratic function and the interval bounds on the decision variables, and construct an alphaBB convex relaxation of that function. Since we're solving a QCQP, we'll use the eigvals function to directly compute the eigenvalues of the input mathbf Q_i matrix.\n\nfunction αBB_relax(Q::Matrix{T}, c::Vector{T}, xL::Vector{T}, xU::Vector{T}, x::Real...) where {T<:Float64}\n    α = max(0.0, -minimum(eigvals(Q))/2)\n    y = [x[1]; x[2]]\n    cv = 1/2*y'*Q*y + c'*y + α*(xL - y)'*(xU - y)\n    return cv\nend","category":"section"},{"location":"examples/alpha_bb/#Redefine-the-Lower-Bounding-Problem","page":"Advanced-Use Example 2","title":"Redefine the Lower-Bounding Problem","text":"The following code first defines our EAGO extension (custom version) struct and then it redefines the lower-bounding problem as our own version. That is, when we call this customized version of EAGO to solve the problem, it'll deploy this version of the lower-bounding problem instead of the default version.  \n\nimport EAGO: Optimizer, GlobalOptimizer\n\nstruct αBB_Convex <: EAGO.ExtensionType end\nimport EAGO: lower_problem!\nfunction EAGO.lower_problem!(t::αBB_Convex, opt::GlobalOptimizer)\n    # Get active node\n    n = opt._current_node\n    # Get bounds on active node for calculating relaxations\n    xL = n.lower_variable_bounds[1:2]\n    xU = n.upper_variable_bounds[1:2]\n    # Get the problem data\n    Qf, cf, Qg1, cg1, Qg2, cg2 = QCQP_setup()\n\n    # Define the JuMP model and declare the solver\n    mL = JuMP.Model(JuMP.optimizer_with_attributes(IpoptMathOptInterfaceExt.Optimizer,\n                                \"tol\" => 1.0e-6,\n                                \"print_level\" => 0))\n    @variable(mL, xL[i] <= x[i=1:2] <= xU[i])\n    \n    # Define the function closures for the user-defined relaxations\n    fcv(x...) = αBB_relax(Qf, cf, xL, xU, x...)\n    g1cv(x...) = αBB_relax(Qg1, cg1, xL, xU, x...)\n    g2cv(x...) = αBB_relax(Qg2, cg2, xL, xU, x...)\n\n    # Register the user-defined functions\n    # Note: If the gradients and Hessians are directly available, they could\n    # be passed as arguments to the register function to speed things up.\n    JuMP.register(mL, :fcv, 2, fcv, autodiff=true)\n    JuMP.register(mL, :g1cv, 2, g1cv, autodiff=true)\n    JuMP.register(mL, :g2cv, 2, g2cv, autodiff=true)\n\n    # Declare the objective function and constraints\n    @NLobjective(mL, Min, fcv(x[1], x[2]))\n    @NLconstraint(mL, g1cv(x[1], x[2]) <= 0.0)\n    @NLconstraint(mL, g2cv(x[1], x[2]) <= 0.0)\n    \n    # Solve the relaxed problem\n    JuMP.optimize!(mL)\n    \n    # Get primal status, termination status, determine if a global solution was obtained\n    tstatus = MOI.get(mL, MOI.TerminationStatus())\n    pstatus = MOI.get(mL, MOI.PrimalStatus())\n\n    solution = JuMP.value.(x)\n    # Interpret status codes for branch-and-bound\n    if EAGO.local_problem_status(tstatus, pstatus) == EAGO.LRS_FEASIBLE\n        opt._lower_objective_value = JuMP.objective_value(mL) \n        opt._lower_solution[1:length(solution)] = solution\n        opt._lower_feasibility = true\n        opt._cut_add_flag = false\n    else\n        opt._lower_feasibility = false\n        opt._lower_objective_value = -Inf\n        opt._cut_add_flag = false\n    end\n    return\nend\n\nnote: Note\nBy default, EAGO solves the epigraph reformulation of your original problem, which increases the original problem dimensionality by +1 with the introduction of an auxiliary variable. When defining custom routines (such as the lower-bounding problem here) that are intended to work nicely with default EAGO routines (such as preprocessing), the user must account for the new dimensionality of the problem. In the code above, we wish to access the information of the specific B&B node and define an optimization problem based on that information. However, in this example, the node has information for 3 variables (the original 2 plus 1 for the auxiliary variable appended to the original variable vector) as (x_1 x_2 eta). The lower-bounding problem was defined to optimize the relaxed problem with respect to the original 2 decision variables. When storing the results of this subproblem to the current B&B node, it is important to take care to store the information at the appropriate indices and not inadvertently redefine the problem dimensionality (i.e., by simply storing the optimization solution as the lower_solution of the current node). For problems that are defined to only branch on a subset of the original variables, the optimizer has a member _sol_to_branch_map that carries the mapping between the indices of the original variables to those of the variables being branched on. Visit our quasiconvex example to see how this is done.","category":"section"},{"location":"examples/alpha_bb/#(Optional)-Turn-Off-Processing-Routines","page":"Advanced-Use Example 2","title":"(Optional) Turn Off Processing Routines","text":"Turn off preprocessing routines if you don't want to use them as defined in EAGO. \n\nimport EAGO: preprocess!\nfunction EAGO.preprocess!(t::αBB_Convex, x::GlobalOptimizer)\n    x._preprocess_feasibility = true\n    return\nend\n\nTurn off postprocessing routines if you don't want to use them as defined in EAGO. \n\nimport EAGO: postprocess!\nfunction EAGO.postprocess!(t::αBB_Convex, x::GlobalOptimizer)\n    x._postprocess_feasibility = true\n    return\nend","category":"section"},{"location":"examples/alpha_bb/#Construct-the-JuMP-Model-and-Optimize","page":"Advanced-Use Example 2","title":"Construct the JuMP Model and Optimize","text":"Now, we'll tell EAGO to use our custom/extended solver, set up the main JuMP model, and solve it with our custom solver. \n\nfactory = () -> EAGO.Optimizer(SubSolvers(; t = αBB_Convex() ))\nm = JuMP.Model(optimizer_with_attributes(factory,\n                                \"relative_tolerance\" => 1e-3,\n                                \"verbosity\" => 1,\n                                \"output_iterations\" => 1, \n                                \"branch_variable\" => Bool[true; true],\n                                ))\nQf, cf, Qg1, cg1, Qg2, cg2 = QCQP_setup()   # Get QCQP data\nxL = [-3.0; -5.0]                           # Lower bounds on x\nxU = [1.0; 2.0]                             # Upper bounds on x\n@variable(m, xL[i] <= x[i=1:2] <= xU[i])\n\n# Define objective and constraints\n@objective(m, Min, 1/2*x'*Qf*x + cf'*x)\n@constraint(m, 1/2*x'*Qg1*x + cg1'*x <= 0.0)\n@constraint(m, 1/2*x'*Qg2*x + cg2'*x <= 0.0)\n\n# Solve the problem\n@time optimize!(m)","category":"section"},{"location":"examples/alpha_bb/#Retrieve-Results","page":"Advanced-Use Example 2","title":"Retrieve Results","text":"We then recover the objective value, the solution values, and termination status codes using standard JuMP syntax.\n\nprintln(\"x1* = \", JuMP.value(x[1]), \" x2* = \",\n         JuMP.value(x[2]),\" f* = \",JuMP.objective_value(m))\nTermStatus = JuMP.termination_status(m)\nPrimStatus = JuMP.primal_status(m)\nprintln(\"Algorithm terminated with a status of $TermStatus and result code of $PrimStatus\")","category":"section"},{"location":"optimizer/bnb_back/#EAGO's-Branch-and-Bound-Routine","page":"EAGO's Branch and Bound Routine","title":"EAGO's Branch and Bound Routine","text":"This component is meant to provide a flexible framework for implementing spatial branch-and-bound based optimization routines in Julia. All components of the branch-and-bound routine can be customized by the individual user: lower-bounding problem, upper-bounding problem.","category":"section"},{"location":"optimizer/bnb_back/#Branch-and-Bound-Node-Storage","page":"EAGO's Branch and Bound Routine","title":"Branch and Bound Node Storage","text":"The GlobalOptimizer structure holds all information relevant to branch-and-bound.","category":"section"},{"location":"optimizer/bnb_back/#Customizable-Subroutines","page":"EAGO's Branch and Bound Routine","title":"Customizable Subroutines","text":"","category":"section"},{"location":"optimizer/bnb_back/#Stack-Management-Subroutines","page":"EAGO's Branch and Bound Routine","title":"Stack Management Subroutines","text":"","category":"section"},{"location":"optimizer/bnb_back/#Internal-Subproblem-Status-Codes-and-Subsolver-Management","page":"EAGO's Branch and Bound Routine","title":"Internal Subproblem Status Codes and Subsolver Management","text":"","category":"section"},{"location":"optimizer/bnb_back/#Main-Subproblem-and-Termination-Subroutines","page":"EAGO's Branch and Bound Routine","title":"Main Subproblem and Termination Subroutines","text":"","category":"section"},{"location":"optimizer/bnb_back/#Internal-Subroutines","page":"EAGO's Branch and Bound Routine","title":"Internal Subroutines","text":"","category":"section"},{"location":"optimizer/bnb_back/#Functions-for-Generating-Console-Output","page":"EAGO's Branch and Bound Routine","title":"Functions for Generating Console Output","text":"","category":"section"},{"location":"optimizer/bnb_back/#Support-for-Log-Output-at-Each-Iteration","page":"EAGO's Branch and Bound Routine","title":"Support for Log Output at Each Iteration","text":"","category":"section"},{"location":"optimizer/bnb_back/#Interval-Representations-of-Expressions","page":"EAGO's Branch and Bound Routine","title":"Interval Representations of Expressions","text":"","category":"section"},{"location":"optimizer/bnb_back/#EAGO.NodeBB","page":"EAGO's Branch and Bound Routine","title":"EAGO.NodeBB","text":"struct NodeBB\n\nStore information associated with each node in the branch-and-bound tree.\n\nlower_variable_bounds::Vector{Float64}: Lower bounds of variable box.\nupper_variable_bounds::Vector{Float64}: Upper bounds of variable box.\nis_integer::BitVector: Is dimension integer valued\ncontinuous::Bool: Are all dimensions continuous (or fixed)\nlower_bound::Float64: Lower bound of problem solution on nodeBB\nupper_bound::Float64: Upper bound of problem solution on nodeBB\ndepth::Int64: Depth of node in B&B tree.\ncont_depth::Int64: Depth of first parent in B&B tree that was continuously valued\nid::Int64: Unique ID for each node.\nbranch_direction::EAGO.BranchDirection: Whether last branch was negative or positive in direction\nlast_branch::Int64: Dimension of last branch\nbranch_extent::Float64: Extent of last branch (using for psuedocost calculation)\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.GlobalOptimizer","page":"EAGO's Branch and Bound Routine","title":"EAGO.GlobalOptimizer","text":"mutable struct GlobalOptimizer{Q, S, T<:ExtensionType} <: MathOptInterface.AbstractOptimizer\n\nOptimizer internal to EAGO which holds information used to perform branch-and-bound in order to solve nonconvex MINLPs.\n\nDescriptions of all fields available in extended help.\n\nExtended Help\n\n_subsolvers::SubSolvers{Q, S} where {Q, S}: Storage for relaxed and upper optimizers to use, and any custom extensions\n_parameters::EAGOParameters: Parameters that do not change during a global solve\n_input_problem::InputProblem: Expressions and constraints added to the EAGO model (not directly     used for relaxations)\n_working_problem::ParsedProblem: Expressions and problem descriptions that EAGO uses to formulate     relaxed problems\n_auxiliary_variable_info::Union{Nothing, EAGO._AuxVarData}: Information on any auxiliary variables\nobbt_variable_values::Vector{Bool}: Variables to perform OBBT on (default: all variables in nonlinear expressions)\nenable_optimize_hook::Bool: Specifies that the optimize_hook! function should be called rather than throw the     problem to the standard routine\next::Any: (Deprecated, use _subsolvers instead) Storage for custom extension types\n_end_state::EAGO.GlobalEndState: The completion status code for the branch-and-bound algorithm\n_termination_status_code::MathOptInterface.TerminationStatusCode: The MathOptInterface-compliant completion status code\n_result_status_code::MathOptInterface.ResultStatusCode: Value indicating the feasibility status of the result\n_obj_mult::Float64: Multiplier used internally to convert objective sense from Max to Min. Only     takes on values of {-1.0, 1.0}\n_obj_var_slack_added::Bool: Flag to indicate if a slack variable was added for the objective function. This     is done in some epigraph reformulations (see reform_epigraph_min!)\n_stack::DataStructures.BinaryMinMaxHeap{NodeBB}: A heap of all nodes in the branch-and-bound tree\n_current_node::NodeBB: The individual node being examined at any particular time. Nodes are removed from     the stack and placed here, evaluated, and then sent back to the stack\n_first_relax_point_set::Bool: (Unused) Flag for relaxation points\n_current_xref::Vector{Float64}: (Unused) Variable values of a particular point\n_candidate_xref::Vector{Float64}: (Unused) Variable values of a candidate point\n_use_prior_objective_xref::Bool: (Unused) Flag to use variable values from previous evaluation on the current step\n_current_objective_xref::Vector{Float64}: (Unused) Variable values for objective evaluation\n_prior_objective_xref::Vector{Float64}: (Unused) Variable values for previous objective evaluation\n_user_branch_variables::Bool: Flag for if the user has specified branch variables (see label_branch_variables!)\n_fixed_variable::Vector{Bool}: Variables that are fixed in place\n_branch_variable_count::Int64: Number of variables that can be branched on\n_branch_to_sol_map::Vector{Int64}: Mapping from the branch variables to the full set of variables in the problem\n_sol_to_branch_map::Vector{Int64}: Mapping from the full set of variables in the problem to the branch variables\n_continuous_solution::Vector{Float64}: The final (or intermediate) variable values of the solution\n_preprocess_feasibility::Bool: Flag to ensure preprocessing result is feasible\n_preprocess_termination_status::MathOptInterface.TerminationStatusCode: Status codes for use in bounds tightening\n_preprocess_primal_status::MathOptInterface.ResultStatusCode: Status codes for use in bounds tightening\n_preprocess_dual_status::MathOptInterface.ResultStatusCode: Status codes for use in bounds tightening\n_lower_primal_status::MathOptInterface.ResultStatusCode: Primal status of the lower problem\n_lower_dual_status::MathOptInterface.ResultStatusCode: Dual status of the lower problem\n_lower_termination_status::MathOptInterface.TerminationStatusCode: Termination status of the lower problem\n_lower_feasibility::Bool: Flag for lower problem feasibility\n_lower_objective_value::Float64: Objective value result from the lower problem\n_lower_solution::Vector{Float64}: Variable values of the lower problem solution\n_lower_lvd::Vector{Float64}: Lower variable duals for use in duality-based bound tightening\n_lower_uvd::Vector{Float64}: Upper variable duals for use in duality-based bound tightening\n_last_cut_objective::Float64: Objective value associated with the previous cut in the cutting planes algorithm\n_upper_result_status::MathOptInterface.ResultStatusCode: Primal status of the upper problem\n_upper_termination_status::MathOptInterface.TerminationStatusCode: Termination status of the upper problem\n_upper_feasibility::Bool: Flag for upper problem feasibility\n_upper_objective_value::Float64: Objective value result from the upper problem\n_upper_variables::Vector{MathOptInterface.VariableIndex}: \n_upper_solution::Vector{Float64}: \n_postprocess_feasibility::Bool: (Unused) Flag to ensure postprocessing result is feasible\n_time_left::Float64: Time remaining for the optimization algorithm. This is set in initial_parse! to the user-defined     time limit and is decremented throughout global_solve!\n_start_time::Float64: Storage for the time() when optimization began\n_run_time::Float64: Current run time, incremented using time()-_start_time\n_parse_time::Float64: A field to keep track of time spent on initial problem parsing\n_presolve_time::Float64: Used in optimize_nonconvex.jl to track how long the presolve step takes\n_last_preprocess_time::Float64: Updated each iteration to track the time of the preprocess step\n_last_lower_problem_time::Float64: Updated each iteration to track the time of the lower problem step\n_last_upper_problem_time::Float64: Updated each iteration to track the time of the upper problem step\n_last_postprocessing_time::Float64: Updated each iteration to track the time of the postprocess step\n_last_printed_iteration::Int64: Updated each time an iteration is printed\n_min_converged_value::Float64: A field to track convergence progress across iterations\n_global_lower_bound::Float64: The best-known lower bound\n_global_upper_bound::Float64: The best-known upper bound\n_maximum_node_id::Int64: The total number of nodes that have been created\n_iteration_count::Int64: The number of iterations the branch-and-bound algorithm has completed\n_node_count::Int64: The number of nodes in the stack\n_solution_value::Float64: (Unused) The best-known solution value\n_feasible_solution_found::Bool: A flag for if a feasible solution was identified. Updated if preprocessing,     lower problem, and upper problem all return feasible values\n_solution_node::Int64: The node ID of the best-known feasible upper problem solution (default = -1, if no feasible solution is found)\n_best_upper_value::Float64: The best-known upper bound\n_obbt_working_lower_index::Vector{Bool}: Indices of variables to perform OBBT on\n_obbt_working_upper_index::Vector{Bool}: Indices of variables to perform OBBT on\n_lower_indx_diff::Vector{Bool}: Tracker for changes in obbtworkinglowerindex across iterations\n_upper_indx_diff::Vector{Bool}: Tracker for changes in obbtworkingupperindex across iterations\n_old_low_index::Vector{Bool}: Storage for indices prior to OBBT step\n_old_upp_index::Vector{Bool}: Storage for indices prior to OBBT step\n_new_low_index::Vector{Bool}: New indices following OBBT step; compared with _old_low_index\n_new_upp_index::Vector{Bool}: New indices following OBBT step; compared with _old_upp_index\n_obbt_variables::Vector{MathOptInterface.VariableIndex}: (Deprecated) Variables to perform OBBT on. Replaced by _obbt_working_lower_index and _obbt_working_upper_index\n_obbt_variable_count::Int64: The number of variables to perform OBBT on\n_obbt_performed_flag::Bool: (Unused) Flag to indicate whether OBBT has been performed\n_lower_fbbt_buffer::Vector{Float64}: Buffer for FBBT lower bounds. Set in presolve, used in preprocess\n_upper_fbbt_buffer::Vector{Float64}: Buffer for FBBT upper bounds. Set in presolve, used in preprocess\n_cp_improvement::Float64: (Unused) Improvement in constraint propagation\n_cp_evaluation_reverse::Bool: (Unused) Flag for if constraint propagation results need to be reversed\n_cut_iterations::Int64: Iterations of the cutting planes algorithm completed\n_cut_add_flag::Bool: (Unused) Flag to check if cuts should be added\n_node_repetitions::Int64: Counter for number of times a node is evaluated. If the repeat_check function     is overloaded to return true, a node will not be branched on, but will instead     be added back into the stack using single_storage!. In this case, _node_repetitions     is incremented\n_log::Log: Storage for logging information during a branch-and-bound run\n_affine_relax_ci::Vector{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}}: Storage for affine constraints\n_affine_objective_cut_ci::Union{Nothing, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}}: Storage for a linear objective cut constraint\n_relaxed_variable_number::Int64: (Unused) Number of relaxed variables\n_relaxed_variable_index::Vector{MathOptInterface.VariableIndex}: Indices of relaxed variables\n_relaxed_variable_et::Vector{Tuple{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.EqualTo{Float64}}, Int64}}: Stored EqualTo constraints\n_relaxed_variable_lt::Vector{Tuple{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}, Int64}}: Stored LessThan constraints\n_relaxed_variable_gt::Vector{Tuple{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.GreaterThan{Float64}}, Int64}}: Stored GreaterThan constraints\n_relaxed_variable_integer::Vector{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.Integer}}: Stored Integer constraints\n_branch_variables::Vector{Bool}: List of variables that can be branched on. If not user-specified, branch variables     are identified in label_branch_variables!\n_nonbranching_int::Bool: (Unused) Flag for non-branching integers\n_new_eval_constraint::Bool: Flag indicating if an initial evaluation of the constraints has occurred\n_new_eval_objective::Bool: Flag indicating if the objective expression was evaluated\n_node_to_sv_leq_ci::Dict{Int64, MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}}: Storage for carrying LessThan constraint information. Used in obbt! and     update_relaxed_problem_box!\n_node_to_sv_geq_ci::Dict{Int64, MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.GreaterThan{Float64}}}: Storage for carrying GreaterThan constraint information. Used in obbt! and     update_relaxed_problem_box!\n_nonlinear_evaluator_created::Bool: Flag to check for nonlinear evaluators. Set to true in add_nonlinear_evaluator!\n_branch_cost::EAGO.BranchCostStorage{Float64}: (FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED) Storage for pseudocost branching\n_branch_variable_sparsity::SparseArrays.SparseMatrixCSC{Bool, Int64}: (FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED) Sparsity information of the     branch variables\n_constraint_infeasiblity::Vector{Float64}: (FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED) Information on the infeasibility     of each constraint\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.branch_node!-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.branch_node!","text":"branch_node!(t::ExtensionType, m::GlobalOptimizer)\n\n\nCreate two nodes from current_node and store them on the stack. Call select_branch_variable(t, m) and select_branch_point(t, m, k) to determine the variable that should be branched on and the point at which branching should occur, respectively.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.select_branch_variable-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.select_branch_variable","text":"select_branch_variable(\n    t::ExtensionType,\n    m::GlobalOptimizer\n) -> Any\n\n\nChoose a variable to branch on. A maximum relative width branching rule is used by default.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.select_branch_point-Tuple{ExtensionType, GlobalOptimizer, Any}","page":"EAGO's Branch and Bound Routine","title":"EAGO.select_branch_point","text":"select_branch_point(\n    t::ExtensionType,\n    m::GlobalOptimizer,\n    i\n) -> Float64\n\n\nSelect a point xb within the domain of the ith branching variable. By default, this point is a convex combination of the solution to the relaxation and the midpoint of the node (branch_cvx_factor*xmid + (1-branch_cvx_factor)*xsol). If the solution lies within branch_offset of a bound, then the branch point is moved to a distance of branch_offset from that bound.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.node_selection!-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.node_selection!","text":"node_selection!(t::ExtensionType, m::GlobalOptimizer)\n\n\nSelect the next node in the stack to evaluate. By default, perform best-first  node selection (select the node with the lowest lower bound in the stack).\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.fathom!-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.fathom!","text":"fathom!(t::ExtensionType, m::GlobalOptimizer)\n\n\nRemove nodes from the stack. By default, delete nodes from the stack if their lower bounds are greater than the current global upper bound.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.initialize_stack!-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.initialize_stack!","text":"initialize_stack!(t::ExtensionType, m::GlobalOptimizer)\n\n\nPrepare the stack for the branch-and-bound routine. By default, create an initial node with the variable bounds as box constraints and add it to the stack.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.single_storage!-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.single_storage!","text":"single_storage!(t::ExtensionType, m::GlobalOptimizer)\n\n\nStore the current node to the stack, without branching, after updating lower/upper bounds.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.RelaxResultStatus","page":"EAGO's Branch and Bound Routine","title":"EAGO.RelaxResultStatus","text":"RelaxResultStatus\n\nStatus code used internally to determine how to interpret the results from the solution of a relaxed problem.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.LocalResultStatus","page":"EAGO's Branch and Bound Routine","title":"EAGO.LocalResultStatus","text":"LocalResultStatus\n\nStatus code used internally to determine how to interpret the results from the solution of a local problem solve.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.Incremental","page":"EAGO's Branch and Bound Routine","title":"EAGO.Incremental","text":"mutable struct Incremental{S<:MathOptInterface.AbstractOptimizer} <: MathOptInterface.AbstractOptimizer\n\nA type-stable cache used to wrapper for an optimizer that enables incremental modification of solvers that don't inherently suppport this. Explicitly checks support of MOI functionality used in EAGO. \n\n(Deprecated) For Q = Val{true}, the subsolver supports incremental loading.  For Q = Val{false}, the subsolver does not.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.SubSolvers","page":"EAGO's Branch and Bound Routine","title":"EAGO.SubSolvers","text":"mutable struct SubSolvers{Q<:MathOptInterface.AbstractOptimizer, S<:MathOptInterface.AbstractOptimizer, T<:ExtensionType}\n\nA structure containing the relaxed and upper optimizers to be used, as well as any user-defined extension.\n\nrelaxed_optimizer::MathOptInterface.AbstractOptimizer: Optimizer used to solve relaxed subproblems. Set using r = [...] (<: MOI.AbstractOptimizer)         (default = GLPK.Optimizer())\nupper_optimizer::MathOptInterface.AbstractOptimizer: Optimizer used to solve upper bounding problems. Set using u = [...] (<: MOI.AbstractOptimizer)         (default = Ipopt.Optimizer())\next::ExtensionType: User-defined extension to use. Set using t = [...](<: EAGO.ExtensionType)\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.set_default_config!-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.set_default_config!","text":"set_default_config!\n\nConfigures subsolver tolerances based on tolerance parameters provided to EAGO (provided that a specialized subsolver configuration routine has been provided and m.user_solver_config = false).\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.convergence_check-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.convergence_check","text":"convergence_check(\n    t::ExtensionType,\n    m::GlobalOptimizer\n) -> Bool\n\n\nCheck for problem convergence.\n\nBy default, check if the lower and upper bounds have converged to within absolute and/or relative tolerances.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.cut_condition-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.cut_condition","text":"cut_condition(t::ExtensionType, m::GlobalOptimizer) -> Bool\n\n\nReturns true if a cut should be added and computes a new reference point to add the cut at. By default, checks that cut_max_iterations are not exceeded and that the  improvement in the objective value associated with the previous cut is greater than both an absolute tolerance cut_ϵ_abs and a relative tolerance cut_ϵ_rel. Returns false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.lower_problem!-Union{Tuple{Q}, Tuple{S}, Tuple{R}, Tuple{ExtensionType, GlobalOptimizer{R, S, Q}}} where {R, S, Q<:ExtensionType}","page":"EAGO's Branch and Bound Routine","title":"EAGO.lower_problem!","text":"lower_problem!(\n    t::ExtensionType,\n    m::GlobalOptimizer{R, S, Q<:ExtensionType}\n)\n\n\nConstructs a relaxation of the MINLP on node y and solves it using the default EAGO  relaxation scheme. By default, EAGO applies Kelley's algorithm (from Kelley Jr., J.E.:  The cutting-plane method for solving convex programs. J. Soc. Ind. Appl. Math. 8(4),  703 to 712 (1960)) while cut_condition(m) returns true then activates the integrality constraints of the relaxed problems and solves the resulting MILP relaxation. results are stored to the _lower_solution, _lower_termination_status, _lower_primal_status, _lower_dual_status, _lower_objective_value, and _lower_feasibility. Further, lower and upper variable duals are stored _lower_lvd and _lower_uvd, respectively, for use in duality based bound tightening. If relaxation-based bounds are weaker or cutting-planes  are numerically poorly ill-posed, then interval bounds are used instead. If the problem is dual feasible but the primal status is ambiguous the dual objective value is used for the  lower bound to avoid numerical issues.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.preprocess!-Union{Tuple{Q}, Tuple{S}, Tuple{R}, Tuple{ExtensionType, GlobalOptimizer{R, S, Q}}} where {R, S, Q<:ExtensionType}","page":"EAGO's Branch and Bound Routine","title":"EAGO.preprocess!","text":"preprocess!(\n    t::ExtensionType,\n    m::GlobalOptimizer{R, S, Q<:ExtensionType}\n)\n\n\nRuns contractor methods prior to solving lower bounding problem. By default linear and quadratic  contractor methods followed by interval constraint propagation then optimization-based bound  tightening for a specified number of iterations while the subproblem at current node n has  not been proven infeasible.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.postprocess!-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.postprocess!","text":"postprocess!(t::ExtensionType, m::GlobalOptimizer)\n\n\nDefault postprocess perfoms duality-based bound tightening (Tawarmalani, M.,  Sahinidis, N.V.: Global optimization of mixed-integer nonlinear programs:  a theoretical and computational study. Math. Progr. 99, 563–591 (2004).) up to an iteration limit set by dbbt_depth.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.repeat_check-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.repeat_check","text":"repeat_check(t::ExtensionType, m::GlobalOptimizer) -> Bool\n\n\nCheck to see if current node should be reprocessed. Without any custom extension, return false by default.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.termination_check-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.termination_check","text":"termination_check(m::GlobalOptimizer)\ntermination_check(t::ExtensionType, m::GlobalOptimizer) -> Bool\n\nCheck for termination of the branch-and-bound algorithm.\n\nIf only the GlobalOptimizer is given as an argument, termination_check dispatches to the other form using the ExtensionType given in the SubSolvers. If there is no user-defined extension, then by default, this will check for satisfaction of absolute or relative tolerances, solution infeasibility, and other specified limits. Returns  true if any conditions are met and branch-and-bound should end, and false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.upper_problem!-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.upper_problem!","text":"upper_problem!(t::ExtensionType, m::GlobalOptimizer)\n\n\nDefault upper bounding problem which simply calls solve_local_nlp! to solve the NLP locally.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.parse_global!-Tuple{ExtensionType, GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.parse_global!","text":"Basic parsing for global solutions (no extensive manipulation). By default, does nothing.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.optimize_hook!-Tuple{ExtensionType, Optimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.optimize_hook!","text":"optimize_hook!(t::ExtensionType, m::Optimizer)\n\nProvide a hook for extensions to EAGO. \n\nThe user-defined extension of optimize_hook! is used in EAGO's overloading of MOI.optimize! (see EAGO.jl/src/eago_optimizer/optimize/optimize.jl). Without the optimize_hook! specified, EAGO will run initial_parse!, parse_classify_problem!, and then optimize! using the parsed problem type. The user-specified optimize_hook!  should thus take the new extension and Optimizer as inputs and will execute when the  user writes optimize!(model).\n\nExample\n\nHere, optimize_hook! is used to bypass EAGO's problem parsing and treat every problem using its branch-and-bound routine. This is done in this example by telling EAGO to treat the problem as a mixed integer nonconvex problem, which normally dispatches to branch-and-bound.\n\nstruct MyNewExtension <: EAGO.ExtensionType end\nimport EAGO: optimize_hook!\nfunction EAGO.optimize_hook!(t::MyNewExtension, m::Optimizer)\n    initial_parse!(m)\n    optimize!(EAGO.MINCVX(), m)\nend\n\nThe same functionality could be accomplished by setting the EAGOParameter field force_global_solve to be true.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.is_integer_subproblem-Tuple{Any}","page":"EAGO's Branch and Bound Routine","title":"EAGO.is_integer_subproblem","text":"is_integer_subproblem(m)\n\n\nReturns true that the subproblem at the current node n has participating integer variables that have not been fixed to constant valued as the branch-and-bound algorithm progresses. Returns false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.is_integer_feasible_local-Tuple{GlobalOptimizer, Any}","page":"EAGO's Branch and Bound Routine","title":"EAGO.is_integer_feasible_local","text":"is_integer_feasible_local(m::GlobalOptimizer, d) -> Bool\n\n\nChecks that the solution of a local solve is integer feasible to within the tolerances specified by integer_abs_tol and integer_rel_tol.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.is_integer_feasible_relaxed-Tuple{GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.is_integer_feasible_relaxed","text":"is_integer_feasible_relaxed(m::GlobalOptimizer) -> Bool\n\n\nCheck that the solution of the lower (relaxed problem) is integer feasible to within tolerances specified by the parameters: integer_abs_tol (absolute tolerance) and integer_rel_tol (relative tolerance).\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.interval_bound","page":"EAGO's Branch and Bound Routine","title":"EAGO.interval_bound","text":"interval_bound(::GlobalOptimizer, ::T)\n\nCompute a tuple representing the lower and upper interval bounds for an AbstractEAGOConstraint representing an equality constraint.\n\nOptions for T (all are subtypes of AbstractEAGOConstraint):\n\nAffineFunctionEq\nAffineFunctionIneq\nBufferedQuadraticEq\nBufferedQuadraticIneq\nBufferedNonlinearFunction{V,N,T} where {V,N,T}\n\n\n\n\n\n","category":"function"},{"location":"optimizer/bnb_back/#EAGO.lower_interval_bound","page":"EAGO's Branch and Bound Routine","title":"EAGO.lower_interval_bound","text":"lower_interval_bound(::GlobalOptimizer, ::T)\n\nCompute the lower interval bound for an AbstractEAGOConstraint representing an inequality constraint.\n\nOptions for T (all are subtypes of AbstractEAGOConstraint):\n\nAffineFunctionIneq\nBufferedQuadraticIneq\nBufferedSOC\nBufferedNonlinearFunction{V,N,T} where {V,N,T}\n\n\n\n\n\n","category":"function"},{"location":"optimizer/bnb_back/#EAGO.same_box-Tuple{NodeBB, NodeBB, Float64}","page":"EAGO's Branch and Bound Routine","title":"EAGO.same_box","text":"same_box(x::NodeBB, y::NodeBB, r::Float64) -> Bool\n\n\nCheck that node x and y have equal domains within an absolute tolerance of r.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.solve_local_nlp!-Tuple{Optimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.solve_local_nlp!","text":"Constructs and solves the problem locally on node y updated the upper solution informaton in the optimizer.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.set_dual!-Tuple{Optimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.set_dual!","text":"set_dual!(m)\n\n\nRetrieves the lower and upper duals for variable bounds from the relaxed_optimizer and sets the appropriate values in the _lower_lvd and _lower_uvd storage fields.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.update_relaxed_problem_box!","page":"EAGO's Branch and Bound Routine","title":"EAGO.update_relaxed_problem_box!","text":"update_relaxed_problem_box!(m)\n\n\nUpdate the relaxed constraint by setting the constraint set of v == x* , xL_i <= x_i, and x_i <= xU_i for each such constraint added to the relaxed optimizer. Resets integral valued constraints to either EqualTo or Interval  constraints.\n\n\n\n\n\n","category":"function"},{"location":"optimizer/bnb_back/#EAGO.reform_epigraph_min!-Tuple{GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.reform_epigraph_min!","text":"reform_epigraph_min!(m::GlobalOptimizer)\n\n\nPerform an epigraph reformulation assuming the working_problem is a minimization problem.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.label_fixed_variables!-Tuple{GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.label_fixed_variables!","text":"label_fixed_variables!(m::GlobalOptimizer) -> Vector{Bool}\n\n\nDetect any variables set to a fixed value by equality or inequality constraints and populate the _fixed_variable storage array.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.label_branch_variables!-Tuple{GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.label_branch_variables!","text":"label_branch_variables!(m::GlobalOptimizer)\n\n\nDetect any variables participating in nonconvex terms and populate the _branch_variables storage array.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.add_nonlinear!-Tuple{GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.add_nonlinear!","text":"add_nonlinear!(m::GlobalOptimizer)\n\n\nAdd an Evaluator and nonlinear functions and populate each appropriately.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.parse_classify_problem!-Tuple{GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.parse_classify_problem!","text":"parse_classify_problem!(m::GlobalOptimizer)\n\nInterprets the type/number of constraints and the type of objective function to infer a problem type. Current possible types include:\n\nLP: Linear program; sent to optimize_lp.jl\n'MILP: Mixed integer linear program; sent tooptimize_lp.jl`\nSOCP: Second-order cone program; sent to optimize_conic.jl\nMINCVX: Mixed-integer nonconvex; sent to optimize_nonconvex.jl\n\nIf the force_global_solve parameter is set to true, parse_classify_problem! will set the problem type to MINCVX to pass the problem to optimize_nonconvex.jl.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.local_problem_status-Tuple{MathOptInterface.TerminationStatusCode, MathOptInterface.ResultStatusCode}","page":"EAGO's Branch and Bound Routine","title":"EAGO.local_problem_status","text":"local_problem_status(t, r)\n\n\nTakes an MOI.TerminationStatusCode and a MOI.ResultStatusCode and returns true if this corresponds to a solution that is proven to be feasible. Returns false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.print_iteration!","page":"EAGO's Branch and Bound Routine","title":"EAGO.print_iteration!","text":"print_iteration!\n\nPrint status information based on iteration count. The header print frequency is based on the header_iterations setting, and the data print frequency is based on the output_iterations setting.\n\n\n\n\n\n","category":"function"},{"location":"optimizer/bnb_back/#EAGO.print_node!","page":"EAGO's Branch and Bound Routine","title":"EAGO.print_node!","text":"print_node!\n\nPrint information about the current node. Includes node ID, lower bound, upper bound, and interval box.\n\n\n\n\n\n","category":"function"},{"location":"optimizer/bnb_back/#EAGO.print_results!","page":"EAGO's Branch and Bound Routine","title":"EAGO.print_results!","text":"print_results!(m::GlobalOptimizer, lower_flag::Bool)\n\n\nPrint the results of a single (lower or upper) bounding problem. lower_flag=true prints information for the lower problem, lower_flag=false prints information for the upper problem.\n\n\n\n\n\n","category":"function"},{"location":"optimizer/bnb_back/#EAGO.print_solution!","page":"EAGO's Branch and Bound Routine","title":"EAGO.print_solution!","text":"print_solution!\n\nPrint solution information for the B&B problem. Display node with the best solution, solution value, solution, and time spent solving subproblems. This print occurs following termination of the B&B algorithm.\n\n\n\n\n\n","category":"function"},{"location":"optimizer/bnb_back/#EAGO.Log","page":"EAGO's Branch and Bound Routine","title":"EAGO.Log","text":"mutable struct Log\n\nA structure used to store information on the history of the solution procedure for generating convergence plots and other analyses.\n\ncurrent_lower_bound::Vector{Float64}: Storage for lower bound calculated for current node.\ncurrent_upper_bound::Vector{Float64}: Storage for upper bound calculated for current node.\npreprocessing_time::Vector{Float64}: Storage for preprocessing time of each iteration.\nlower_problem_time::Vector{Float64}: Storage for lower bounding time of each iteration.\nupper_problem_time::Vector{Float64}: Storage for upper bounding time of each iteration.\npostprocessing_time::Vector{Float64}: Storage for postprocessing time of each iteration.\npreprocessing_feas::Vector{Bool}: Storage for preprocessing feasibility of each iteration.\nlower_problem_feas::Vector{Bool}: Storage for lower bounding feasibility of each iteration.\nupper_problem_feas::Vector{Bool}: Storage for upper bounding feasibility of each iteration.\npostprocessing_feas::Vector{Bool}: Storage for postprocessing feasibility of each iteration.\nglobal_lower_bound::Vector{Float64}: Storage for best (global) lower bound at each iteration.\nglobal_upper_bound::Vector{Float64}: Storage for best (global) upper bound at each iteration.\nnode_count::Vector{Int64}: Number of nodes at each iteration.\nrun_time::Vector{Float64}: Run time at each iteration.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.log_iteration!-Tuple{GlobalOptimizer}","page":"EAGO's Branch and Bound Routine","title":"EAGO.log_iteration!","text":"log_iteration!(m::GlobalOptimizer)\n\n\nIf log_on is true, the global_lower_bound, global_upper_bound, run_time, and node_count are stored every log_interval. If log_subproblem_info then the lower bound, feasibility and run times of the subproblems are logged every log_interval.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/bnb_back/#EAGO.AbstractEAGOConstraint","page":"EAGO's Branch and Bound Routine","title":"EAGO.AbstractEAGOConstraint","text":"abstract type AbstractEAGOConstraint\n\nAn abstract super-type used for representing constraints built by EAGO's backend.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.AffineFunctionEq","page":"EAGO's Branch and Bound Routine","title":"EAGO.AffineFunctionEq","text":"mutable struct AffineFunctionEq <: EAGO.AbstractEAGOConstraint\n\nRepresentation of an affine equality. Currently only used for bound tightening.\n\nterms::Vector{Tuple{Float64, Int64}}\nconstant::Float64\nlen::Int64\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.AffineFunctionIneq","page":"EAGO's Branch and Bound Routine","title":"EAGO.AffineFunctionIneq","text":"mutable struct AffineFunctionIneq <: EAGO.AbstractEAGOConstraint\n\nRepresentation of an affine inequality. Currently only used for bound tightening.\n\nterms::Vector{Tuple{Float64, Int64}}\nconstant::Float64\nlen::Int64\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.BufferedQuadraticIneq","page":"EAGO's Branch and Bound Routine","title":"EAGO.BufferedQuadraticIneq","text":"mutable struct BufferedQuadraticIneq <: EAGO.AbstractEAGOConstraint\n\nRepresentation of a general quadratic inequality constraint with a buffer.\n\nfunc::MathOptInterface.ScalarQuadraticFunction{Float64}\nbuffer::Dict{Int64, Float64}\nsaf::MathOptInterface.ScalarAffineFunction{Float64}\nlen::Int64\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.BufferedQuadraticEq","page":"EAGO's Branch and Bound Routine","title":"EAGO.BufferedQuadraticEq","text":"mutable struct BufferedQuadraticEq <: EAGO.AbstractEAGOConstraint\n\nRepresentation of a general quadratic equality constraint with a buffer.\n\nfunc::MathOptInterface.ScalarQuadraticFunction{Float64}\nminus_func::MathOptInterface.ScalarQuadraticFunction{Float64}\nbuffer::Dict{Int64, Float64}\nsaf::MathOptInterface.ScalarAffineFunction{Float64}\nlen::Int64\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.NonlinearExpression","page":"EAGO's Branch and Bound Routine","title":"EAGO.NonlinearExpression","text":"mutable struct NonlinearExpression{V, N, T<:RelaxTag} <: EAGO.AbstractEAGOConstraint\n\nStores a general quadratic function with a buffer.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/bnb_back/#EAGO.BufferedNonlinearFunction","page":"EAGO's Branch and Bound Routine","title":"EAGO.BufferedNonlinearFunction","text":"mutable struct BufferedNonlinearFunction{V, N, T<:RelaxTag} <: EAGO.AbstractEAGOConstraint\n\nStores a general nonlinear function with a buffer represented by the sum of a tape and a scalar affine function.\n\n\n\n\n\n","category":"type"},{"location":"custom_guidelines/#Customization-Guidelines","page":"Customization","title":"Customization Guidelines","text":"This section contains general guidelines on how the functionality of EAGO can be extended for specific use cases. Many functions in EAGO are extensible, so examples are not provided for every possible case, but some important functions are covered. If there is a use case you do not see provided here, but would like to see, please contact Robert Gottlieb.","category":"section"},{"location":"custom_guidelines/#1)-Creating-an-Extension","page":"Customization","title":"1) Creating an Extension","text":"Extensibility in EAGO is based on the ExtensionType. To create customized functions, the recommended method is to create a new structure, as follows:\n\nusing EAGO\n\nstruct MyNewStruct <: EAGO.ExtensionType end\n\nTo let EAGO know that you would like to use this extension (and any functions you overload), when you create the JuMP model, declare your new type in the subsolver_block field of the Optimizer as follows:\n\nusing JuMP\n\nfactory = () -> EAGO.Optimizer(SubSolvers(; t = MyNewStruct() ))\nmodel = Model(factory)\n\nThe key point to note here is that the new structure is set to SubSolvers.t, which is the field that holds any user-defined extension type. Now, when EAGO calls any of its functions, it will check to see if a custom function for this new extension has been created. If so, it will use the new one; if not, it will use the default version of that function.","category":"section"},{"location":"custom_guidelines/#2)-Preprocessing","page":"Customization","title":"2) Preprocessing","text":"In EAGO's branch-and-bound routine, preprocessing is performed prior to solving the lower and upper problems. By default, linear and quadratic contractor methods are performed, followed by interval constraint propagation, then optimization-based bounds tightening. An important outcome of EAGO's default preprocessing is that the _preprocess_feasibility field of the GlobalOptimizer is set to true, unless the subproblem at the current node has been proven infeasible. Therefore, to bypass preprocessing for your own problem, you must, at a minimum, set this field to true. For example:\n\nimport EAGO: preprocess!\nfunction EAGO.preprocess!(t::MyNewStruct, x::EAGO.GlobalOptimizer)\n    x._preprocess_feasibility = true\nend\n\nThe user-defined preprocessing step can be as simple or complex as desired, but if _preprocess_feasibility is not set to true, EAGO will assume each node is infeasible.","category":"section"},{"location":"custom_guidelines/#3)-Lower-Problem","page":"Customization","title":"3) Lower Problem","text":"By default, EAGO applies Kelley's cutting-plane algorithm [1] to solve the lower-problem. This can be overloaded using the same syntax as for the other functions. Necessary changes to the GlobalOptimizer that occur within the lower problem are changing the _lower_objective_value and _lower_feasibility fields. If the _lower_objective_value field is not changed, branch-and-bound will not update the lower bound. If _lower_feasibility is not set to true, the node will be discarded as infeasible. A minimum functional (though not useful) lower problem extension is as follows:\n\nimport EAGO: lower_problem!\nfunction EAGO.lower_problem!(t::MyNewStruct, x::EAGO.GlobalOptimizer)\n    x._lower_objective_value = -Inf\n    x._lower_feasibility = true\nend\n\nAny arbitrarily complex lower problem can be substituted here in place of EAGO's default method, as long as these fields are updated. Note also that, although there is a separate upper problem function, if the lower problem is being replaced by an algorithm that also calculates an upper objective value, the necessary fields to update in upper_problem! can simply be updated here, and the upper_problem! can be overloaded by a function that does nothing.","category":"section"},{"location":"custom_guidelines/#4)-Upper-Problem","page":"Customization","title":"4) Upper Problem","text":"By default, the upper-bounding problem is run on every node up to depth upper_bounding_depth, and is triggered with a probability of 0.5^(depth - upper_bounding_depth) afterwards for continuous problems. For integer problems, this approach is used in addition to running on every node up to depth upper_bounding_depth + cont_depth, with another trigger of probability 0.5^(depth - upper_bounding_depth - cont_depth). The upper_bounding_depth and cont_depth are fields of EAGOParameters and can be changed from their default values when the JuMP model is created, or at any time afterwards. If any of these trigger conditions are met, the default EAGO upper problem runs a local NLP solve. \n\nThe important fields to update in the upper_problem! are the _upper_objective_value and _upper_feasibility fields. If _upper_objective_value is not updated, the upper bound in the branch-and-bound algorithm will not update and the problem will not converge. If _upper_feasibility is not set to true, then any changes made to _upper_objective_value will not be updated for each node and the problem will not converge. A minimum functional (though not useful) upper problem extension is as follows:\n\nimport EAGO: upper_problem!\nfunction upper_problem!(t::MyNewStruct, x::EAGO.GlobalOptimizer)\n    x._upper_objective_value = Inf\n    x._upper_feasibility = true\nend\n\nThis example upper problem will set the upper bound on the objective value to Inf for each node. Given that no useful information is provided here, we could also have set x_upper_feasibility to false (or equivalently, remove the line where we set it to true), and the global upper bound would never be updated.\n\nNote that if the _upper_objective_value is changed elsewhere, such as in the definition for the lower_problem!, the _upper_feasibility flag must be set to true. If this is not done, the change to the _upper_objective_value will be discarded.","category":"section"},{"location":"custom_guidelines/#5)-Convergence-Check","page":"Customization","title":"5) Convergence Check","text":"By default, EAGO checks to see if the lower and upper bounds have converged to within either the absolute or relative tolerance. This method of checking convergence may not be desired if, for example, only the absolute tolerance is relevant, and you want to ensure that the program does not end prematurely due to a relative tolerance limit being reached. The fields to check are _lower_objective_value and _upper_objective_value for the best-identified global lower and upper bounds, respectively. This function should return true if the lower and upper bounds have converged, and false otherwise. An example of how to specify that the convergence check only use the absolute tolerance is as follows:\n\nimport EAGO: convergence_check\nfunction EAGO.convergence_check(t::MyNewStruct, x::EAGO.GlobalOptimizer)\n    gap = (x._upper_objective_value - x._lower_objective_value)\n    return (gap <= x._parameters.absolute_tolerance)\nend","category":"section"},{"location":"custom_guidelines/#6)-Postprocessing","page":"Customization","title":"6) Postprocessing","text":"Postprocessing is the final step before a node is branched on. By default, EAGO performs duality-based bounds tightening [2] up to an iteration limit set by dbbt_depth in the EAGOParameters field. The important field to update in postprocessing is _postprocess_feasibility, which must be set to true for EAGO to branch on any given node. The minimum working postprocessing function is therefore:\n\nimport EAGO: postprocess!\nfunction EAGO.postprocess!(t::MyNewStruct, x::EAGO.GlobalOptimizer)\n    x._postprocess_feasibility = true\nend\n\nIf _postprocess_feasibility is not set to true, no nodes will be branched on.","category":"section"},{"location":"custom_guidelines/#7)-Termination-Check","page":"Customization","title":"7) Termination Check","text":"This is the check that occurs on each iteration of the branch-and-bound algorithm that determines whether the algorithm continues or not. By default, several conditions are checked for such as the satisfaction of absolute or relative tolerances, solution infeasibility, or other specified limits. This function returns true if any of the stopping conditions have been met, and  branch-and-bound should stop, and false otherwise. The important fields to update are _end_state, which takes values of EAGO.GlobalEndState, _termination_status_code, which takes values of MOI.TerminationStatusCode, and _result_status_code, which takes values of MOI.ResultStatusCode. Combined, these fields provide information about the branch-and-bound completion status and result feasibility. \n\nAs an example, suppose we have updated the convergence_check function to only check for absolute tolerance, and based on our knowledge of the problem, this is the only condition we care about, and we know the solution will be optimal. We could then overload the termination_check function as follows:\n\nimport EAGO: termination_check\nfunction EAGO.termination_check(t::MyNewStruct, x::EAGO.GlobalOptimizer)\n    flag = EAGO.convergence_check(t, x)\n    if flag\n        x._end_state = EAGO.GS_OPTIMAL\n        x._termination_status_code = MathOptInterface.OPTIMAL\n        x._result_status_code = MathOptInterface.FEASIBLE_POINT\n    end\n    return flag\nend","category":"section"},{"location":"custom_guidelines/#References","page":"Customization","title":"References","text":"Kelley, J. E. “The Cutting-Plane Method for Solving Convex Programs.” Journal of the Society for Industrial and Applied Mathematics, vol. 8, no. 4, pp. 703–12 (1960). \nTawarmalani, M., Sahinidis, N. V. \"Global optimization of mixed-integer nonlinear programs: A theoretical and computational study.\" Math. Program., Ser. A, 99, pp. 563-591 (2004).","category":"section"},{"location":"optimizer/high_performance/#High-Performance-Configuration","page":"High-Performance Configuration","title":"High-Performance Configuration","text":"","category":"section"},{"location":"optimizer/high_performance/#Linear-Programming-Solver-Selection","page":"High-Performance Configuration","title":"Linear Programming Solver Selection","text":"By default, EAGO uses GLPK for solving linear subproblems introduced. Using a commercial linear programming (LP) solver is highly recommended, such as Gurobi, CPLEX, or XPRESS. Both Gurobi and CPLEX are free for academics and installation information can be found on the Gurobi website and the IBM website, respectively.\n\nA non-default LP solver can then be selected by the user via a series of keyword argument inputs as illustrated in the code snippet below. The relaxed_optimizer contains an instance optimizer with valid relaxations that are made at the root node and is updated with affine relaxations in place.\n\n# Create opt EAGO Optimizer with Gurobi as a lower subsolver\neago_factory = () -> EAGO.Optimizer(SubSolvers(; r = Gurobi.Optimizer()))\nm = Model(eago_factory)","category":"section"},{"location":"optimizer/high_performance/#Rounding-Mode","page":"High-Performance Configuration","title":"Rounding Mode","text":"The IntervalArithmetic.jl package supports a number of different directed rounding modes. The default directed rounding mode is :tight. It is recommended that the user specify that :accurate directed rounding mode be used as it may results in a significant performance improvement. Setting a rounding mode can requires the redefinition of a number of functions. As a result, this should only be done at the top-level by the user (rather than by using keyword arguments). To set the rounding mode to :accurate using the following syntax when loading the EAGO package initially:\n\nusing IntervalArithmetic; setrounding(Interval, :accurate)\nusing EAGO\n# REST OF CODE","category":"section"},{"location":"optimizer/high_performance/#Ipopt-Build","page":"High-Performance Configuration","title":"Ipopt Build","text":"Ipopt is the recommended solver for upper-bounding problems. Ipopt's performance is highly dependent on the linear algebra package used (up to 30x). By default MUMPS is used. It is recommended that you either compile Ipopt with HSL MA57 or the Pardiso linear algebra packages with a machine specific Blas library (for Intel users the JuliaPro MKL version is recommended). For information on this, see the links below:\n\nCompiling Ipopt\nJulia specifics:\nPointing Ipopt to a compiled version:\nIpopt Package Info\nDiscourse discussion\nIssues using Pardiso:\nUbuntu\nWindows\nHSL website\nPardiso website","category":"section"},{"location":"dev/future/#Future-Work","page":"Future Work","title":"Future Work","text":"","category":"section"},{"location":"dev/future/#Current-Activity","page":"Future Work","title":"Current Activity","text":"Update CI testing.\nSpecialized algorithms for relaxing ODE constrained problems and solving global and robust optimization problems.\nExtensions for nonconvex dynamic global & robust optimization.\nProvide support for mixed-integer problems.\nUpdate EAGO to support nonsmooth problems (requires: a nonsmooth local nlp optimizer or lexicographic AD, support for relaxations is already included).\nEvaluation and incorporation of implicit relaxation routines in basic solver.","category":"section"},{"location":"dev/future/#Other-Things-on-the-Wishlist-(But-Not-Actively-Being-Worked-On)","page":"Future Work","title":"Other Things on the Wishlist (But Not Actively Being Worked On)","text":"Implement the interval constraint propagation scheme presented in Vu 2008. For improved convergences.\nA parametric bisection routine will be updated that can divide the (X P) space into a series of boxes that all contain unique branches of the implicit function p - y(p).\nProvide a better interface the nonconvex semi-infinite programs solvers (JuMPeR extension?).\nAdd additional McCormick relaxations.\nAdd handling for domain reduction of special expression forms.","category":"section"},{"location":"examples/explicit_ann/#Standard-Use-Example-1","page":"Standard-Use Example 1","title":"Standard-Use Example 1","text":"This example is also provided here as a Jupyter Notebook.","category":"section"},{"location":"examples/explicit_ann/#Solving-an-ANN-to-Optimality-in-EAGO","page":"Standard-Use Example 1","title":"Solving an ANN to Optimality in EAGO","text":"In [1, 2], a surrogate artificial neural network (ANN) model of bioreactor productivity was constructed by fitting results from computationally expensive computational fluid dynamics (CFD) simulations. The authors then optimized this surrogate model to obtain ideal processing conditions. The optimization problem is given by:\n\nbeginaligned\nmax_mathbf x in X B_2 + sum_r = 1^3 W_2r frac21 + exp (-2y_r + B_1r)   rm where   y_r = sum_i = 1^8 W_1ir x_i\nendaligned","category":"section"},{"location":"examples/explicit_ann/#Input-Parameters","page":"Standard-Use Example 1","title":"Input Parameters","text":"In the first block, we input parameters values supplied in the paper for W_1, W_2, B_1, and B_2 into Julia as simple array objects. We also input bounds for the variables which are used to scale the values obtained from optimization from -1 1 back into the design values.\n\nusing JuMP, EAGO\n\n# Weights associated with the hidden layer\nW1 = [0.54, -1.97, 0.09, -2.14, 1.01, -0.58, 0.45, 0.26;\n      -0.81, -0.74, 0.63, -1.60, -0.56, -1.05, 1.23, 0.93;\n      -0.11, -0.38, -1.19, 0.43, 1.21, 2.78, -0.06, 0.40]\n\n# Weights associated with the output layer\nW2 = [-0.91, 0.11, 0.52]\n\n# Bias associated with the hidden layer\nB1 = [-2.698, 0.012, 2.926]\n\n# Bias associated with the output layer\nB2 = -0.46\n\n# Variable bounds (Used to scale variables after optimization)\nxLBD = [0.623, 0.093, 0.259, 6.56, 1114.0, 0.013, 0.127, 0.004]\nxUBD = [5.89, 0.5, 1.0, 90.0, 25000.0, 0.149, 0.889, 0.049]","category":"section"},{"location":"examples/explicit_ann/#Construct-the-JuMP-Model-and-Optimize","page":"Standard-Use Example 1","title":"Construct the JuMP Model and Optimize","text":"We now formulate the problem using standard JuMP [3] syntax and optimize it. Note that we are using the @NLexpression macro to handle the summation term to keep the code visually simple, but this could be placed directly in the @NLobjective macro instead.\n\n# Model construction\nmodel = Model(optimizer_with_attributes(EAGO.Optimizer, \"absolute_tolerance\" => 0.001))\n@variable(model, -1.0 <= x[i=1:8] <= 1.0)\n@NLexpression(model, y[r=1:3], sum(W1[r,i]*x[i] for i in 1:8))\n@NLobjective(model, Max, B2 + sum(W2[r]*(2.0/(1 + exp(-2.0*y[r] + B1[r]))) for r=1:3))\n\n# Solve the model\noptimize!(model)","category":"section"},{"location":"examples/explicit_ann/#Retrieve-Results","page":"Standard-Use Example 1","title":"Retrieve Results","text":"We then recover the objective value, the solution values, and termination status codes using standard JuMP syntax. The optimal value and solution values are then rescaled using the variable bounds to obtain their physical interpretations.\n\n# Access calculated values\nfval = JuMP.objective_value(model)\nxsol = JuMP.value.(x)\nstatus_term = JuMP.termination_status(model)\nstatus_prim = JuMP.primal_status(model)\nprintln(\"EAGO terminated with a status of $status_term and a result code of $status_prim.\")\nprintln(\"The optimal value is: $(round(fval, digits=5)).\")\nprintln(\"The solution found is $(round.(xsol, digits=3)).\")\nprintln(\" \")\n\n# Rescale values back to physical space\nrescaled_fval = ((fval + 1.0)/2.0)*0.07\nrescaled_xsol = ((xsol .+ 1.0)./2.0).*(xUBD - xLBD) .+ xLBD\nprintln(\"Rescaled optimal value and solution values:\")\nprintln(\"The rescaled optimal value is: $(round(rescaled_fval, digits=4))\")\nprintln(\"The rescaled solution is $(round.(rescaled_xsol, digits=3)).\")","category":"section"},{"location":"examples/explicit_ann/#References","page":"Standard-Use Example 1","title":"References","text":"J. D. Smith, A. A. Neto, S. Cremaschi, and D. W. Crunkleton, CFD-based optimization of a flooded bed algae bioreactor, Industrial & Engineering Chemistry Research, 52 (2012), pp. 7181–7188.\nA. M. Schweidtmann and A. Mitsos. Global Deterministic Optimization with Artificial Neural Networks Embedded https://arxiv.org/pdf/1801.07114.pdf.\nIain Dunning and Joey Huchette and Miles Lubin. JuMP: A Modeling Language for Mathematical Optimization, SIAM Review, 59 (2017), pp. 295-320.","category":"section"},{"location":"news/#News-for-EAGO-Releases","page":"News","title":"News for EAGO Releases","text":"","category":"section"},{"location":"news/#[v0.8.4](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.8.4)-(December-18,-2025)","page":"News","title":"v0.8.4 (December 18, 2025)","text":"Switched from Cbc to GLPK as the default relaxed optimizer.\nAdded an EAGO parameter fbbt_tolerance for FBBT to consider lower and upper bounds equal which defaults to 1E-8.","category":"section"},{"location":"news/#[v0.8.3](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.8.3)-(May-1,-2025)","page":"News","title":"v0.8.3 (May 1, 2025)","text":"Added support for MOI.UserDefinedFunction.\nUpdated bounds in unbounded_check from +/- 1E10 to +/- 1E6.\nBumped requirement for Ipopt.jl to 1.10 for type stability: https://github.com/jump-dev/Ipopt.jl?tab=readme-ov-file#type-stability.\nUpdated display.","category":"section"},{"location":"news/#[v0.8.2](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.8.2)-(October-27,-2024)","page":"News","title":"v0.8.2 (October 27, 2024)","text":"Added support for MOI.ScalarNonlinearFunction.\nUsers can now define all constraints using @constraint instead of needing to use @NLconstraint. This applies to @objective as well.\nAdded support for variable names.\nUpdated display.","category":"section"},{"location":"news/#[v0.8.1](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.8.1)-(June-15,-2023)","page":"News","title":"v0.8.1 (June 15, 2023)","text":"Resolved an issue where integer and binary variables would sometimes throw a MathOptInterface.UpperBoundAlreadySet error.\nAdded the function unbounded_check! which warns users if they are missing variable bounds and sets them to +/- 1E10 by default.\nAdded an EAGO parameter unbounded_check which defaults to true and enables unbounded_check!.\nBumped requirement for PrettyTables.jl to v2+ to accommodate the latest version of DataFrames.jl.","category":"section"},{"location":"news/#[v0.8.0](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.8.0)-(June-12,-2023)","page":"News","title":"v0.8.0 (June 12, 2023)","text":"Updated EAGO for compatibility with the nonlinear expression API changes introduced in JuMP v1.2: https://discourse.julialang.org/t/ann-upcoming-refactoring-of-jumps-nonlinear-api/83052.\nEAGO now uses the MOI.Nonlinear submodule instead of JuMP._Derivatives.\nModels, nodes, expressions, constraints, and operators are now compatible with MOI.\nAdded logic and comparison operators to EAGO.OperatorRegistry.","category":"section"},{"location":"news/#[v0.7.3](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.7.3)-(April-11,-2023)","page":"News","title":"v0.7.3 (April 11, 2023)","text":"Bumped DocStringExtensions.jl compatibility.","category":"section"},{"location":"news/#[v0.7.2](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.7.2)-(November-22,-2022)","page":"News","title":"v0.7.2 (November 22, 2022)","text":"Added support for Julia 1.7.\nBumped NaNMath.jl compatibility.\nAdded help? information for various functions and structures.\nUpdated documentation and some formatting.","category":"section"},{"location":"news/#[v0.7.1](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.7.1)-(June-26,-2022)","page":"News","title":"v0.7.1 (June 26, 2022)","text":"Added the function print_problem_summary, an internal script used to display all constraints, objectives in a linear program which is added to functions for debug purposes while writing code.\nAdjusted default EAGOParameters.\nbranch_cvx_factor: 0.5 => 0.25\nbranch_offset: 0.2 => 0.15\ntime_limit and _time_left: 1000.0 => 3600.0\nobbt_depth: 0 => 6\nobbt_repetitions: 1 => 3\ncut_tolerance_rel: 1E-2 => 1E-3\nAdjusted Ipopt.Optimizer attributes.\nmax_iter: 20000 => 10000\nacceptable_iter: 10000 => 1000\nExcluded test_quadratic_nonconvex_constraint_basic from MOI tests.\nRestricted JuMP compatibility to 1.0.0 - 1.1.1.","category":"section"},{"location":"news/#[v0.7.0](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.7.0)-(March-28,-2022)","page":"News","title":"v0.7.0 (March 28, 2022)","text":"Added envelopes of activation functions: xabsx, logcosh\nAdded variations of estimator_extrema, estimator_under, and estimator_over functions to EAGO for bilinear relaxations.\nMoved various functions and related structures to new files.\nAdded RelaxCache structure to hold relaxed problem information.\nUpdated forward and reverse propagation.\nAdded PrettyTables.jl.\nAdded test examples.\nAdded a memory allocation analysis.\nUpdated documentation.","category":"section"},{"location":"news/#[v0.6.1](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.6.1)-(March-4,-2021)","page":"News","title":"v0.6.1 (March 4, 2021)","text":"Minor update to tests.","category":"section"},{"location":"news/#[v0.6.0](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.6.0)-(February-19,-2021)","page":"News","title":"v0.6.0 (February 19, 2021)","text":"License changed from CC BY-NC-SA 4.0 to MIT.\nFix deprecated Ipopt constructor.\nFix discrepancy between the returned objective value and the objective evaluated at the solution.\nDramatically decrease allocates and first-run performance of SIP routines.\nAdd two algorithms which modify SIPRes detailed in Djelassi, H. and Mitsos A. 2017.\nFix objective interval fallback function.\nNew SIP interface with extendable subroutines.\nFix x^y relaxation bug.\nAdd issues template.\nAdd SIP subroutine documentation.","category":"section"},{"location":"news/#[v0.5.2](https://github.com/PSORLab/EAGO.jl/commit/bc59c5a8a5e26960c159e06e7b26e2e5c2472956)-(November-18,-2020)","page":"News","title":"v0.5.2 (November 18, 2020)","text":"Fix user specified branching variables.","category":"section"},{"location":"news/#[v0.5.1](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.5.1)-(November-18,-2020)","page":"News","title":"v0.5.1 (November 18, 2020)","text":"Support for Julia ~1 (with limited functionality for Julia 1.0 and 1.1).","category":"section"},{"location":"news/#[v0.5.0](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.5.0)-(November-18,-2020)","page":"News","title":"v0.5.0 (November 18, 2020)","text":"Introduces the register_eago_operators!(m::JuMP.Model) which can be used to register all nonstandard nonlinear terms used in EAGO in any JuMP model.\nIntroduces positive, negative, lower_bnd, upper_bnd, and bnd functions which can be used to enforce bounds on intermediate terms in nonlinear expressions (EAGO.Optimizer only).\nAdds envelopes: abs2, sinpi, cospi, fma, cbrt\nAdds envelopes and functions: xlogx\nAdds envelopes of special functions: erf, erfc, erfinv, erfcinv\nAdds envelopes of activation functions: relu, gelu, elu, selu, swish, sigmoid, softsign, softplus, bisigmoid, pentanh, leaky_relu, param_relu\nError messages in sip_explicit have been made more transparent.\nFixes some issues with documentation image rendering and links.\nDrops appveyor CI and Travis CI in favor of GitHub Actions.","category":"section"},{"location":"news/#[v0.4.2](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.4.2)-(August-28,-2020)","page":"News","title":"v0.4.2 (August 28, 2020)","text":"Support for Julia 1.5.","category":"section"},{"location":"news/#[v0.4.1](https://github.com/PSORLab/EAGO.jl/commit/9c1bcf024a19840a0ac49c8c6da13619a5f3845f#comments)-(June-17,-2020)","page":"News","title":"v0.4.1 (June 17, 2020)","text":"Minor bug fixes.","category":"section"},{"location":"news/#[v0.4.0](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.4.0)-(June-12,-2020)","page":"News","title":"v0.4.0 (June 12, 2020)","text":"Support for new MOI/JuMP RawParameter input and a number of new attributes.\nSeparates McCormick and ReverseMcCormick libraries (now McCormick.jl and ReverseMcCormick.jl) from main package. McCormick.jl is reexported.\nRelaxation calculations now return NaN values on a domain violation.\nTolerance based validation of cuts has been added to generate numerically safe cuts.\nSignificantly simplify internal codebase for EAGO.Optimizer (no changes to API): fully decouples input problem specifications from the formulation used internally, stack only stores variables that are branched on, and a number of internal rearrangements to clearly delineate different routines.\nAdd problem classification preprocessing that throws to simpler routines if LP problem types are detected (enables future support for SOCP, MILP, MISOCP, and Convex forms).\nFix multiple bugs and add more transparent error codes.","category":"section"},{"location":"news/#[v0.3.1](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.3.1)-(January-29,-2020)","page":"News","title":"v0.3.1 (January 29, 2020)","text":"Add unit tests.\nSupport for Julia 1.3.\nFix IntervalContractors.jl dependency issue.","category":"section"},{"location":"news/#[v0.3.0](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.3.0)-(November-5,-2019)","page":"News","title":"v0.3.0 (November 5, 2019)","text":"This update is intended to be the last to create a large number of breaking changes to the EAGO API. Please review the use cases provided in the documentation to update examples.\n\nA number of performance improvements have been made to the underlying McCormick relaxation library.\nThe optimizer used to construct relaxations is now modified in place.\nAll subproblem storage has been moved to the Optimizer object and storage types (e.g. LowerInfo) have been removed.\nA BinaryMinMaxHeap structure is now used to store nodes.\nSpeed and aesthetics for logging and printing utilities have been updated.\nSubroutines are now customized by creating a subtype of ExtensionType and defining subroutines which dispatch on this new structure.\nParametric interval methods and the Implicit optimizer have been move to a separate package (to be tagged shortly).\nJIT compilation time has been reduced substantially.\nSupport for silent tag and time limits.","category":"section"},{"location":"news/#[v0.2.1](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.2.1)-(July-7,-2019)","page":"News","title":"v0.2.1 (July 7, 2019)","text":"Bug fix for explicit SIP solving routine that occurred for uncertainty sets of dimension greater than 1.\nBug fix for MOI.MAX_SENSE (max objective sense).","category":"section"},{"location":"news/#[v0.2.0](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.2.0)-(June-14,-2019)","page":"News","title":"v0.2.0 (June 14, 2019)","text":"This update creates a number of breaking changes to the EAGO API. Please review the use cases provided in the documentation to update examples.\n\nUpdated to support Julia 1.0+, MathOptInterface (MOI), and MOI construction of subproblems.\nAdditional domain reduction routines available.\nSupport for specialized handling of linear and quadratic terms.\nSignificant performance improvements due to pre-allocation of Wengert tapes and MOI support.\nA more intuitive API for McCormick relaxation construction.","category":"section"},{"location":"news/#[v0.1.2](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.1.2)-(June-20,-2018)","page":"News","title":"v0.1.2 (June 20, 2018)","text":"Significant speed and functionality updates.","category":"section"},{"location":"news/#[v0.1.1](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.1.1)-(June-7,-2018)","page":"News","title":"v0.1.1 (June 7, 2018)","text":"Initial release of combined EAGO packages.","category":"section"},{"location":"news/#[v0.1.0](https://github.com/PSORLab/EAGO.jl/releases/tag/v0.1.0)-(April-10,-2018)","page":"News","title":"v0.1.0 (April 10, 2018)","text":"Main global solver release.","category":"section"},{"location":"mccormick/overview/#Overview","page":"Overview","title":"Overview","text":"EAGO provides a library of McCormick relaxations in native Julia code. The EAGO optimizer supports relaxing functions using nonsmooth McCormick relaxations (Mitsos2009, Scott2011), smooth McCormick relaxations (Khan2016, Khan2018, Khan2019), and multi-variant McCormick relaxations (Tsoukalas2014; a variant of subgradient-based interval refinement (Najman2017)). For functions with arbitrarily differentiable relaxations, the differentiable constant μ can be modified by adjusting a constant value in the package. Additionally, validated and nonvalidated interval bounds are supported via IntervalArithmetic.jl which is reexported. The basic McCormick operator and reverse McCormick operator (Wechsung2015) libraries are included in two dependent subpackages which can loaded and used independently:\n\nMcCormick.jl: A forward McCormick operator library\nReverseMcCormick.jl: A reverse McCormick operator library","category":"section"},{"location":"mccormick/overview/#NaN-Numerics","page":"Overview","title":"NaN Numerics","text":"When a relaxation is computed at an undefined point or over an unbounded domain, the resulting relaxation is defined as \"not a number\" (NaN) rather than throwing an error. This allows algorithms to check for these cases without resorting to try-catch statements. Moreover, when the interval domain is extensive enough to cause a domain violation, an x::MC structure is returned that satisfies isnan(x) === true.","category":"section"},{"location":"mccormick/overview/#References","page":"Overview","title":"References","text":"Khan KA, Watson HAJ, Barton PI (2017). Differentiable McCormick relaxations. Journal of Global Optimization, 67(4): 687-729.\nKhan KA, Wilhelm ME, Stuber MD, Cao H, Watson HAJ, Barton PI (2018). Corrections to: Differentiable McCormick relaxations. Journal of Global Optimization, 70(3): 705-706.\nKhan KA (2019). Whitney differentiability of optimal-value functions for bound-constrained convex programming problems. Optimization, 68(2-3): 691-711\nMitsos A, Chachuat B, and Barton PI. (2009). McCormick-based relaxations of algorithms. SIAM Journal on Optimization, 20(2): 573–601.\nNajman J, Bongratz D, Tsoukalas A, and Mitsos A (2017). Erratum to: Multivariate McCormick relaxations. Journal of Global Optimization, 68: 219-225.\nScott JK,  Stuber MD, and Barton PI. (2011). Generalized McCormick relaxations. Journal of Global Optimization, 51(4): 569–606.\nStuber MD, Scott JK, Barton PI (2015). Convex and concave relaxations of implicit functions. Optim. Methods Softw., 30(3): 424–460\nTsoukalas A and Mitsos A (2014). Multivariate McCormick Relaxations. Journal of Global Optimization, 59: 633–662.\nWechsung A, Scott JK, Watson HAJ, and Barton PI. (2015). Reverse propagation of McCormick relaxations. Journal of Global Optimization, 63(1): 1-36.","category":"section"},{"location":"optimizer/optimizer/#EAGO-Optimizer","page":"EAGO Optimizer","title":"EAGO Optimizer","text":"The Optimizer object holds all algorithm solution information. A description of all user-facing options has been provided in the docstring.","category":"section"},{"location":"optimizer/optimizer/#EAGO.Optimizer","page":"EAGO Optimizer","title":"EAGO.Optimizer","text":"","category":"section"},{"location":"optimizer/optimizer/#EAGO-Specific-Functions-and-Operators","page":"EAGO Optimizer","title":"EAGO Specific Functions and Operators","text":"EAGO supports a number of functions and operators that for which specialized relaxation routines are available. These can be registered and added to a JuMP model using the function:","category":"section"},{"location":"optimizer/optimizer/#Storage-for-Input-Parameters","page":"EAGO Optimizer","title":"Storage for Input Parameters","text":"","category":"section"},{"location":"optimizer/optimizer/#Internal-Storage-Structures","page":"EAGO Optimizer","title":"Internal Storage Structures","text":"","category":"section"},{"location":"optimizer/optimizer/#Internal-Problem-Representations","page":"EAGO Optimizer","title":"Internal Problem Representations","text":"","category":"section"},{"location":"optimizer/optimizer/#Interval-Optimizer-Subroutines","page":"EAGO Optimizer","title":"Interval Optimizer Subroutines","text":"","category":"section"},{"location":"optimizer/optimizer/#Extending-EAGO","page":"EAGO Optimizer","title":"Extending EAGO","text":"Functionality has been included that allows for extensions to EAGO's Optimizer to be readily defined. This can be done in two ways first defining a new structure which is a subtype of ExtensionType and overloading methods associated with this new structure. An instance of this new structure is provided to the Optimizer using the ext_type keyword. This results in EAGO now dispatch to the new methods rather than the generally defined methods for the parent type. For a complete example, the reader is directed to the interval bounding example and the quasiconvex example. Alternatively, the user can overload the optimize_hook! for this subtype which will entirely circumvent the default global solution routine. Additional information can be stored in the ext field of the Optimizer. In order to allow for compatibility between packages the user is encouraged to append their extension name to the start of each variable name (e.g. newext_newdata).","category":"section"},{"location":"optimizer/optimizer/#EAGO.Optimizer","page":"EAGO Optimizer","title":"EAGO.Optimizer","text":"mutable struct Optimizer{Q, S, T} <: MathOptInterface.AbstractOptimizer\n\nThe highest level optimizer object used by EAGO to solve problems during the optimization routine. Additional options and temporary storage are located in the _global_optimizer::GlobalOptimizer{Q,S,T} field. Parameters which are expected to be constant over the entire solve are stored in the _parameters::EAGOParameters field.  Some user-facing keywords not in the EAGOParameters field include:\n\nrelaxed_optimizer::MOI.AbstractOptimizer: An instance of the optimizer used to solve    the relaxed subproblems (default = GLPK.Optimizer()). Located in subsolver_block::SubSolvers{Q,S,T}.\nupper_optimizer::MOI.AbstractOptimizer: Optimizer used to solve upper bounding problems    (default = Ipopt.Optimizer()). Located in subsolver_block::SubSolvers{Q,S,T}.\next::ExtensionType: Holds an instance of a subtype of EAGO.ExtensionType, used to define   new custom subroutines (default = DefaultExt()). Located in subsolver_block::SubSolvers{Q,S,T}.\nenable_optimize_hook::Bool: Specifies that the user-defined optimize_hook! function should   be called rather than use the standard EAGO optimization routines. Located in Optimizer   and _global_optimizer::GlobalOptimizer{Q,S,T}.\nobbt_variable_values::Vector{Bool}: Variables to perform OBBT on (default: all variables in nonlinear   expressions). Located in _global_optimizer::GlobalOptimizer{Q,S,T}.\n\nDescriptions of all Optimizer fields available in extended help.\n\nExtended Help\n\nsubsolver_block::SubSolvers{Q, S, T} where {Q, S, T}: Holds definitions of the relaxed and upper optimizers, as well as any user-defined extension types\nenable_optimize_hook::Bool: Specifies that the optimize_hook! function should be called rather than throw the     problem to the standard routine\next::Union{Nothing, T} where T: (Deprecated, use subsolver_block instead) Storage for custom extension types\n_auxiliary_variable_info::Union{Nothing, EAGO._AuxVarData}: Information on any auxiliary variables\n_global_optimizer::GlobalOptimizer{Q, S, T} where {Q, S, T}: Additional options and temporary storage for solving optimization problems\n_input_problem::InputProblem: Expressions and constraints added to the EAGO model (not directly     used for relaxations)\n_working_problem::ParsedProblem: Expressions and problem descriptions that EAGO uses to formulate     relaxed problems\n_parameters::EAGOParameters: Parameters that do not change during a global solve\n_optimizer_attributes_set::Vector{MathOptInterface.AbstractOptimizerAttribute}: Set of optimizer attributes\n_termination_status_code::MathOptInterface.TerminationStatusCode: The MathOptInterface-compliant completion status code\n_result_status_code::MathOptInterface.ResultStatusCode: Value indicating the feasibility status of the result\n_run_time::Float64: Optimization run time\n_objective_value::Float64: The objective value of the primal solution\n_objective_bound::Float64: The best-known bound on the optimal objective value\n_relative_gap::Float64: The gap between the upper and lower bound, relative to the bound with the larger magnitude\n_iteration_count::Int64: The number of iterations the branch-and-bound algorithm has completed\n_node_count::Int64: The number of nodes in the stack\n\n\n\n\n\n","category":"type"},{"location":"optimizer/optimizer/#EAGO.EAGOParameters","page":"EAGO Optimizer","title":"EAGO.EAGOParameters","text":"mutable struct EAGOParameters\n\nStorage for parameters that do not change during a global solve.\n\npresolve_scrubber_flag::Bool: Should EAGO attempt to remove type-assert issues for user-defined functions (default = false)\npresolve_to_JuMP_flag::Bool: Create and use DAG representations of user-defined functions (default = false)\npresolve_flatten_flag::Bool: Rerrange the DAG using registered transformations (default = false)\nconic_convert_quadratic::Bool: Attempt to bridge convex constraint to second-order cone (default = false)\nlog_on::Bool: Turn logging on; record global bounds, node count, and run time. Additional      options are available for recording information specific to subproblems (default = false)\nlog_subproblem_info::Bool: Turn on logging of times and feasibility of subproblems (default = false)\nlog_interval::Int64: Log data every log_interval iterations (default = 1)\nverbosity::Int64: The amount of information that should be printed to console while solving.     Values range from 0 - 4: 0 is silent, 1 shows iteration summary statistics     only, 2-4 show varying degrees of detail about calculations within each     iteration (default = 1)\noutput_iterations::Int64: Display summary of iteration to console every output_iterations (default = 1000)\nheader_iterations::Int64: Display header for summary to console every output_iterations (default = 100000)\nbranch_cvx_factor::Float64: Convex coefficient used to select branch point. Branch point is given by     branch_cvx_factor*xmid + (1-branch_cvx_factor)*xsol (default = 0.25)\nbranch_offset::Float64: Minimum distance from bound to have branch point, normalized by width of     dimension to branch on (default = 0.15)\nbranch_pseudocost_on::Bool: Indicate that pseudocost branching should be used (default = false)\nbranch_variable::Vector{Bool}: Variables to branch on (default is all nonlinear)\nbranch_max_repetitions::Int64: [FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED] Number of times to repeat node     processing prior to branching (default = 4)\nbranch_repetition_tol::Float64: [FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED] Volume ratio tolerance required     to repeat processing the current node (default = 0.9)\nnode_limit::Int64: Maximum number of nodes (default = 1E7)\ntime_limit::Float64: Maximum CPU time in seconds (default = 3600)\niteration_limit::Int64: Maximum number of iterations (default 1E9)\nabsolute_tolerance::Float64: Absolute tolerance for termination (default = 1E-3)\nrelative_tolerance::Float64: Relative tolerance for termination (default = 1E-3)\nabsolute_constraint_feas_tolerance::Float64: Absolute constraint feasibility tolerance (default = 1E-8)\ncp_depth::Int64: Depth in B&B tree above which constraint propagation should be disabled (default = 0)\ncp_repetitions::Int64: Number of times to repeat forward-reverse pass routine (default = 0)\ncp_tolerance::Float64: Disable constraint propagation if the ratio of new node volume to beginning node volume exceeds     this number (default = 0.99)\ncp_interval_only::Bool: Use only valid interval bounds during constraint propagation (default = false)\nobbt_depth::Int64: Depth in B&B tree above which OBBT should be disabled (default = 6)\nobbt_repetitions::Int64: Number of repetitions of OBBT to perform in preprocessing (default = 3)\nobbt_aggressive_on::Bool: Turn on aggressive OBBT (default = true)\nobbt_aggressive_max_iteration::Int64: Maximum iteration to perform aggressive OBBT (default = 2)\nobbt_aggressive_min_dimension::Int64: Minimum dimension to perform aggressive OBBT (default = 2)\nobbt_tolerance::Float64: Tolerance to consider bounds equal (default = 1E-10)\nfbbt_lp_depth::Int64: Depth in B&B tree above which linear FBBT should be disabled (default = 1000)\nfbbt_lp_repetitions::Int64: Number of repetitions of linear FBBT to perform in preprocessing (default = 3)\nfbbt_tolerance::Float64: Tolerance to consider bounds equal (default = 1E-8)\ndbbt_depth::Int64: Depth in B&B tree above which duality-based bound tightening should be disabled (default = 1E10)\ndbbt_tolerance::Float64: New bound is considered equal to the prior bound if within dbbt_tolerance (default = 1E-8)\nrelax_tag::RelaxTag: RelaxTag used to specify type of McCormick operator (default = NS())\nsubgrad_tighten::Bool: Perform tightening of interval bounds using subgradients at each factor in     each nonlinear tape during a forward pass (default = true)\nreverse_subgrad_tighten::Bool: Perform tightening of interval bounds using subgradients at each factor in     each nonlinear tape during a reverse pass (default = false)\nsubgrad_tol::Float64: Outer-round computed subgradient bounds by this amount (default = 1E-10)\nmul_relax_style::Int64: Select the type of relaxation to use for the bilinear term (multiplication): 0 corresponds to     a standard McCormick arithmetic approach. Settings 1-3 augment the standard McCormick relaxation     with implied a priori relaxations: (1) corresponds to a subgradient-based a priori relaxation approach; (2)     corresponds to an affine arithmetic-based a priori approach; and (3) corresponds to a enumerative a priori     relaxation-based approach (default = 0)\ncut_min_iterations::Int64: Minimum number of cuts at each node to attempt (unsafe cuts not necessarily added) (default = 2)\ncut_max_iterations::Int64: Maximum number of cuts at each node to attempt (default = 8)\ncut_tolerance_abs::Float64: Absolute tolerance checked for continuing cut (default = 1E-6)\ncut_tolerance_rel::Float64: Relative tolerance checked for continuing cut (default = 1E-3)\ncut_safe_on::Bool: Use tolerances to determine safe cuts in a Khajavirad 2018 manner (default = true)\ncut_safe_l::Float64: Lower tolerance for safe-lp cut, Khajavirad 2018 (default = 1E-7)\ncut_safe_u::Float64: Upper tolerance for safe-lp cut, Khajavirad 2018 (default = 1E7)\ncut_safe_b::Float64: Constant tolerance for safe-lp cut, Khajavirad 2018 (default = 1E9)\nupper_bounding_depth::Int64: Solve upper problem for every node with depth less than upper_bounding_depth,     and otherwise solve upper problems with a probability of (1/2)^(depth-upper_bounding_depth)     (default = 8)\ndomain_violation_guard_on::Bool: (Unused) Protect against domain violation (default = false)\ndomain_violation_ϵ::Float64: (Unused) Amount about a domain violation to ignore when propagating bounds (default = 1E-9)\nuser_solver_config::Bool: If true, EAGO forgoes its default configuration process for subsolvers (default = false)\ninteger_abs_tol::Float64: Absolute tolerance used to check for integrality of decision variables (default = 1E-9)\ninteger_rel_tol::Float64: Relative tolerance used to check for integrality of decision variables (default = 1E-9)\nforce_global_solve::Bool: Ignore EAGO's ability to parse problem types and force it to run global optimization (default = false)\nunbounded_check::Bool: Check that all branching variables have finite bounds and set them to +/- 1E10 if not (default = true)\n\n\n\n\n\n","category":"type"},{"location":"optimizer/optimizer/#EAGO.VariableInfo","page":"EAGO Optimizer","title":"EAGO.VariableInfo","text":"struct VariableInfo{T<:AbstractFloat}\n\nA structure used to store information related to the bounds assigned to each variable.\n\nis_integer::Bool: Is the variable integer valued?\nhas_lower_bound::Bool: Boolean indicating whether a finite lower bound exists.\nhas_upper_bound::Bool: Boolean indicating whether a finite upper bound exists.\nis_fixed::Bool: Boolean indicating if variable is fixed to a finite value.\nhas_constraints::Bool: Boolean indicating that constraints have been set\nlower_bound::AbstractFloat: Lower bound. May be -Inf.\nupper_bound::AbstractFloat: Upper bound. May be Inf.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/optimizer/#EAGO.ExtensionType","page":"EAGO Optimizer","title":"EAGO.ExtensionType","text":"abstract type ExtensionType\n\nAn abstract type the subtypes of which are associated with functions method overloaded for new extensions. An instance of this is the DefaultExt <: ExtensionType structure in the ext_type field of the Optimizer.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/optimizer/#EAGO.InputProblem","page":"EAGO Optimizer","title":"EAGO.InputProblem","text":"mutable struct InputProblem\n\nA structure used to hold objectives and constraints added to the EAGO model. The constraints generally aren't used for relaxations.\n\nAll field information available in extended help.\n\nExtended Help\n\n_variable_count::Int64: Count for the number of variables\n_variable_names::Dict{MathOptInterface.VariableIndex, String}: Dictionary containing variable indices and their names\n_constraint_count::Int64: Count for the number of constraints\n_vi_leq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}}\n_vi_geq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.GreaterThan{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.GreaterThan{Float64}}}\n_vi_eq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.EqualTo{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.EqualTo{Float64}}}\n_vi_it_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.Interval{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.Interval{Float64}}}\n_vi_zo_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.ZeroOne}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.ZeroOne}}\n_vi_int_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.Integer}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.Integer}}\n_parameter_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.Parameter{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.Parameter{Float64}}}\n_linear_leq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}, Tuple{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}}\n_linear_geq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, Tuple{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}}\n_linear_eq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}, Tuple{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}}\n_quadratic_leq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}, Tuple{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}}\n_quadratic_geq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, Tuple{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}}\n_quadratic_eq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}, Tuple{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}}\n_conic_second_order::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VectorOfVariables, MathOptInterface.SecondOrderCone}, Tuple{MathOptInterface.VectorOfVariables, MathOptInterface.SecondOrderCone}}\n_linear_leq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}, Float64}\n_linear_geq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, Float64}\n_linear_eq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}, Float64}\n_quadratic_leq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}, Float64}\n_quadratic_geq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, Float64}\n_quadratic_eq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}, Float64}\n_linear_leq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}}\n_linear_geq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}}\n_linear_eq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}}\n_quadratic_leq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}}\n_quadratic_geq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}}\n_quadratic_eq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}}\n_objective::Union{Nothing, MathOptInterface.VariableIndex, MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.ScalarQuadraticFunction{Float64}}: Storage for the objective function\n_nlp_data::Union{Nothing, MathOptInterface.NLPBlockData}: Storage for NLP constraints (set by MOI.set(m, ::NLPBlockData...) in moi_wrapper.jl)\n_optimization_sense::MathOptInterface.OptimizationSense: Objective sense information (set by MOI.set(m, ::ObjectiveSense...))\n\n\n\n\n\n","category":"type"},{"location":"optimizer/optimizer/#EAGO.ParsedProblem","page":"EAGO Optimizer","title":"EAGO.ParsedProblem","text":"mutable struct ParsedProblem\n\nA structure used to store expressions and problem descriptions EAGO uses to formulate relaxed problems.\n\nAll field information available in extended help.\n\nExtended Help\n\n_problem_type::Union{Nothing, EAGO.DIFF_CVX, EAGO.LP, EAGO.MILP, EAGO.MINCVX, EAGO.MISOCP, EAGO.SOCP}: Problem classification (set in parse_classify_problem!)\n_objective_saf::MathOptInterface.ScalarAffineFunction{Float64}: Stores the objective and is used for constructing linear affine cuts\n_objective::Union{Nothing, MathOptInterface.VariableIndex, EAGO.AffineFunctionIneq, EAGO.BufferedQuadraticIneq, EAGO.BufferedNonlinearFunction}: Storage for the objective function\n_optimization_sense::MathOptInterface.OptimizationSense: Objective sense information (set by MOI.set(m, ::ObjectiveSense...))\n_saf_leq::Vector{EAGO.AffineFunctionIneq}\n_saf_eq::Vector{EAGO.AffineFunctionEq}\n_sqf_leq::Vector{EAGO.BufferedQuadraticIneq}\n_sqf_eq::Vector{EAGO.BufferedQuadraticEq}\n_conic_second_order::Vector{EAGO.BufferedSOC}\n_nlp_data::Union{Nothing, MathOptInterface.NLPBlockData}\n_nonlinear_constr::Vector{EAGO.BufferedNonlinearFunction}\n_relaxed_evaluator::Evaluator\n_variable_info::Vector{VariableInfo{Float64}}: Variable information (set in initial_parse!)\n_variable_count::Int64: Count for the number of variables\n\n\n\n\n\n","category":"type"},{"location":"optimizer/optimizer/#EAGO.initial_parse!-Union{Tuple{Optimizer{R, S, T}}, Tuple{T}, Tuple{S}, Tuple{R}} where {R, S, T}","page":"EAGO Optimizer","title":"EAGO.initial_parse!","text":"initial_parse!(m::Optimizer{R, S, T})\n\n\nTranslate the input problem to the working problem. Any checks or optional manipulation are left to the presolve stage.\n\n\n\n\n\n","category":"method"},{"location":"jump/README/","page":"EAGO - Easy Advanced Global Optimization","title":"EAGO - Easy Advanced Global Optimization","text":"<img src=\"https://github.com/PSORLab/EAGO.jl/blob/master/docs/src/assets/logo.png?raw=true\" width=\"75%\" height=\"75%\"/>","category":"section"},{"location":"jump/README/#EAGO-Easy-Advanced-Global-Optimization","page":"EAGO - Easy Advanced Global Optimization","title":"EAGO - Easy Advanced Global Optimization","text":"EAGO is an open-source development environment for robust and global optimization in Julia. See the full README for more information.\n\nPSOR Lab Current Version Build Status Documentation\n(Image: ) (Image: ) (Image: Build Status) (Image: codecov) (Image: )\n\nEAGO is a deterministic global optimizer designed to address a wide variety of optimization problems, emphasizing nonlinear programs (NLPs), by propagating McCormick relaxations along the factorable structure of each expression in the NLP. Most operators supported by modern automatic differentiation (AD) packages are supported by EAGO and a number utilities for sanitizing native Julia code and generating relaxations on a wide variety of user-defined functions have been included. Currently, EAGO supports problems that have a priori variable bounds defined and have differentiable constraints. That is, problems should be specified in the generic form below:\n\nbeginaligned\nf^* =  min_mathbf y in Y subset mathbb R^n_y f(mathbf y) \nrm st    mathbf h(mathbf y) = mathbf 0 \n mathbf g(mathbf y) leq mathbf 0 \n Y = mathbf y^L mathbf y^U in mathbbIR^n \n qquad mathbf y^L mathbf y^U in mathbb R^n\nendaligned\n\nFor each nonlinear term, EAGO makes use of factorable representations to construct bounds and relaxations.\n\nFor example, given the function\n\nf(x) = x (x - 5) sin(x)\n\na list is generated and rules for constructing McCormick relaxations are used  to formulate relaxations in the original decision space, X [1]:\n\nbeginaligned\nv_1  = x \nv_2  = v_1 - 5 \nv_3  = sin(v_1) \nv_4  = v_1 v_2 \nv_5  = v_4 v_3 \nf(x)  = v_5 \nendaligned\n\n<p align=\"center\">\n<img src=\"https://github.com/PSORLab/EAGO.jl/blob/master/docs/src/mccormick/Figure_1.png?raw=true\" width=\"60%\" height=\"60%\"/>\n</p>\n\nEither these original relaxations, differentiable McCormick relaxations [2], or affine relaxations thereof can be used to construct relaxations of optimization problems useful in branch and bound routines for global optimization. Utilities are included to combine these with algorithms for relaxing implicit functions [3] and forward-reverse propagation of McCormick arithmetic [4].","category":"section"},{"location":"jump/README/#License","page":"EAGO - Easy Advanced Global Optimization","title":"License","text":"EAGO is licensed under the MIT License.","category":"section"},{"location":"jump/README/#Installation","page":"EAGO - Easy Advanced Global Optimization","title":"Installation","text":"EAGO is a registered Julia package that can be installed using the Julia package manager:\n\nimport Pkg\nPkg.add(\"EAGO\")","category":"section"},{"location":"jump/README/#Use-with-JuMP","page":"EAGO - Easy Advanced Global Optimization","title":"Use with JuMP","text":"EAGO makes use of JuMP to improve the user's experience in setting up optimization models. Consider the \"process\" problem instance from [5]:\n\nbeginaligned\nmax_mathbf x in X  0063 x_4 x_7 - 504 x_1 - 0035 x_2 - 10 x_3 - 336 x_2 \nrm st    x_1 (112 + 013167 x_8 - 000667 x_8^2) + x_4 = 0 \n -0001 x_4 x_9 x_6  (98 - x_6) + x_3 = 0 \n -(1098 x_8 - 0038 x_8^2) - 0325 x_6 + x_7 = 0 \n -(x_2 + x_5)  x_1 + x_8 = 0 \n -x_1 + 122 x_4 - x_5 = 0 \n x_9 + 0222 x_10 - 3582 = 0 \n -30 x_7 + x_10 + 1330 = 0 \n X = 10 2000 times 0 16000 times 0 120 times 0 5000 \n qquad times 0 2000 times 85 93 times 909 5 times 3 12 times 12 4 times 145 162\nendaligned\n\nThis model can be formulated in Julia as:\n\nusing JuMP\nimport EAGO\n# Build model using EAGO's optimizer\nmodel = Model(EAGO.Optimizer)\n# Define bounded variables\nxL = [10.0, 0.0, 0.0, 0.0, 0.0, 85.0, 90.0, 3.0, 1.2, 145.0]\nxU = [2000.0, 16000.0, 120.0, 5000.0, 2000.0, 93.0, 95.0, 12.0, 4.0, 162.0]\n@variable(model, xL[i] <= x[i=1:10] <= xU[i])\n# Define nonlinear constraints\n@NLconstraints(model, begin\n    -x[1]*(1.12 + 0.13167*x[8] - 0.00667*(x[8])^2) + x[4] == 0.0\n    -0.001*x[4]*x[9]*x[6]/(98.0 - x[6]) + x[3] == 0.0\n    -(1.098*x[8] - 0.038*(x[8])^2) - 0.325*x[6] + x[7] == 57.425\n    -(x[2] + x[5])/x[1] + x[8] == 0.0\nend)\n# Define linear constraints\n@constraints(model, begin\n    -x[1] + 1.22*x[4] - x[5] == 0.0\n    x[9] + 0.222*x[10] == 35.82\n    -3.0*x[7] + x[10] == -133.0\nend)\n# Define nonlinear objective\n@NLobjective(\n    model, \n    Max,\n    0.063*x[4]*x[7] - 5.04*x[1] - 0.035*x[2] - 10*x[3] - 3.36*x[5],\n)\n# Solve the optimization problem\noptimize!(model)","category":"section"},{"location":"jump/README/#Documentation","page":"EAGO - Easy Advanced Global Optimization","title":"Documentation","text":"EAGO has numerous features: a solver accessible from JuMP/MathOptInterface (MOI), domain reduction routines, McCormick relaxations, and specialized nonconvex semi-infinite program solvers. A full description of all features can be found on the documentation website. \n\nA series of examples have been provided in the documentation and in the form of Jupyter Notebooks in the separate EAGO-notebooks repository.","category":"section"},{"location":"jump/README/#A-Cautionary-Note-on-Global-Optimization","page":"EAGO - Easy Advanced Global Optimization","title":"A Cautionary Note on Global Optimization","text":"As a global optimization platform, EAGO's solvers can be used to find solutions of general nonconvex problems with a guaranteed certificate of optimality. However, global solvers suffer from the curse of dimensionality and therefore their performance is outstripped by convex/local solvers.\n\nFor users interested in large-scale applications, be warned that problems generally larger than a few variables may prove challenging for certain types of global optimization problems.","category":"section"},{"location":"jump/README/#Citing-EAGO","page":"EAGO - Easy Advanced Global Optimization","title":"Citing EAGO","text":"Please cite the following paper when using EAGO. In plain text form this is:\n\nWilhelm, M.E. and Stuber, M.D. EAGO.jl: easy advanced global optimization in Julia.\nOptimization Methods and Software. 37(2): 425—450 (2022). DOI: 10.1080/10556788.2020.1786566\n\nAs a BibTeX entry:\n\n@article{doi:10.1080/10556788.2020.1786566,\n    author = {Wilhelm, M.E. and Stuber, M.D.},\n    title = {EAGO.jl: easy advanced global optimization in Julia},\n    journal = {Optimization Methods and Software},\n    volume = {37},\n    number = {2},\n    pages = {425-450},\n    year  = {2022},\n    publisher = {Taylor & Francis},\n    doi = {10.1080/10556788.2020.1786566},\n    URL = {https://doi.org/10.1080/10556788.2020.1786566},\n    eprint = {https://doi.org/10.1080/10556788.2020.1786566}\n}","category":"section"},{"location":"jump/README/#References","page":"EAGO - Easy Advanced Global Optimization","title":"References","text":"Mitsos, A., Chachuat, B., and Barton, P.I. McCormick-based relaxations of algorithms. SIAM Journal on Optimization. 20(2): 573—601 (2009).\nKhan, K.A., Watson, H.A.J., and Barton, P.I. Differentiable McCormick relaxations. Journal of Global Optimization. 67(4): 687—729 (2017).\nStuber, M.D., Scott, J.K., and Barton, P.I.: Convex and concave relaxations of implicit functions. Optimization Methods and Software 30(3): 424—460 (2015).\nWechsung, A., Scott, J.K., Watson, H.A.J., and Barton, P.I. Reverse propagation of McCormick relaxations. Journal of Global Optimization 63(1): 1—36 (2015).\nBracken, J., and McCormick, G.P. Selected Applications of Nonlinear Programming. John Wiley and Sons, New York (1968).","category":"section"},{"location":"optimizer/udf_utilities/#User-Defined-Functions-and-Directed-Acyclic-Graph-Utilities","page":"User-Defined Functions and Directed Acyclic Graph Utilities","title":"User-Defined Functions and Directed Acyclic Graph Utilities","text":"EAGO has included basic functionality to manipulate user-defined functions (UDFs). EAGO also has utilities for directed acyclic graphs (DAGs). These features are largely experimental and we're interested in providing additional features for novel use cases.","category":"section"},{"location":"optimizer/udf_utilities/#DAG-Substitution-and-Flattening","page":"User-Defined Functions and Directed Acyclic Graph Utilities","title":"DAG Substitution and Flattening","text":"","category":"section"},{"location":"optimizer/udf_utilities/#UDF-Scrubber","page":"User-Defined Functions and Directed Acyclic Graph Utilities","title":"UDF Scrubber","text":"","category":"section"},{"location":"optimizer/udf_utilities/#EAGO.Script.dag_flattening!","page":"User-Defined Functions and Directed Acyclic Graph Utilities","title":"EAGO.Script.dag_flattening!","text":"dag_flattening!\n\nFlattens (usually) the dag by making all registered substitutions for every nonlinear term in the Optimizer.\n\n\n\n\n\n","category":"function"},{"location":"optimizer/udf_utilities/#EAGO.Script.flatten_expression!","page":"User-Defined Functions and Directed Acyclic Graph Utilities","title":"EAGO.Script.flatten_expression!","text":"flatten_expression!\n\nFlattens (usually) the dag by making all registered substitutions for the expression expr::MOINL.Expression. Performs a depth-first search through the expression adding the terminal node to the stack, then checking to determine if it matches a registered substitution pattern. If it doesn't not then node is added to the new expression graph representation and it's children are added to the queue. If an expression (node) is identified as a pattern then it is substituted and any children expression nodes are then checked for patterns until the depth first search is exhausted.\n\n\n\n\n\n","category":"function"},{"location":"optimizer/udf_utilities/#EAGO.Script.register_substitution!","page":"User-Defined Functions and Directed Acyclic Graph Utilities","title":"EAGO.Script.register_substitution!","text":"register_substitution!\n\nSpecifies that the src::Template_Graph should be subsituted out for the trg::Template_Graph.\n\nConventions for substition, the expression to be checked always appears at key 1 in the Template_Graph and operations are ordered from low value to high value left to right so if 1 is a -, and 4 => 1, 3 => 1 then the expression is 4 - 3\n\n\n\n\n\n","category":"function"},{"location":"optimizer/udf_utilities/#EAGO.Script.Template_Graph","page":"User-Defined Functions and Directed Acyclic Graph Utilities","title":"EAGO.Script.Template_Graph","text":"Template_Graph\n\nHolds a list of Template_Nodes, set of directed edges, lengths, an adjacency matrix and the number of children.\n\n\n\n\n\n","category":"type"},{"location":"optimizer/udf_utilities/#EAGO.Script.Template_Node","page":"User-Defined Functions and Directed Acyclic Graph Utilities","title":"EAGO.Script.Template_Node","text":"Template_Node\n\nA structure which holds a symbol indicating whether the node is an operator, a number, or an expression type, a value which identifies the function or symbol value, potentially a numeric value num_value, and a check that can be run to verify the node is correct check.\n\n\n\n\n\n","category":"type"},{"location":"dev/contributing/#How-to-Contribute-to-EAGO","page":"Contributing","title":"How to Contribute to EAGO","text":"We're always happy to welcome work with additional collaborators and contributors. One of the easy ways for newcomers to contribute is by adding additional McCormick relaxations.\n\nIf you have any requests for additional functionality, bug fixes, or comments, please feel free to open a new issue using the GitHub issue tracker or reach out to us.","category":"section"},{"location":"dev/contributing/#Contact-Us","page":"Contributing","title":"Contact Us","text":"Please direct technical issues and/or bugs to the active developers: \n\nRobert Gottlieb\nDimitri Alston\n\nAll other questions should be directed to Prof. Stuber.","category":"section"},{"location":"mccormick/implicit/#Relaxation-of-Implicit-Functions","page":"Relaxation of Implicit Functions","title":"Relaxation of Implicit Functions","text":"","category":"section"},{"location":"mccormick/implicit/#High-Level-Functions","page":"Relaxation of Implicit Functions","title":"High-Level Functions","text":"","category":"section"},{"location":"mccormick/implicit/#Data-Structures","page":"Relaxation of Implicit Functions","title":"Data Structures","text":"","category":"section"},{"location":"mccormick/implicit/#Subroutines","page":"Relaxation of Implicit Functions","title":"Subroutines","text":"","category":"section"},{"location":"mccormick/implicit/#McCormick.implicit_relax_h!","page":"Relaxation of Implicit Functions","title":"McCormick.implicit_relax_h!","text":"implicit_relax_h!(d)\nimplicit_relax_h!(d, interval_bnds)\n\n\nCompute relaxations of x(p) defined by h(x,p) = 0 where h is specifed as h(out, x, p).\n\n\n\n\n\n","category":"function"},{"location":"mccormick/implicit/#McCormick.AbstractContractorMC","page":"Relaxation of Implicit Functions","title":"McCormick.AbstractContractorMC","text":"abstract type AbstractContractorMC\n\nAn abstract type for each manner of contractor using in the implicit function relaxation algorithms.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/implicit/#McCormick.NewtonGS","page":"Relaxation of Implicit Functions","title":"McCormick.NewtonGS","text":"struct NewtonGS <: McCormick.AbstractContractorMC\n\nThe Gauss-Seidel implementation of the Newton contractor used in the implicit relaxation scheme.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/implicit/#McCormick.KrawczykCW","page":"Relaxation of Implicit Functions","title":"McCormick.KrawczykCW","text":"struct KrawczykCW <: McCormick.AbstractContractorMC\n\nThe componentwise implementation of the Krawczyk contractor used in the implicit relaxation scheme.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/implicit/#McCormick.AbstractPreconditionerMC","page":"Relaxation of Implicit Functions","title":"McCormick.AbstractPreconditionerMC","text":"abstract type AbstractPreconditionerMC\n\nAn abstract type for each manner of preconditioner used in the implicit function relaxation algorithms.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/implicit/#McCormick.DenseMidInv","page":"Relaxation of Implicit Functions","title":"McCormick.DenseMidInv","text":"struct DenseMidInv{S<:VecOrMat{Float64}} <: McCormick.AbstractPreconditionerMC\n\nA dense LU preconditioner for implicit McCormick relaxation.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/implicit/#McCormick.AbstractMCCallback","page":"Relaxation of Implicit Functions","title":"McCormick.AbstractMCCallback","text":"abstract type AbstractMCCallback\n\nAn abstract type for each manner of callback functions used in the implicit function relaxation algorithms.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/implicit/#McCormick.MCCallback","page":"Relaxation of Implicit Functions","title":"McCormick.MCCallback","text":"mutable struct MCCallback{FH, FJ, C<:McCormick.AbstractContractorMC, PRE<:McCormick.AbstractPreconditionerMC, N, T<:RelaxTag, AMAT<:(AbstractMatrix)} <: AbstractMCCallback\n\nA structure used to compute implicit relaxations.\n\nh!::Any: Function h(x,p) = 0 defined in place by h!(out,x,p)\nhj!::Any: Jacobian of h(x,p) w.r.t x\nH::Array{MC{N, T}, 1} where {N, T<:RelaxTag}: Intermediate inplace storage for output of h!\nJ::AbstractMatrix: Intermediate inplace storage for output of hj!\nJ0::Vector{AMAT} where AMAT<:(AbstractMatrix)\nxz0::Vector{AMAT} where AMAT<:(AbstractMatrix)\nxmid::Vector{Float64}\nX::Vector{Interval{Float64}}: State space x interval bounds\nP::Vector{Interval{Float64}}: Decision space p interval bounds\nnx::Int64: State space dimension\nnp::Int64: Decision space dimension\nλ::Float64: Convex combination parameter\neps::Float64: Tolerance for interval equality\nkmax::Int64: Number of contractor steps to take\npref_mc::Array{MC{N, T}, 1} where {N, T<:RelaxTag}: Reference decision point at which affine relaxations are calculated (and used in subsequent calculations).\np_mc::Array{MC{N, T}, 1} where {N, T<:RelaxTag}: Decision point at which relaxation is evaluated.\np_temp_mc::Array{MC{N, T}, 1} where {N, T<:RelaxTag}: Vector used to temporarily store p in genexpansionparams! routine.\nx0_mc::Array{MC{N, T}, 1} where {N, T<:RelaxTag}\nx_mc::Array{MC{N, T}, 1} where {N, T<:RelaxTag}\nxa_mc::Array{MC{N, T}, 1} where {N, T<:RelaxTag}\nxA_mc::Array{MC{N, T}, 1} where {N, T<:RelaxTag}\naff_mc::Array{MC{N, T}, 1} where {N, T<:RelaxTag}\nz_mc::Array{MC{N, T}, 1} where {N, T<:RelaxTag}\ncontractor::McCormick.AbstractContractorMC: Type of contractor used in implicit relaxation routine.\npreconditioner::McCormick.AbstractPreconditionerMC: Preconditioner used in the implicit relaxation routine.\napply_precond::Bool: Boolean indicating that the preconditioner should be applied\nparam::Array{Array{MC{N, T}, 1}, 1} where {N, T<:RelaxTag}: Vector of relaxations of x at each iteration used to generated affine relaxations used in intermediate calculation.\nuse_apriori::Bool: Indicates that subgradient-based apriori relaxations of multiplication should be used.\n\n\n\n\n\n","category":"type"},{"location":"mccormick/implicit/#McCormick.preconditioner_storage","page":"Relaxation of Implicit Functions","title":"McCormick.preconditioner_storage","text":"preconditioner_storage(x, t)\n\n\nCreates storage corresponding to x::AbstractPreconditionerMC and t::T where T<:RelaxTag.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/implicit/#McCormick.affine_exp!","page":"Relaxation of Implicit Functions","title":"McCormick.affine_exp!","text":"affine_exp!(x, p, d)\n\n\nComputates the affine relaxations of the state variable.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/implicit/#McCormick.correct_exp!","page":"Relaxation of Implicit Functions","title":"McCormick.correct_exp!","text":"correct_exp!(d)\n\n\nCorrects the relaxation of the state variable x_mc if the affine relaxation,\n\n\n\n\n\n","category":"function"},{"location":"mccormick/implicit/#McCormick.contract!","page":"Relaxation of Implicit Functions","title":"McCormick.contract!","text":"Performs a single step of the parametric method associated with t assumes that the inputs have been preconditioned.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/implicit/#McCormick.precond_and_contract!","page":"Relaxation of Implicit Functions","title":"McCormick.precond_and_contract!","text":"precond_and_contract!(d!, k, b)\n\n\n\n\n\n\n","category":"function"},{"location":"mccormick/implicit/#McCormick.final_cut","page":"Relaxation of Implicit Functions","title":"McCormick.final_cut","text":"final_cut(x, y)\n\n\nAn operator that cuts the x object using the y bounds in a differentiable or nonsmooth fashion to achieve a composite relaxation within y.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/implicit/#McCormick.gen_expansion_params!","page":"Relaxation of Implicit Functions","title":"McCormick.gen_expansion_params!","text":"gen_expansion_params!(d)\ngen_expansion_params!(d, interval_bnds)\n\n\nConstructs parameters need to compute relaxations of h.\n\n\n\n\n\n","category":"function"},{"location":"mccormick/implicit/#McCormick.populate_affine!","page":"Relaxation of Implicit Functions","title":"McCormick.populate_affine!","text":"populate_affine!(d, interval_bnds)\n\n\nPopulates x_mc, xa_mc, xA_mc, and z_mc with affine bounds.\n\n\n\n\n\n","category":"function"},{"location":"dev/api_types/#Types","page":"Types","title":"Types","text":"","category":"section"},{"location":"dev/api_types/#EAGO.AbstractCache-dev-api_types","page":"Types","title":"EAGO.AbstractCache","text":"abstract type AbstractCache\n\nAbstract supertype used for information storage object the directed acyclic graph.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.AbstractCacheAttribute-dev-api_types","page":"Types","title":"EAGO.AbstractCacheAttribute","text":"abstract type AbstractCacheAttribute\n\nAbstract supertype used for attributes stored in a cache.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.AbstractDirectedGraph-dev-api_types","page":"Types","title":"EAGO.AbstractDirectedGraph","text":"abstract type AbstractDirectedGraph\n\nAbstract supertype for generic directed graph structure.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.AbstractEAGOConstraint-dev-api_types","page":"Types","title":"EAGO.AbstractEAGOConstraint","text":"abstract type AbstractEAGOConstraint\n\nAn abstract super-type used for representing constraints built by EAGO's backend.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.AffineFunctionEq-dev-api_types","page":"Types","title":"EAGO.AffineFunctionEq","text":"mutable struct AffineFunctionEq <: EAGO.AbstractEAGOConstraint\n\nRepresentation of an affine equality. Currently only used for bound tightening.\n\nterms::Vector{Tuple{Float64, Int64}}\nconstant::Float64\nlen::Int64\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.AffineFunctionIneq-dev-api_types","page":"Types","title":"EAGO.AffineFunctionIneq","text":"mutable struct AffineFunctionIneq <: EAGO.AbstractEAGOConstraint\n\nRepresentation of an affine inequality. Currently only used for bound tightening.\n\nterms::Vector{Tuple{Float64, Int64}}\nconstant::Float64\nlen::Int64\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.AtomType-dev-api_types","page":"Types","title":"EAGO.AtomType","text":"AtomType\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.BufferedNonlinearFunction-dev-api_types","page":"Types","title":"EAGO.BufferedNonlinearFunction","text":"mutable struct BufferedNonlinearFunction{V, N, T<:RelaxTag} <: EAGO.AbstractEAGOConstraint\n\nStores a general nonlinear function with a buffer represented by the sum of a tape and a scalar affine function.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.BufferedQuadraticEq-dev-api_types","page":"Types","title":"EAGO.BufferedQuadraticEq","text":"mutable struct BufferedQuadraticEq <: EAGO.AbstractEAGOConstraint\n\nRepresentation of a general quadratic equality constraint with a buffer.\n\nfunc::MathOptInterface.ScalarQuadraticFunction{Float64}\nminus_func::MathOptInterface.ScalarQuadraticFunction{Float64}\nbuffer::Dict{Int64, Float64}\nsaf::MathOptInterface.ScalarAffineFunction{Float64}\nlen::Int64\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.BufferedQuadraticIneq-dev-api_types","page":"Types","title":"EAGO.BufferedQuadraticIneq","text":"mutable struct BufferedQuadraticIneq <: EAGO.AbstractEAGOConstraint\n\nRepresentation of a general quadratic inequality constraint with a buffer.\n\nfunc::MathOptInterface.ScalarQuadraticFunction{Float64}\nbuffer::Dict{Int64, Float64}\nsaf::MathOptInterface.ScalarAffineFunction{Float64}\nlen::Int64\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.BufferedSOC-dev-api_types","page":"Types","title":"EAGO.BufferedSOC","text":"mutable struct BufferedSOC <: EAGO.AbstractEAGOConstraint\n\nRepresentation of a second-order cone with a buffer.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.DirectedTree-dev-api_types","page":"Types","title":"EAGO.DirectedTree","text":"DirectedTree\n\nA tree graph with a single sink node.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.EAGOParameters-dev-api_types","page":"Types","title":"EAGO.EAGOParameters","text":"mutable struct EAGOParameters\n\nStorage for parameters that do not change during a global solve.\n\npresolve_scrubber_flag::Bool: Should EAGO attempt to remove type-assert issues for user-defined functions (default = false)\npresolve_to_JuMP_flag::Bool: Create and use DAG representations of user-defined functions (default = false)\npresolve_flatten_flag::Bool: Rerrange the DAG using registered transformations (default = false)\nconic_convert_quadratic::Bool: Attempt to bridge convex constraint to second-order cone (default = false)\nlog_on::Bool: Turn logging on; record global bounds, node count, and run time. Additional      options are available for recording information specific to subproblems (default = false)\nlog_subproblem_info::Bool: Turn on logging of times and feasibility of subproblems (default = false)\nlog_interval::Int64: Log data every log_interval iterations (default = 1)\nverbosity::Int64: The amount of information that should be printed to console while solving.     Values range from 0 - 4: 0 is silent, 1 shows iteration summary statistics     only, 2-4 show varying degrees of detail about calculations within each     iteration (default = 1)\noutput_iterations::Int64: Display summary of iteration to console every output_iterations (default = 1000)\nheader_iterations::Int64: Display header for summary to console every output_iterations (default = 100000)\nbranch_cvx_factor::Float64: Convex coefficient used to select branch point. Branch point is given by     branch_cvx_factor*xmid + (1-branch_cvx_factor)*xsol (default = 0.25)\nbranch_offset::Float64: Minimum distance from bound to have branch point, normalized by width of     dimension to branch on (default = 0.15)\nbranch_pseudocost_on::Bool: Indicate that pseudocost branching should be used (default = false)\nbranch_variable::Vector{Bool}: Variables to branch on (default is all nonlinear)\nbranch_max_repetitions::Int64: [FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED] Number of times to repeat node     processing prior to branching (default = 4)\nbranch_repetition_tol::Float64: [FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED] Volume ratio tolerance required     to repeat processing the current node (default = 0.9)\nnode_limit::Int64: Maximum number of nodes (default = 1E7)\ntime_limit::Float64: Maximum CPU time in seconds (default = 3600)\niteration_limit::Int64: Maximum number of iterations (default 1E9)\nabsolute_tolerance::Float64: Absolute tolerance for termination (default = 1E-3)\nrelative_tolerance::Float64: Relative tolerance for termination (default = 1E-3)\nabsolute_constraint_feas_tolerance::Float64: Absolute constraint feasibility tolerance (default = 1E-8)\ncp_depth::Int64: Depth in B&B tree above which constraint propagation should be disabled (default = 0)\ncp_repetitions::Int64: Number of times to repeat forward-reverse pass routine (default = 0)\ncp_tolerance::Float64: Disable constraint propagation if the ratio of new node volume to beginning node volume exceeds     this number (default = 0.99)\ncp_interval_only::Bool: Use only valid interval bounds during constraint propagation (default = false)\nobbt_depth::Int64: Depth in B&B tree above which OBBT should be disabled (default = 6)\nobbt_repetitions::Int64: Number of repetitions of OBBT to perform in preprocessing (default = 3)\nobbt_aggressive_on::Bool: Turn on aggressive OBBT (default = true)\nobbt_aggressive_max_iteration::Int64: Maximum iteration to perform aggressive OBBT (default = 2)\nobbt_aggressive_min_dimension::Int64: Minimum dimension to perform aggressive OBBT (default = 2)\nobbt_tolerance::Float64: Tolerance to consider bounds equal (default = 1E-10)\nfbbt_lp_depth::Int64: Depth in B&B tree above which linear FBBT should be disabled (default = 1000)\nfbbt_lp_repetitions::Int64: Number of repetitions of linear FBBT to perform in preprocessing (default = 3)\nfbbt_tolerance::Float64: Tolerance to consider bounds equal (default = 1E-8)\ndbbt_depth::Int64: Depth in B&B tree above which duality-based bound tightening should be disabled (default = 1E10)\ndbbt_tolerance::Float64: New bound is considered equal to the prior bound if within dbbt_tolerance (default = 1E-8)\nrelax_tag::RelaxTag: RelaxTag used to specify type of McCormick operator (default = NS())\nsubgrad_tighten::Bool: Perform tightening of interval bounds using subgradients at each factor in     each nonlinear tape during a forward pass (default = true)\nreverse_subgrad_tighten::Bool: Perform tightening of interval bounds using subgradients at each factor in     each nonlinear tape during a reverse pass (default = false)\nsubgrad_tol::Float64: Outer-round computed subgradient bounds by this amount (default = 1E-10)\nmul_relax_style::Int64: Select the type of relaxation to use for the bilinear term (multiplication): 0 corresponds to     a standard McCormick arithmetic approach. Settings 1-3 augment the standard McCormick relaxation     with implied a priori relaxations: (1) corresponds to a subgradient-based a priori relaxation approach; (2)     corresponds to an affine arithmetic-based a priori approach; and (3) corresponds to a enumerative a priori     relaxation-based approach (default = 0)\ncut_min_iterations::Int64: Minimum number of cuts at each node to attempt (unsafe cuts not necessarily added) (default = 2)\ncut_max_iterations::Int64: Maximum number of cuts at each node to attempt (default = 8)\ncut_tolerance_abs::Float64: Absolute tolerance checked for continuing cut (default = 1E-6)\ncut_tolerance_rel::Float64: Relative tolerance checked for continuing cut (default = 1E-3)\ncut_safe_on::Bool: Use tolerances to determine safe cuts in a Khajavirad 2018 manner (default = true)\ncut_safe_l::Float64: Lower tolerance for safe-lp cut, Khajavirad 2018 (default = 1E-7)\ncut_safe_u::Float64: Upper tolerance for safe-lp cut, Khajavirad 2018 (default = 1E7)\ncut_safe_b::Float64: Constant tolerance for safe-lp cut, Khajavirad 2018 (default = 1E9)\nupper_bounding_depth::Int64: Solve upper problem for every node with depth less than upper_bounding_depth,     and otherwise solve upper problems with a probability of (1/2)^(depth-upper_bounding_depth)     (default = 8)\ndomain_violation_guard_on::Bool: (Unused) Protect against domain violation (default = false)\ndomain_violation_ϵ::Float64: (Unused) Amount about a domain violation to ignore when propagating bounds (default = 1E-9)\nuser_solver_config::Bool: If true, EAGO forgoes its default configuration process for subsolvers (default = false)\ninteger_abs_tol::Float64: Absolute tolerance used to check for integrality of decision variables (default = 1E-9)\ninteger_rel_tol::Float64: Relative tolerance used to check for integrality of decision variables (default = 1E-9)\nforce_global_solve::Bool: Ignore EAGO's ability to parse problem types and force it to run global optimization (default = false)\nunbounded_check::Bool: Check that all branching variables have finite bounds and set them to +/- 1E10 if not (default = true)\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.Evaluator-dev-api_types","page":"Types","title":"EAGO.Evaluator","text":"Evaluator\n\nMOI.AbstractNLPEvaluator for calculating relaxations of nonlinear terms.\n\nChecks that the resulting value should be a number.\n\nuser_operators::EAGO.OperatorRegistry\nhas_user_mv_operator::Bool\nnum_mv_buffer::Vector{Float64}\nparameter_values::Vector{Float64}\nnode::NodeBB\nvariable_values::EAGO.VariableValues{Float64}\nsubgrad_tighten::Bool\nreverse_subgrad_tighten::Bool\nsubexpressions::Vector{EAGO.NonlinearExpression}\nsubexpressions_eval::Vector{Bool}\nis_post::Bool\nis_intersect::Bool\nis_first_eval::Bool\ninterval_intersect::Bool\nsubgrad_tol::Float64\nrelax_type::EAGO.RelaxType\npass_number::Int64\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.ExtensionType-dev-api_types","page":"Types","title":"EAGO.ExtensionType","text":"abstract type ExtensionType\n\nAn abstract type the subtypes of which are associated with functions method overloaded for new extensions. An instance of this is the DefaultExt <: ExtensionType structure in the ext_type field of the Optimizer.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.GlobalEndState-dev-api_types","page":"Types","title":"EAGO.GlobalEndState","text":"primitive type GlobalEndState <: Enum{Int32} 32\n\nAn Enum of possible values for EAGO's termination status. This attribute is used by EAGO to explain why the optimizer stopped executing in the most recent call to optimize!. See also MathOptInterface.TerminationStatusCode.\n\nIf no call has been made to optimize!, the GlobalEndState value is:\n\nGS_UNSET: The optimization algorithm has not stated.\n\nOK\n\nGS_OPTIMAL: A globally optimal solution was found.\nGS_INFEASIBLE: The algorithm concluded that no feasible solution exists.\n\nLimits reached\n\nGS_NODE_LIMIT: The branch-and-bound algorithm stopped because it reached the       user-set maximum number of nodes in the branch-and-bound tree.\nGS_ITERATION_LIMIT: The maximum number of iterations was reached.\nGS_RELATIVE_TOL: The gap between the lower and upper bounds, relative        to the bound with the larger magnitude, is within the user-set relative       tolerance.\nGS_ABSOLUTE_TOL: The gap between the lower and upper bounds is within the user-set        absolute tolerance.\nGS_TIME_LIMIT: The algorithm stopped after the user-specified time limit was reached.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.GlobalOptimizer-dev-api_types","page":"Types","title":"EAGO.GlobalOptimizer","text":"mutable struct GlobalOptimizer{Q, S, T<:ExtensionType} <: MathOptInterface.AbstractOptimizer\n\nOptimizer internal to EAGO which holds information used to perform branch-and-bound in order to solve nonconvex MINLPs.\n\nDescriptions of all fields available in extended help.\n\nExtended Help\n\n_subsolvers::SubSolvers{Q, S} where {Q, S}: Storage for relaxed and upper optimizers to use, and any custom extensions\n_parameters::EAGOParameters: Parameters that do not change during a global solve\n_input_problem::InputProblem: Expressions and constraints added to the EAGO model (not directly     used for relaxations)\n_working_problem::ParsedProblem: Expressions and problem descriptions that EAGO uses to formulate     relaxed problems\n_auxiliary_variable_info::Union{Nothing, EAGO._AuxVarData}: Information on any auxiliary variables\nobbt_variable_values::Vector{Bool}: Variables to perform OBBT on (default: all variables in nonlinear expressions)\nenable_optimize_hook::Bool: Specifies that the optimize_hook! function should be called rather than throw the     problem to the standard routine\next::Any: (Deprecated, use _subsolvers instead) Storage for custom extension types\n_end_state::EAGO.GlobalEndState: The completion status code for the branch-and-bound algorithm\n_termination_status_code::MathOptInterface.TerminationStatusCode: The MathOptInterface-compliant completion status code\n_result_status_code::MathOptInterface.ResultStatusCode: Value indicating the feasibility status of the result\n_obj_mult::Float64: Multiplier used internally to convert objective sense from Max to Min. Only     takes on values of {-1.0, 1.0}\n_obj_var_slack_added::Bool: Flag to indicate if a slack variable was added for the objective function. This     is done in some epigraph reformulations (see reform_epigraph_min!)\n_stack::DataStructures.BinaryMinMaxHeap{NodeBB}: A heap of all nodes in the branch-and-bound tree\n_current_node::NodeBB: The individual node being examined at any particular time. Nodes are removed from     the stack and placed here, evaluated, and then sent back to the stack\n_first_relax_point_set::Bool: (Unused) Flag for relaxation points\n_current_xref::Vector{Float64}: (Unused) Variable values of a particular point\n_candidate_xref::Vector{Float64}: (Unused) Variable values of a candidate point\n_use_prior_objective_xref::Bool: (Unused) Flag to use variable values from previous evaluation on the current step\n_current_objective_xref::Vector{Float64}: (Unused) Variable values for objective evaluation\n_prior_objective_xref::Vector{Float64}: (Unused) Variable values for previous objective evaluation\n_user_branch_variables::Bool: Flag for if the user has specified branch variables (see label_branch_variables!)\n_fixed_variable::Vector{Bool}: Variables that are fixed in place\n_branch_variable_count::Int64: Number of variables that can be branched on\n_branch_to_sol_map::Vector{Int64}: Mapping from the branch variables to the full set of variables in the problem\n_sol_to_branch_map::Vector{Int64}: Mapping from the full set of variables in the problem to the branch variables\n_continuous_solution::Vector{Float64}: The final (or intermediate) variable values of the solution\n_preprocess_feasibility::Bool: Flag to ensure preprocessing result is feasible\n_preprocess_termination_status::MathOptInterface.TerminationStatusCode: Status codes for use in bounds tightening\n_preprocess_primal_status::MathOptInterface.ResultStatusCode: Status codes for use in bounds tightening\n_preprocess_dual_status::MathOptInterface.ResultStatusCode: Status codes for use in bounds tightening\n_lower_primal_status::MathOptInterface.ResultStatusCode: Primal status of the lower problem\n_lower_dual_status::MathOptInterface.ResultStatusCode: Dual status of the lower problem\n_lower_termination_status::MathOptInterface.TerminationStatusCode: Termination status of the lower problem\n_lower_feasibility::Bool: Flag for lower problem feasibility\n_lower_objective_value::Float64: Objective value result from the lower problem\n_lower_solution::Vector{Float64}: Variable values of the lower problem solution\n_lower_lvd::Vector{Float64}: Lower variable duals for use in duality-based bound tightening\n_lower_uvd::Vector{Float64}: Upper variable duals for use in duality-based bound tightening\n_last_cut_objective::Float64: Objective value associated with the previous cut in the cutting planes algorithm\n_upper_result_status::MathOptInterface.ResultStatusCode: Primal status of the upper problem\n_upper_termination_status::MathOptInterface.TerminationStatusCode: Termination status of the upper problem\n_upper_feasibility::Bool: Flag for upper problem feasibility\n_upper_objective_value::Float64: Objective value result from the upper problem\n_upper_variables::Vector{MathOptInterface.VariableIndex}: \n_upper_solution::Vector{Float64}: \n_postprocess_feasibility::Bool: (Unused) Flag to ensure postprocessing result is feasible\n_time_left::Float64: Time remaining for the optimization algorithm. This is set in initial_parse! to the user-defined     time limit and is decremented throughout global_solve!\n_start_time::Float64: Storage for the time() when optimization began\n_run_time::Float64: Current run time, incremented using time()-_start_time\n_parse_time::Float64: A field to keep track of time spent on initial problem parsing\n_presolve_time::Float64: Used in optimize_nonconvex.jl to track how long the presolve step takes\n_last_preprocess_time::Float64: Updated each iteration to track the time of the preprocess step\n_last_lower_problem_time::Float64: Updated each iteration to track the time of the lower problem step\n_last_upper_problem_time::Float64: Updated each iteration to track the time of the upper problem step\n_last_postprocessing_time::Float64: Updated each iteration to track the time of the postprocess step\n_last_printed_iteration::Int64: Updated each time an iteration is printed\n_min_converged_value::Float64: A field to track convergence progress across iterations\n_global_lower_bound::Float64: The best-known lower bound\n_global_upper_bound::Float64: The best-known upper bound\n_maximum_node_id::Int64: The total number of nodes that have been created\n_iteration_count::Int64: The number of iterations the branch-and-bound algorithm has completed\n_node_count::Int64: The number of nodes in the stack\n_solution_value::Float64: (Unused) The best-known solution value\n_feasible_solution_found::Bool: A flag for if a feasible solution was identified. Updated if preprocessing,     lower problem, and upper problem all return feasible values\n_solution_node::Int64: The node ID of the best-known feasible upper problem solution (default = -1, if no feasible solution is found)\n_best_upper_value::Float64: The best-known upper bound\n_obbt_working_lower_index::Vector{Bool}: Indices of variables to perform OBBT on\n_obbt_working_upper_index::Vector{Bool}: Indices of variables to perform OBBT on\n_lower_indx_diff::Vector{Bool}: Tracker for changes in obbtworkinglowerindex across iterations\n_upper_indx_diff::Vector{Bool}: Tracker for changes in obbtworkingupperindex across iterations\n_old_low_index::Vector{Bool}: Storage for indices prior to OBBT step\n_old_upp_index::Vector{Bool}: Storage for indices prior to OBBT step\n_new_low_index::Vector{Bool}: New indices following OBBT step; compared with _old_low_index\n_new_upp_index::Vector{Bool}: New indices following OBBT step; compared with _old_upp_index\n_obbt_variables::Vector{MathOptInterface.VariableIndex}: (Deprecated) Variables to perform OBBT on. Replaced by _obbt_working_lower_index and _obbt_working_upper_index\n_obbt_variable_count::Int64: The number of variables to perform OBBT on\n_obbt_performed_flag::Bool: (Unused) Flag to indicate whether OBBT has been performed\n_lower_fbbt_buffer::Vector{Float64}: Buffer for FBBT lower bounds. Set in presolve, used in preprocess\n_upper_fbbt_buffer::Vector{Float64}: Buffer for FBBT upper bounds. Set in presolve, used in preprocess\n_cp_improvement::Float64: (Unused) Improvement in constraint propagation\n_cp_evaluation_reverse::Bool: (Unused) Flag for if constraint propagation results need to be reversed\n_cut_iterations::Int64: Iterations of the cutting planes algorithm completed\n_cut_add_flag::Bool: (Unused) Flag to check if cuts should be added\n_node_repetitions::Int64: Counter for number of times a node is evaluated. If the repeat_check function     is overloaded to return true, a node will not be branched on, but will instead     be added back into the stack using single_storage!. In this case, _node_repetitions     is incremented\n_log::Log: Storage for logging information during a branch-and-bound run\n_affine_relax_ci::Vector{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}}: Storage for affine constraints\n_affine_objective_cut_ci::Union{Nothing, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}}: Storage for a linear objective cut constraint\n_relaxed_variable_number::Int64: (Unused) Number of relaxed variables\n_relaxed_variable_index::Vector{MathOptInterface.VariableIndex}: Indices of relaxed variables\n_relaxed_variable_et::Vector{Tuple{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.EqualTo{Float64}}, Int64}}: Stored EqualTo constraints\n_relaxed_variable_lt::Vector{Tuple{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}, Int64}}: Stored LessThan constraints\n_relaxed_variable_gt::Vector{Tuple{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.GreaterThan{Float64}}, Int64}}: Stored GreaterThan constraints\n_relaxed_variable_integer::Vector{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.Integer}}: Stored Integer constraints\n_branch_variables::Vector{Bool}: List of variables that can be branched on. If not user-specified, branch variables     are identified in label_branch_variables!\n_nonbranching_int::Bool: (Unused) Flag for non-branching integers\n_new_eval_constraint::Bool: Flag indicating if an initial evaluation of the constraints has occurred\n_new_eval_objective::Bool: Flag indicating if the objective expression was evaluated\n_node_to_sv_leq_ci::Dict{Int64, MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}}: Storage for carrying LessThan constraint information. Used in obbt! and     update_relaxed_problem_box!\n_node_to_sv_geq_ci::Dict{Int64, MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.GreaterThan{Float64}}}: Storage for carrying GreaterThan constraint information. Used in obbt! and     update_relaxed_problem_box!\n_nonlinear_evaluator_created::Bool: Flag to check for nonlinear evaluators. Set to true in add_nonlinear_evaluator!\n_branch_cost::EAGO.BranchCostStorage{Float64}: (FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED) Storage for pseudocost branching\n_branch_variable_sparsity::SparseArrays.SparseMatrixCSC{Bool, Int64}: (FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED) Sparsity information of the     branch variables\n_constraint_infeasiblity::Vector{Float64}: (FUTURE FEATURE, NOT CURRENTLY IMPLEMENTED) Information on the infeasibility     of each constraint\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.Incremental-dev-api_types","page":"Types","title":"EAGO.Incremental","text":"mutable struct Incremental{S<:MathOptInterface.AbstractOptimizer} <: MathOptInterface.AbstractOptimizer\n\nA type-stable cache used to wrapper for an optimizer that enables incremental modification of solvers that don't inherently suppport this. Explicitly checks support of MOI functionality used in EAGO. \n\n(Deprecated) For Q = Val{true}, the subsolver supports incremental loading.  For Q = Val{false}, the subsolver does not.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.InputProblem-dev-api_types","page":"Types","title":"EAGO.InputProblem","text":"mutable struct InputProblem\n\nA structure used to hold objectives and constraints added to the EAGO model. The constraints generally aren't used for relaxations.\n\nAll field information available in extended help.\n\nExtended Help\n\n_variable_count::Int64: Count for the number of variables\n_variable_names::Dict{MathOptInterface.VariableIndex, String}: Dictionary containing variable indices and their names\n_constraint_count::Int64: Count for the number of constraints\n_vi_leq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.LessThan{Float64}}}\n_vi_geq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.GreaterThan{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.GreaterThan{Float64}}}\n_vi_eq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.EqualTo{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.EqualTo{Float64}}}\n_vi_it_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.Interval{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.Interval{Float64}}}\n_vi_zo_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.ZeroOne}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.ZeroOne}}\n_vi_int_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.Integer}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.Integer}}\n_parameter_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VariableIndex, MathOptInterface.Parameter{Float64}}, Tuple{MathOptInterface.VariableIndex, MathOptInterface.Parameter{Float64}}}\n_linear_leq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}, Tuple{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}}\n_linear_geq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, Tuple{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}}\n_linear_eq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}, Tuple{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}}\n_quadratic_leq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}, Tuple{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}}\n_quadratic_geq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, Tuple{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}}\n_quadratic_eq_constraints::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}, Tuple{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}}\n_conic_second_order::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.VectorOfVariables, MathOptInterface.SecondOrderCone}, Tuple{MathOptInterface.VectorOfVariables, MathOptInterface.SecondOrderCone}}\n_linear_leq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}, Float64}\n_linear_geq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, Float64}\n_linear_eq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}, Float64}\n_quadratic_leq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}, Float64}\n_quadratic_geq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, Float64}\n_quadratic_eq_primal::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}, Float64}\n_linear_leq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.LessThan{Float64}}}\n_linear_geq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.GreaterThan{Float64}}}\n_linear_eq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}}\n_quadratic_leq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}}\n_quadratic_geq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.GreaterThan{Float64}}}\n_quadratic_eq_prob_to_ip::Dict{MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.EqualTo{Float64}}}\n_objective::Union{Nothing, MathOptInterface.VariableIndex, MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.ScalarQuadraticFunction{Float64}}: Storage for the objective function\n_nlp_data::Union{Nothing, MathOptInterface.NLPBlockData}: Storage for NLP constraints (set by MOI.set(m, ::NLPBlockData...) in moi_wrapper.jl)\n_optimization_sense::MathOptInterface.OptimizationSense: Objective sense information (set by MOI.set(m, ::ObjectiveSense...))\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.LocalResultStatus-dev-api_types","page":"Types","title":"EAGO.LocalResultStatus","text":"LocalResultStatus\n\nStatus code used internally to determine how to interpret the results from the solution of a local problem solve.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.Log-dev-api_types","page":"Types","title":"EAGO.Log","text":"mutable struct Log\n\nA structure used to store information on the history of the solution procedure for generating convergence plots and other analyses.\n\ncurrent_lower_bound::Vector{Float64}: Storage for lower bound calculated for current node.\ncurrent_upper_bound::Vector{Float64}: Storage for upper bound calculated for current node.\npreprocessing_time::Vector{Float64}: Storage for preprocessing time of each iteration.\nlower_problem_time::Vector{Float64}: Storage for lower bounding time of each iteration.\nupper_problem_time::Vector{Float64}: Storage for upper bounding time of each iteration.\npostprocessing_time::Vector{Float64}: Storage for postprocessing time of each iteration.\npreprocessing_feas::Vector{Bool}: Storage for preprocessing feasibility of each iteration.\nlower_problem_feas::Vector{Bool}: Storage for lower bounding feasibility of each iteration.\nupper_problem_feas::Vector{Bool}: Storage for upper bounding feasibility of each iteration.\npostprocessing_feas::Vector{Bool}: Storage for postprocessing feasibility of each iteration.\nglobal_lower_bound::Vector{Float64}: Storage for best (global) lower bound at each iteration.\nglobal_upper_bound::Vector{Float64}: Storage for best (global) upper bound at each iteration.\nnode_count::Vector{Int64}: Number of nodes at each iteration.\nrun_time::Vector{Float64}: Run time at each iteration.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.Node-dev-api_types","page":"Types","title":"EAGO.Node","text":"struct Node <: EAGO.AbstractNode\n\nDescribes connectivity and expression represented by node.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.NodeBB-dev-api_types","page":"Types","title":"EAGO.NodeBB","text":"struct NodeBB\n\nStore information associated with each node in the branch-and-bound tree.\n\nlower_variable_bounds::Vector{Float64}: Lower bounds of variable box.\nupper_variable_bounds::Vector{Float64}: Upper bounds of variable box.\nis_integer::BitVector: Is dimension integer valued\ncontinuous::Bool: Are all dimensions continuous (or fixed)\nlower_bound::Float64: Lower bound of problem solution on nodeBB\nupper_bound::Float64: Upper bound of problem solution on nodeBB\ndepth::Int64: Depth of node in B&B tree.\ncont_depth::Int64: Depth of first parent in B&B tree that was continuously valued\nid::Int64: Unique ID for each node.\nbranch_direction::EAGO.BranchDirection: Whether last branch was negative or positive in direction\nlast_branch::Int64: Dimension of last branch\nbranch_extent::Float64: Extent of last branch (using for psuedocost calculation)\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.NodeClass-dev-api_types","page":"Types","title":"EAGO.NodeClass","text":"NodeType\n\nEach node in the directed graph can be classified into the following types\n\nVARIABLE: Denotes a decision variable.\nPARAMETER: An adjustable parameter value (not a decision variable).\nCONSTANT: A constant value\nEXPRESSION: Any other expression that isn't a subexpression\nSUBEXPRESSION: Any expression referencing a different graph representation.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.NonlinearExpression-dev-api_types","page":"Types","title":"EAGO.NonlinearExpression","text":"mutable struct NonlinearExpression{V, N, T<:RelaxTag} <: EAGO.AbstractEAGOConstraint\n\nStores a general quadratic function with a buffer.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.Optimizer-dev-api_types","page":"Types","title":"EAGO.Optimizer","text":"mutable struct Optimizer{Q, S, T} <: MathOptInterface.AbstractOptimizer\n\nThe highest level optimizer object used by EAGO to solve problems during the optimization routine. Additional options and temporary storage are located in the _global_optimizer::GlobalOptimizer{Q,S,T} field. Parameters which are expected to be constant over the entire solve are stored in the _parameters::EAGOParameters field.  Some user-facing keywords not in the EAGOParameters field include:\n\nrelaxed_optimizer::MOI.AbstractOptimizer: An instance of the optimizer used to solve    the relaxed subproblems (default = GLPK.Optimizer()). Located in subsolver_block::SubSolvers{Q,S,T}.\nupper_optimizer::MOI.AbstractOptimizer: Optimizer used to solve upper bounding problems    (default = Ipopt.Optimizer()). Located in subsolver_block::SubSolvers{Q,S,T}.\next::ExtensionType: Holds an instance of a subtype of EAGO.ExtensionType, used to define   new custom subroutines (default = DefaultExt()). Located in subsolver_block::SubSolvers{Q,S,T}.\nenable_optimize_hook::Bool: Specifies that the user-defined optimize_hook! function should   be called rather than use the standard EAGO optimization routines. Located in Optimizer   and _global_optimizer::GlobalOptimizer{Q,S,T}.\nobbt_variable_values::Vector{Bool}: Variables to perform OBBT on (default: all variables in nonlinear   expressions). Located in _global_optimizer::GlobalOptimizer{Q,S,T}.\n\nDescriptions of all Optimizer fields available in extended help.\n\nExtended Help\n\nsubsolver_block::SubSolvers{Q, S, T} where {Q, S, T}: Holds definitions of the relaxed and upper optimizers, as well as any user-defined extension types\nenable_optimize_hook::Bool: Specifies that the optimize_hook! function should be called rather than throw the     problem to the standard routine\next::Union{Nothing, T} where T: (Deprecated, use subsolver_block instead) Storage for custom extension types\n_auxiliary_variable_info::Union{Nothing, EAGO._AuxVarData}: Information on any auxiliary variables\n_global_optimizer::GlobalOptimizer{Q, S, T} where {Q, S, T}: Additional options and temporary storage for solving optimization problems\n_input_problem::InputProblem: Expressions and constraints added to the EAGO model (not directly     used for relaxations)\n_working_problem::ParsedProblem: Expressions and problem descriptions that EAGO uses to formulate     relaxed problems\n_parameters::EAGOParameters: Parameters that do not change during a global solve\n_optimizer_attributes_set::Vector{MathOptInterface.AbstractOptimizerAttribute}: Set of optimizer attributes\n_termination_status_code::MathOptInterface.TerminationStatusCode: The MathOptInterface-compliant completion status code\n_result_status_code::MathOptInterface.ResultStatusCode: Value indicating the feasibility status of the result\n_run_time::Float64: Optimization run time\n_objective_value::Float64: The objective value of the primal solution\n_objective_bound::Float64: The best-known bound on the optimal objective value\n_relative_gap::Float64: The gap between the upper and lower bound, relative to the bound with the larger magnitude\n_iteration_count::Int64: The number of iterations the branch-and-bound algorithm has completed\n_node_count::Int64: The number of nodes in the stack\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.ParsedProblem-dev-api_types","page":"Types","title":"EAGO.ParsedProblem","text":"mutable struct ParsedProblem\n\nA structure used to store expressions and problem descriptions EAGO uses to formulate relaxed problems.\n\nAll field information available in extended help.\n\nExtended Help\n\n_problem_type::Union{Nothing, EAGO.DIFF_CVX, EAGO.LP, EAGO.MILP, EAGO.MINCVX, EAGO.MISOCP, EAGO.SOCP}: Problem classification (set in parse_classify_problem!)\n_objective_saf::MathOptInterface.ScalarAffineFunction{Float64}: Stores the objective and is used for constructing linear affine cuts\n_objective::Union{Nothing, MathOptInterface.VariableIndex, EAGO.AffineFunctionIneq, EAGO.BufferedQuadraticIneq, EAGO.BufferedNonlinearFunction}: Storage for the objective function\n_optimization_sense::MathOptInterface.OptimizationSense: Objective sense information (set by MOI.set(m, ::ObjectiveSense...))\n_saf_leq::Vector{EAGO.AffineFunctionIneq}\n_saf_eq::Vector{EAGO.AffineFunctionEq}\n_sqf_leq::Vector{EAGO.BufferedQuadraticIneq}\n_sqf_eq::Vector{EAGO.BufferedQuadraticEq}\n_conic_second_order::Vector{EAGO.BufferedSOC}\n_nlp_data::Union{Nothing, MathOptInterface.NLPBlockData}\n_nonlinear_constr::Vector{EAGO.BufferedNonlinearFunction}\n_relaxed_evaluator::Evaluator\n_variable_info::Vector{VariableInfo{Float64}}: Variable information (set in initial_parse!)\n_variable_count::Int64: Count for the number of variables\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.Relax-dev-api_types","page":"Types","title":"EAGO.Relax","text":"Relax\n\nUsed to dispatch relaxations to a standard \n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.RelaxAA-dev-api_types","page":"Types","title":"EAGO.RelaxAA","text":"RelaxAA\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.RelaxMulEnum-dev-api_types","page":"Types","title":"EAGO.RelaxMulEnum","text":"RelaxMulEnum\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.RelaxResultStatus-dev-api_types","page":"Types","title":"EAGO.RelaxResultStatus","text":"RelaxResultStatus\n\nStatus code used internally to determine how to interpret the results from the solution of a relaxed problem.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.SIPHybrid-dev-api_types","page":"Types","title":"EAGO.SIPHybrid","text":"SIPHybrid\n\nSpecifies that the SIPHybrid algorithm which implements Algorithm #2 of Djelassi, Hatim, and Alexander Mitsos. \"A hybrid discretization algorithm with guaranteed feasibility for the global solution of semi-infinite programs.\" Journal of Global Optimization 68.2 (2017): 227-253 should be used.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.SIPProblem-dev-api_types","page":"Types","title":"EAGO.SIPProblem","text":"  SIPProblem\n\nStructure storing problem information for the solution routine.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.SIPRes-dev-api_types","page":"Types","title":"EAGO.SIPRes","text":"SIPRes\n\nSpecifies that the SIPRes algorithm which implements Algorithm #1 of Djelassi, Hatim, and Alexander Mitsos. \"A hybrid discretization algorithm with guaranteed feasibility for the global solution of semi-infinite programs.\" Journal of Global Optimization 68.2 (2017): 227-253 should be used.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.SIPResRev-dev-api_types","page":"Types","title":"EAGO.SIPResRev","text":"SIPResRev\n\nSpecifies that the SIPResRev algorithm which implements Algorithm #1 of Djelassi, Hatim, and Alexander Mitsos. \"A hybrid discretization algorithm with guaranteed feasibility for the global solution of semi-infinite programs.\" Journal of Global Optimization 68.2 (2017): 227-253 should be used.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.SIPResult-dev-api_types","page":"Types","title":"EAGO.SIPResult","text":"SIPResult\n\nStructure storing the results of the SIPRes algorithm.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.SIPSubResult-dev-api_types","page":"Types","title":"EAGO.SIPSubResult","text":"SIPBuffer\n\nHold objective value, solution, discretization set, and feasibility status of each subproblem encountered by SIP algorithm.\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.SubSolvers-dev-api_types","page":"Types","title":"EAGO.SubSolvers","text":"mutable struct SubSolvers{Q<:MathOptInterface.AbstractOptimizer, S<:MathOptInterface.AbstractOptimizer, T<:ExtensionType}\n\nA structure containing the relaxed and upper optimizers to be used, as well as any user-defined extension.\n\nrelaxed_optimizer::MathOptInterface.AbstractOptimizer: Optimizer used to solve relaxed subproblems. Set using r = [...] (<: MOI.AbstractOptimizer)         (default = GLPK.Optimizer())\nupper_optimizer::MathOptInterface.AbstractOptimizer: Optimizer used to solve upper bounding problems. Set using u = [...] (<: MOI.AbstractOptimizer)         (default = Ipopt.Optimizer())\next::ExtensionType: User-defined extension to use. Set using t = [...](<: EAGO.ExtensionType)\n\n\n\n\n\n","category":"type"},{"location":"dev/api_types/#EAGO.VariableInfo-dev-api_types","page":"Types","title":"EAGO.VariableInfo","text":"struct VariableInfo{T<:AbstractFloat}\n\nA structure used to store information related to the bounds assigned to each variable.\n\nis_integer::Bool: Is the variable integer valued?\nhas_lower_bound::Bool: Boolean indicating whether a finite lower bound exists.\nhas_upper_bound::Bool: Boolean indicating whether a finite upper bound exists.\nis_fixed::Bool: Boolean indicating if variable is fixed to a finite value.\nhas_constraints::Bool: Boolean indicating that constraints have been set\nlower_bound::AbstractFloat: Lower bound. May be -Inf.\nupper_bound::AbstractFloat: Upper bound. May be Inf.\n\n\n\n\n\n","category":"type"},{"location":"examples/quasiconvex/#Advanced-Use-Example-1","page":"Advanced-Use Example 1","title":"Advanced-Use Example 1","text":"This example is also provided here as a Jupyter Notebook.","category":"section"},{"location":"examples/quasiconvex/#Customizing-EAGO-to-Solve-a-Quasiconvex-Problem","page":"Advanced-Use Example 1","title":"Customizing EAGO to Solve a Quasiconvex Problem","text":"In this example, we'll adapt EAGO to implement the bisection-based algorithm used to solve a quasiconvex optimization problem presented in [1]:\n\nbeginaligned\nf^* =  min_mathbf y in Y f(mathbf y) \nrm st    sum_i = 1^5 i cdot y_i - 5 = 0 \n sum_i = 1^5 y_i^2 - 05 pi leq 0 \n -bigg(frac12 y_1^2 + frac12 y_2^2 + 2 y_1 y_2 + 4 y_1 y_3 + 2 y_2 y_3 bigg) leq 0 \n -y_1^2 - 6 y_1 y_2 - 2 y_2^2 + cos (y_1) + pi leq 0 \n Y = 0 5^5\nendaligned\n\nwhere\n\nbeginaligned\nf(mathbf y) = -fracln ((5 + y_1)^2 + sum_i = 1^5 y_i)1 + sum_i = 1^5 y_i^2\nendaligned\n\nInterval analysis shows that the objective value is bounded by the interval F such that f^* in F = f^L f^U = -5 0. Introducing an auxiliary variable t in T = F allows the problem to be formulated as:\n\nbeginaligned\nt^* =  min_mathbf y in Y t in T t \nrm st    (24) - (27) \n f(mathbf y) - t leq 0 \n Y = 05^2   T = -50\nendaligned\n\nLet phi_tau(mathbf y) = f(mathbf y) - tau such that tau = (t^L + t^U)2. We solve for mathbf y subject to constraints (24) - (27) where phi_tau (mathbf y) leq 0. If this is feasible, t^* in t^Ltau, else t^* in τ t^U. The interval containing t^* is kept and the other is fathomed. This manner of bisection is repeated until an interval containing a feasible solution with a width of at most epsilon is located [2].","category":"section"},{"location":"examples/quasiconvex/#Customizing-EAGO's-Script","page":"Advanced-Use Example 1","title":"Customizing EAGO's Script","text":"First, the preprocessing step, upper problem, and postprocessing routines are short-circuited as only a single optimization problem needs to be solved at each iteration.\n\nusing MathOptInterface, EAGO, JuMP\nimport EAGO: Optimizer, GlobalOptimizer\n\nstruct QuasiConvex <: EAGO.ExtensionType end\nimport EAGO: preprocess!, upper_problem!, postprocess!\nfunction EAGO.preprocess!(t::QuasiConvex, x::GlobalOptimizer)\n    x._preprocess_feasibility = true\nend\nfunction EAGO.upper_problem!(t::QuasiConvex, x::GlobalOptimizer)\n    x._upper_feasibility = true\nend\nfunction EAGO.postprocess!(t::QuasiConvex, x::GlobalOptimizer)\n    x._postprocess_feasibility = true\nend\n\nNext, we specify that only an absolute tolerance should be checked for convergence and termination.\n\nimport EAGO: convergence_check, termination_check\nfunction EAGO.convergence_check(t::QuasiConvex, x::GlobalOptimizer)\n    gap = (x._upper_objective_value - x._lower_objective_value)\n    return (gap <= x._parameters.absolute_tolerance)\nend\nfunction EAGO.termination_check(t::QuasiConvex, x::GlobalOptimizer)\n    flag = EAGO.convergence_check(t, x)\n    if flag\n        x._end_state = EAGO.GS_OPTIMAL\n        x._termination_status_code = MathOptInterface.OPTIMAL\n        x._result_status_code = MathOptInterface.FEASIBLE_POINT\n    end\n    return flag\nend\n\nWe then indicate that only the sixth variable, representing t, should be branched on. Since we will apply our knowledge about which t^* should be kept in the lower problem definition, we also short-circuit the EAGO.repeat_check function here to tell EAGO not to branch this node, but instead to repeatedly evaluate it.\n\nimport EAGO: repeat_check\nbranch_variable = [i == 6 for i=1:6]\nEAGO.repeat_check(t::QuasiConvex, x::GlobalOptimizer) = true\n\nIn the lower problem, we then specify that the problem is to be solved locally for a fixed t value. The objective value is then updated and the problem is contracted in order to discard the region which is known to not contain the optimal value.\n\nimport EAGO: lower_problem!\nfunction EAGO.lower_problem!(t::QuasiConvex, x::GlobalOptimizer)\n    y = x._current_node\n    indx = x._sol_to_branch_map[6]\n    lower = y.lower_variable_bounds[indx]\n    upper = y.upper_variable_bounds[indx]\n    midy = (lower + upper)/2.0\n    y.lower_variable_bounds[indx] = midy\n    y.upper_variable_bounds[indx] = midy\n    EAGO.solve_local_nlp!(x)\n    feas = x._upper_feasibility\n    y.lower_variable_bounds[indx] = feas ? lower : midy\n    y.upper_variable_bounds[indx] = feas ? midy : upper\n    x._lower_objective_value = y.lower_variable_bounds[indx]\n    x._upper_objective_value = y.upper_variable_bounds[indx]\n    x._lower_feasibility = true\n    return\nend\n\nWe now define the optimizer factory to extend the core EAGO optimizer for this special problem. The SubSolvers constructor is used to set the extension type (t), as well as the relaxed optimizer (r) and upper-bounding optimizer (u), if necessary. In this case, we will use the default solvers and only set the extension type.\n\nfactory = () -> Optimizer(SubSolvers(; t = QuasiConvex()))","category":"section"},{"location":"examples/quasiconvex/#Construct-the-JuMP-Model-and-Optimize","page":"Advanced-Use Example 1","title":"Construct the JuMP Model and Optimize","text":"We now build the JuMP [3] model representing this problem, solve it, and retrieve the solution.\n\nopt = optimizer_with_attributes(factory, \n                                \"absolute_tolerance\" => 1E-8, \n                                \"branch_variable\" => branch_variable,\n                                \"iteration_limit\" => 1000)\nm = Model(opt)\n@variable(m, ((i<6) ? 0.0 : -5.0) <= y[i=1:6] <= ((i<6) ? 5.0 : 0.0))\n@constraint(m, sum(i*y[i] for i=1:5) - 5.0 == 0.0)\n@constraint(m, sum(y[i]^2 for i=1:5) - 0.5*pi^2 <= 0.0)\n@expression(m, expr1, 2.0*y[1]*y[2] + 4.0*y[1]*y[3] + 2.0*y[2]*y[3])\n@constraint(m, -(0.5*y[1]^2 + 0.5*y[2]^2 + y[3]^2 + expr1) <= 0.0)\n@NLexpression(m, expr2, log((5.0 + y[1])^2 + sum(y[i] for i=1:5)))\n@NLconstraint(m, -y[1]^2 - 6.0*y[1]*y[2] - 2.0*y[2]^2 + cos(y[1]) + pi <= 0.0)\n@NLconstraint(m, -expr2/(1.0 + sum(y[i]^2 for i=1:5)) - y[6] <= 0.0)\n@objective(m, Min, y[6])\n\nJuMP.optimize!(m)","category":"section"},{"location":"examples/quasiconvex/#Retrieve-Results","page":"Advanced-Use Example 1","title":"Retrieve Results","text":"We then recover the solution values and the objective value using standard JuMP syntax.\n\nsolution = JuMP.value.(y[1:5])\nglobal_obj_value = JuMP.value.(y[6])\nprint(\"Global solution at y*=$solution with a value of f*=$global_obj_value\")","category":"section"},{"location":"examples/quasiconvex/#References","page":"Advanced-Use Example 1","title":"References","text":"C. Jansson, Quasiconvex relaxations based on interval arithmetic, Linear Algebra and its Applications, 324 (2001), pp. 27–53.\nS. Boyd and L. Vandenberghe, Convex optimization, Cambridge University Press, 2004.\nIain Dunning and Joey Huchette and Miles Lubin. JuMP: A Modeling Language for Mathematical Optimization, SIAM Review, 59 (2017), pp. 295-320.","category":"section"},{"location":"semiinfinite/semiinfinite/#Solving-Semi-Infinite-Programs","page":"Semi-Infinite Programming","title":"Solving Semi-Infinite Programs","text":"","category":"section"},{"location":"semiinfinite/semiinfinite/#Using-EAGO-to-Solve-a-Semi-Infinite-Program","page":"Semi-Infinite Programming","title":"Using EAGO to Solve a Semi-Infinite Program","text":"This example is also provided here as a Jupyter Notebook.\n\nSemi-infinite programming remains an active area of research. In general, the solutions of semi-infinite programs (SIPs) with nonconvex semi-infinite constraints of the following form are extremely challenging:\n\nbeginaligned\nf^* =  min_mathbf x in X f(mathbf x) \nrm st    g(mathbf x mathbf p) leq 0     forall mathbf p in P \n mathbf x in X =  mathbf x in mathbb R^n_x  mathbf x^L leq mathbf x leq mathbf x^U  \n P =  mathbf p in mathbb R^n_p  mathbf p^L leq mathbf p leq mathbf p^U \nendaligned\n\nEAGO implements three different algorithms detailed in [1, 2] to determine a globally optimal solution to problems of the above form. This is accomplished using the sip_solve function which returns the optimal value, the solution, and a boolean feasibility flag. To illustrate the use of this function, a simple example is presented here which solves the problem:\n\nbeginaligned\nf(mathbf x)  = frac13 x_1^2 + x_2^2 + fracx_12 \ng(mathbf x p)  = (1 - x_1^2 p^2)^2 - x_1 p^2 - x_2^2 + x_2 leq 0 \n mathbf x in X = -1000 1000^2 \n p in P = 0 1\nendaligned\n\nusing EAGO, JuMP\n\n# Define semi-infinite program\nf(x) = (1/3)*x[1]^2 + x[2]^2 + x[1]/2\ngSIP(x, p) = (1.0 - x[1]^2*p[1]^2)^2 - x[1]*p[1]^2 - x[2]^2 + x[2]\n\nx_l = Float64[-1000.0, -1000.0]\nx_u = Float64[1000.0, 1000.0]\np_l = Float64[0.0]\np_u = Float64[1.0]\n\nsip_result = sip_solve(SIPRes(), x_l, x_u, p_l, p_u, f, Any[gSIP], res_sip_absolute_tolerance = 1E-3);","category":"section"},{"location":"semiinfinite/semiinfinite/#Semi-Infinite-Solver","page":"Semi-Infinite Programming","title":"Semi-Infinite Solver","text":"","category":"section"},{"location":"semiinfinite/semiinfinite/#References","page":"Semi-Infinite Programming","title":"References","text":"Mitsos A (2009). Global optimization of semi-infinite programs via restriction of the right-hand side. Optimization, 60(10-11):1291-1308.\nDjelassi, Hatim, and Alexander Mitsos. A hybrid discretization algorithm with guaranteed feasibility for the global solution of semi-infinite programs. Journal of Global Optimization, 68.2 (2017): 227-253 should be used.","category":"section"},{"location":"semiinfinite/semiinfinite/#EAGO.SIPProblem","page":"Semi-Infinite Programming","title":"EAGO.SIPProblem","text":"  SIPProblem\n\nStructure storing problem information for the solution routine.\n\n\n\n\n\n","category":"type"},{"location":"semiinfinite/semiinfinite/#EAGO.SIPResult","page":"Semi-Infinite Programming","title":"EAGO.SIPResult","text":"SIPResult\n\nStructure storing the results of the SIPRes algorithm.\n\n\n\n\n\n","category":"type"},{"location":"semiinfinite/semiinfinite/#EAGO.SIPRes","page":"Semi-Infinite Programming","title":"EAGO.SIPRes","text":"SIPRes\n\nSpecifies that the SIPRes algorithm which implements Algorithm #1 of Djelassi, Hatim, and Alexander Mitsos. \"A hybrid discretization algorithm with guaranteed feasibility for the global solution of semi-infinite programs.\" Journal of Global Optimization 68.2 (2017): 227-253 should be used.\n\n\n\n\n\n","category":"type"},{"location":"semiinfinite/semiinfinite/#EAGO.SIPResRev","page":"Semi-Infinite Programming","title":"EAGO.SIPResRev","text":"SIPResRev\n\nSpecifies that the SIPResRev algorithm which implements Algorithm #1 of Djelassi, Hatim, and Alexander Mitsos. \"A hybrid discretization algorithm with guaranteed feasibility for the global solution of semi-infinite programs.\" Journal of Global Optimization 68.2 (2017): 227-253 should be used.\n\n\n\n\n\n","category":"type"},{"location":"semiinfinite/semiinfinite/#EAGO.SIPHybrid","page":"Semi-Infinite Programming","title":"EAGO.SIPHybrid","text":"SIPHybrid\n\nSpecifies that the SIPHybrid algorithm which implements Algorithm #2 of Djelassi, Hatim, and Alexander Mitsos. \"A hybrid discretization algorithm with guaranteed feasibility for the global solution of semi-infinite programs.\" Journal of Global Optimization 68.2 (2017): 227-253 should be used.\n\n\n\n\n\n","category":"type"},{"location":"semiinfinite/semiinfinite/#EAGO.get_sip_optimizer","page":"Semi-Infinite Programming","title":"EAGO.get_sip_optimizer","text":"get_sip_optimizer\n\nSpecifices the optimizer to be used in extension t::EAGO.ExtensionType with algorithm alg::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command get_sip_optimizer(t::ExtensionType, alg::AbstractSIPAlgo, s::AbstractSubproblemType).\n\n\n\n\n\n","category":"function"},{"location":"semiinfinite/semiinfinite/#EAGO.build_model","page":"Semi-Infinite Programming","title":"EAGO.build_model","text":"build_model\n\nCreate the model and variables used with extension t::EAGO.ExtensionType in algorithm a::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command build_model(t::ExtensionType, a::AbstractSIPAlgo, s::AbstractSubproblemType, p::SIPProblem).\n\n\n\n\n\n","category":"function"},{"location":"semiinfinite/semiinfinite/#EAGO.sip_llp!","page":"Semi-Infinite Programming","title":"EAGO.sip_llp!","text":"sip_llp!\n\nSolves the lower level problem for the ith-SIP used with extension t::EAGO.ExtensionType in algorithm a::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command  sip_llp!(t::ExtensionType, a::AbstractSIPAlgo, s::AbstractSubproblemType, ..., i, tol).\n\n\n\n\n\n","category":"function"},{"location":"semiinfinite/semiinfinite/#EAGO.sip_bnd!","page":"Semi-Infinite Programming","title":"EAGO.sip_bnd!","text":"sip_bnd!\n\nSolves the bounding problem for the ith-SIP used with extension t::EAGO.ExtensionType in algorithm a::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command sip_bnd!(t::ExtensionType, a::AbstractSIPAlgo, s::AbstractSubproblemType, ..., i, tol).\n\n\n\n\n\n","category":"function"},{"location":"semiinfinite/semiinfinite/#EAGO.sip_res!","page":"Semi-Infinite Programming","title":"EAGO.sip_res!","text":"sip_res!\n\nSolves the restriction problem for extension t::EAGO.ExtensionType in algorithm a::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command sip_res!(t::ExtensionType, a::AbstractSIPAlgo, ...).\n\n\n\n\n\n","category":"function"},{"location":"semiinfinite/semiinfinite/#EAGO.sip_solve","page":"Semi-Infinite Programming","title":"EAGO.sip_solve","text":"sip_solve\n\nSolve an SIP with decision variable bounds x_l to x_u, uncertain variable bounds p_l to p_u, an objective function of f, and gSIP seminfiniite constraint(s).\n\n\n\n\n\n","category":"function"},{"location":"examples/interval_bb/#Standard-Use-Example-2","page":"Standard-Use Example 2","title":"Standard-Use Example 2","text":"This example is also provided here as a Jupyter Notebook.","category":"section"},{"location":"examples/interval_bb/#Using-EAGO's-Basic-Optimizer-With-User-Defined-Subroutines","page":"Standard-Use Example 2","title":"Using EAGO's Basic Optimizer With User-Defined Subroutines","text":"In this section, we construct an optimizer that uses EAGO's basic NLP solution routine with user-defined lower and upper-bounding problems. The Optimizer structure supplies a number of parameters and stored structures that advanced users may find useful for constructing specialized solution routines.\n\nIn this example, we'll forgo extensive integration into the Optimizer and simply replace the lower and upper-bounding problems to construct a B&B routine that solves the following problem to global optimality using bounds obtained from interval arithmetic:\n\nbeginaligned\n min_mathbf x in X   sin(x_1) x_2^2 - cos(x_3)  x_4 \n X = -10 10 times -1 1 times -10 10 times 2 20\nendaligned\n\nWe begin by importing EAGO, IntervalArithmetic [1], and JuMP [2].\n\nusing EAGO, IntervalArithmetic, JuMP\n\nWe now define the IntervalExt struct as a subtype of the ExtensionType.\n\nstruct IntervalExt <: EAGO.ExtensionType end","category":"section"},{"location":"examples/interval_bb/#Define-a-Custom-Lower-Bounding-Problem","page":"Standard-Use Example 2","title":"Define a Custom Lower-Bounding Problem","text":"A valid lower bound is obtained from the lower bound of the natural interval extension using the IntervalArithmetic.jl [1] package. The LowerProblem is dispatched using the new IntervalExt structure and the GlobalOptimizer structure, computes the bound using interval arithmetic, and stores the results to the appropriate field of the GlobalOptimizer. Note that the problem is unconstrained on the domain so we can assume it is always feasible. Further, since the interval bound is constrained along the entire domain associated with a node, no additional cuts will be beneficial and thus we've disabled them using the _cut_add_flag field.\n\nimport EAGO: lower_problem!\nfunction lower_problem!(t::IntervalExt, x::EAGO.GlobalOptimizer)\n    # Retrieve bounds at current node\n    n = x._current_node\n    lower = n.lower_variable_bounds\n    upper = n.upper_variable_bounds\n    \n    # Define X for the node and compute the interval extension\n    x_value = Interval.(lower, upper)\n    F = sin(x_value[1])*x_value[2]^2 - cos(x_value[3])/x_value[4]\n    x._lower_objective_value = F.lo\n    x._lower_solution = IntervalArithmetic.mid.(x_value)\n    x._lower_feasibility = true\n    x._cut_add_flag = false\n    \n    return\nend","category":"section"},{"location":"examples/interval_bb/#Define-a-Custom-Upper-Bounding-Problem","page":"Standard-Use Example 2","title":"Define a Custom Upper-Bounding Problem","text":"Since the problem is unconstrained, any feasible point represents a valid upper bound. Thus, if we arbitrarily evaluate the function at the midpoint, we obtain a valid upper bound. This function constructs an upper bound in this manner then stores the results to the appropriate field of the GlobalOptimizer.\n\nimport EAGO.upper_problem!\nfunction EAGO.upper_problem!(t::IntervalExt, x::EAGO.GlobalOptimizer)\n    # Retrieve bounds at current node\n    n = x._current_node\n    lower = n.lower_variable_bounds\n    upper = n.upper_variable_bounds\n    \n    # Compute midpoint value and evaluate at that point\n    x_value = 0.5*(upper + lower)\n    f_val = sin(x_value[1])*x_value[2]^2-cos(x_value[3])/x_value[4]\n    x._upper_objective_value = f_val\n    x._upper_solution = x_value\n    x._upper_feasibility = true\n    \n    return\nend","category":"section"},{"location":"examples/interval_bb/#Disable-Unnecessary-Routines","page":"Standard-Use Example 2","title":"Disable Unnecessary Routines","text":"It is entirely possible to disable domain reduction by manipulating keyword arguments supplied to the optimizer. However, for simplicity's sake we'll simply overload the default preprocessing and postprocessing methods and indicate that there are no conditions under which EAGO should cut the node.\n\nimport EAGO: preprocess!, postprocess!, cut_condition\nfunction EAGO.preprocess!(t::IntervalExt, x::EAGO.GlobalOptimizer)\n    x._preprocess_feasibility = true\n    return\nend\nfunction EAGO.postprocess!(t::IntervalExt, x::EAGO.GlobalOptimizer)\n    x._postprocess_feasibility = true\n    return\nend\nEAGO.cut_condition(t::IntervalExt, x::EAGO.GlobalOptimizer) = false","category":"section"},{"location":"examples/interval_bb/#Construct-the-JuMP-Model-and-Optimize","page":"Standard-Use Example 2","title":"Construct the JuMP Model and Optimize","text":"We now add our optimizer to a JuMP [2] model, provide variable bounds, and optimize.\n\n# Create a factory that specifies the interval extension in EAGO's SubSolver\nfactory = () -> EAGO.Optimizer(SubSolvers(; t = IntervalExt()))\n\n# Create a JuMP model using the factory, and with the absolute tolerance set by keyword argument\nm = Model(optimizer_with_attributes(factory,\n                    \"absolute_tolerance\" => 0.001\n        ))\n\n# Add variables, bounds, and the objective function\nx_L = [-10.0, -1.0, -10.0, 2.0]\nx_U = [10.0, 1.0, 10.0, 20.0]\n@variable(m, x_L[i] <= x[i=1:4] <= x_U[i])\n@NLobjective(m, Min, sin(x[1])*x[2]^2 - cos(x[3])/x[4])\n\n# Perform the optimization\noptimize!(m)","category":"section"},{"location":"examples/interval_bb/#Retrieve-Results","page":"Standard-Use Example 2","title":"Retrieve Results","text":"The objective value, solution, termination status, and primal status can then be accessed via the standard JuMP interface.\n\nfval = JuMP.objective_value(m)\nxsol = JuMP.value.(x)\nstatus_term = JuMP.termination_status(m)\nstatus_prim = JuMP.primal_status(m)\n\nprintln(\"EAGO terminated with a status of $status_term and a result code of $status_prim\")\nprintln(\"The optimal value is: $(round(fval, digits=3)), the solution found is $(round.(xsol, digits=4)).\")","category":"section"},{"location":"examples/interval_bb/#Advice-for-More-Advanced-Constructions","page":"Standard-Use Example 2","title":"Advice for More Advanced Constructions","text":"The default lower_problem! and upper_problem! should be used as templates for error handling and retrieving information from MOI models.\n\nEssentially all of EAGO's subroutines stored to a field in the Optimizer structure can be reset as user-defined functions.","category":"section"},{"location":"examples/interval_bb/#References","page":"Standard-Use Example 2","title":"References","text":"IntervalArithmetic.jl [Computer software] (2019). Retrieved from https://github.com/JuliaIntervals/IntervalArithmetic.jl\nIain Dunning and Joey Huchette and Miles Lubin. JuMP: A Modeling Language for Mathematical Optimization, SIAM Review, SIAM 59 (2017), pp. 295-320.","category":"section"},{"location":"cite/#Citing-EAGO","page":"Citing EAGO","title":"Citing EAGO","text":"Please cite the following paper when using EAGO.jl:\n\nWilhelm, M.E. and Stuber, M.D. EAGO.jl: easy advanced global optimization in Julia.\nOptimization Methods and Software. 37(2): 425-450 (2022). DOI: 10.1080/10556788.2020.1786566","category":"section"},{"location":"dev/api_functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"dev/api_functions/#EAGO._add_constraint_store_ci!-Union{Tuple{S}, Tuple{F}, Tuple{Any, InputProblem, Type{F}, Type{S}}} where {F, S}-dev-api_functions","page":"Functions","title":"EAGO._add_constraint_store_ci!","text":"_add_constraint_store_ci!(\n    d,\n    m::InputProblem,\n    _::Type{F},\n    _::Type{S}\n)\n\n\nAdd a constraint to the local problem, storing the new constraint index and the associated index in the input problem.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._add_constraint_store_ci_linear!-Tuple{Any, InputProblem}-dev-api_functions","page":"Functions","title":"EAGO._add_constraint_store_ci_linear!","text":"_add_constraint_store_ci_linear!(d, ip::InputProblem)\n\n\nAdd linear constraints to the local problem, storing the new constraint indices and the associated indices in the input problem.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._add_constraint_store_ci_quadratic!-Tuple{Any, InputProblem}-dev-api_functions","page":"Functions","title":"EAGO._add_constraint_store_ci_quadratic!","text":"_add_constraint_store_ci_quadratic!(d, ip::InputProblem)\n\n\nAdd quadratic constraints to the local problem, storing the new constraint indices and the associated indices in the input problem.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._bvi-Tuple{GlobalOptimizer, Int64}-dev-api_functions","page":"Functions","title":"EAGO._bvi","text":"_bvi(m::GlobalOptimizer, i::Int64) -> Int64\n\n\nReturn the branch-to-sol mapping for the i'th variable.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._constraint_primal-Union{Tuple{S}, Tuple{F}, Tuple{GlobalOptimizer, Type{F}, Type{S}}} where {F, S}-dev-api_functions","page":"Functions","title":"EAGO._constraint_primal","text":"_constraint_primal\n\nHelper function which simplifies finding constraints of different types. See also: _constraints\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._constraints-Tuple{Optimizer, Type{MathOptInterface.VariableIndex}, Type{MathOptInterface.LessThan{Float64}}}-dev-api_functions","page":"Functions","title":"EAGO._constraints","text":"_constraints\n\nHelper function which simplifies finding constraints of different types. See also: _constraint_primal\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._diam-Tuple{EAGO.BranchVar, GlobalOptimizer, Int64}-dev-api_functions","page":"Functions","title":"EAGO._diam","text":"_diam(::BranchVar, ::GlobalOptimizer, ::Int)\n_diam(::FullVar, ::GlobalOptimizer, ::Int)\n\nReturn the diameter of a variable (upper bound - lower bound).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._ext-Union{Tuple{SubSolvers{Q, S, T}}, Tuple{T}, Tuple{S}, Tuple{Q}} where {Q<:MathOptInterface.AbstractOptimizer, S<:MathOptInterface.AbstractOptimizer, T<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO._ext","text":"_ext(::Optimizer)\n_ext(::GlobalOptimizer)\n_ext(::SubSolvers)\n\nReturn the extension (<: ExtensionType) from the SubSolvers (sub)field or object.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._extract_primal!-Union{Tuple{S}, Tuple{F}, Tuple{Any, InputProblem, Type{F}, Type{S}}} where {F, S}-dev-api_functions","page":"Functions","title":"EAGO._extract_primal!","text":"_extract_primal!(d, m::InputProblem, _::Type{F}, _::Type{S})\n\n\nExtract primal constraint value from the local problem and save the result to the appropriate field of the optimizer.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._extract_primal_linear!-Tuple{Any, InputProblem}-dev-api_functions","page":"Functions","title":"EAGO._extract_primal_linear!","text":"_extract_primal_linear!(d, ip::InputProblem)\n\n\nExtract linear primal constraint values from the local problem and save the result to the appropriate field of the optimizer.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._extract_primal_quadratic!-Tuple{Any, InputProblem}-dev-api_functions","page":"Functions","title":"EAGO._extract_primal_quadratic!","text":"_extract_primal_quadratic!(d, ip::InputProblem)\n\n\nExtract quadratic primal constraint values from the local problem and save the result to the appropriate field of the optimizer.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._is_branch_var-Tuple{GlobalOptimizer, Any}-dev-api_functions","page":"Functions","title":"EAGO._is_branch_var","text":"_is_branch_var(m::GlobalOptimizer, i) -> Any\n\n\nCheck if m._branch_variables[i] is true or false.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._is_input_min-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO._is_input_min","text":"_is_input_min(m::GlobalOptimizer) -> Bool\n\n\nCheck to see if the sense of the optimization problem is Min (true) or Max (false).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._relaxed_optimizer-Union{Tuple{SubSolvers{Q, S, T}}, Tuple{T}, Tuple{S}, Tuple{Q}} where {Q<:MathOptInterface.AbstractOptimizer, S<:MathOptInterface.AbstractOptimizer, T<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO._relaxed_optimizer","text":"_relaxed_optimizer(::GlobalOptimizer)\n_relaxed_optimizer(::SubSolvers)\n\nReturn the relaxed optimizer (<: MOI.AbstractOptimizer) from the SubSolvers field or object.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._svi-Tuple{GlobalOptimizer, Int64}-dev-api_functions","page":"Functions","title":"EAGO._svi","text":"_svi(m::GlobalOptimizer, i::Int64) -> Int64\n\n\nReturn the sol-to-branch mapping for the i'th variable.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO._upper_optimizer-Union{Tuple{SubSolvers{Q, S, T}}, Tuple{T}, Tuple{S}, Tuple{Q}} where {Q<:MathOptInterface.AbstractOptimizer, S<:MathOptInterface.AbstractOptimizer, T<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO._upper_optimizer","text":"_upper_optimizer(::GlobalOptimizer)\n_upper_optimizer(::SubSolvers)\n\nReturn the upper optimizer (<: MOI.AbstractOptimizer) from the SubSolvers field or object.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.add_nonlinear!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.add_nonlinear!","text":"add_nonlinear!(m::GlobalOptimizer)\n\n\nAdd an Evaluator and nonlinear functions and populate each appropriately.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.add_nonlinear_evaluator!-Tuple{GlobalOptimizer, Nothing}-dev-api_functions","page":"Functions","title":"EAGO.add_nonlinear_evaluator!","text":"add_nonlinear_evaluator!\n\nAdd an Evaluator structure if nonlinear terms are attached.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.add_objective!-Tuple{ParsedProblem, Any}-dev-api_functions","page":"Functions","title":"EAGO.add_objective!","text":"add_objective!\n\nAdd objective function (if any) to the parsed problem.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.affine_relax_quadratic!-Tuple{GlobalOptimizer, MathOptInterface.ScalarQuadraticFunction{Float64}, Dict{Int64, Float64}, MathOptInterface.ScalarAffineFunction{Float64}}-dev-api_functions","page":"Functions","title":"EAGO.affine_relax_quadratic!","text":"affine_relax_quadratic!\n\nDefault routine for relaxing quadratic constraint func < 0.0 on node n. Takes affine bounds of convex part at point x0 and secant line bounds on concave parts. This approach comes from Section 2.4.3.2 of: Vigerske, S. and Gleixner, A. \"SCIP: global optimization of mixed-integer  nonlinear programs in a branch-and-cut framework\". Optimization Methods  and Software, 33:3, 563-593 (2018). DOI: 10.1080/10556788.2017.1335312.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.aggressive_filtering!-Union{Tuple{Q}, Tuple{S}, Tuple{R}, Tuple{GlobalOptimizer{R, S, Q}, NodeBB}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.aggressive_filtering!","text":"aggressive_filtering!(\n    m::GlobalOptimizer{R, S, Q<:ExtensionType},\n    n::NodeBB\n) -> Bool\n\n\nExcludes OBBT on variable indices after a search in a filtering direction.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.bool_indx_diff!-Tuple{Vector{Bool}, Vector{Bool}, Vector{Bool}}-dev-api_functions","page":"Functions","title":"EAGO.bool_indx_diff!","text":"bool_indx_diff!(\n    z::Vector{Bool},\n    x::Vector{Bool},\n    y::Vector{Bool}\n) -> Vector{Bool}\n\n\nUtility function used to set vector of booleans z to x & ~y. Avoids the generation of conversion of the BitArray created by broadcasting logical operators.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.bound_objective-Tuple{GlobalOptimizer, EAGO.BufferedNonlinearFunction}-dev-api_functions","page":"Functions","title":"EAGO.bound_objective","text":"bound_objective(::GlobalOptimizer, ::T)\nbound_objective(::ExtensionType, ::GlobalOptimizer)\n\nCompute a tuple representing the lower and upper bounds for an objective function. Note: bound_objective(::GlobalOptimizer) dispatches to  bound_objective(::ExtensionType, ::GlobalOptimizer).\n\nOptions for T:\n\nAffineFunctionIneq\nBufferedNonlinearFunction\nBufferedQuadraticIneq\nMOI.VariableIndex\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.branch_node!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.branch_node!","text":"branch_node!(t::ExtensionType, m::GlobalOptimizer)\n\n\nCreate two nodes from current_node and store them on the stack. Call select_branch_variable(t, m) and select_branch_point(t, m, k) to determine the variable that should be branched on and the point at which branching should occur, respectively.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.build_model-Union{Tuple{S}, Tuple{A}, Tuple{EAGO.DefaultExt, A, S, SIPProblem}} where {A<:AbstractSIPAlgo, S<:AbstractSubproblemType}-dev-api_functions","page":"Functions","title":"EAGO.build_model","text":"build_model\n\nCreate the model and variables used with extension t::EAGO.ExtensionType in algorithm a::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command build_model(t::ExtensionType, a::AbstractSIPAlgo, s::AbstractSubproblemType, p::SIPProblem).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.check_set_affine_nl!-Union{Tuple{Q}, Tuple{T}, Tuple{N}, Tuple{S}, Tuple{R}, Tuple{V}, Tuple{GlobalOptimizer{R, S, Q}, EAGO.BufferedNonlinearFunction{V, N, T}, Bool, Bool}} where {V, R, S, N, T<:RelaxTag, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.check_set_affine_nl!","text":"check_set_affine_nl!(\n    m::GlobalOptimizer{R, S, Q<:ExtensionType},\n    f::EAGO.BufferedNonlinearFunction{V, N, T<:RelaxTag},\n    finite_cut::Bool,\n    check_safe::Bool\n) -> Bool\n\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.convergence_check-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.convergence_check","text":"convergence_check(\n    t::ExtensionType,\n    m::GlobalOptimizer\n) -> Bool\n\n\nCheck for problem convergence.\n\nBy default, check if the lower and upper bounds have converged to within absolute and/or relative tolerances.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.create_buffer_dict-Tuple{MathOptInterface.ScalarQuadraticFunction{Float64}}-dev-api_functions","page":"Functions","title":"EAGO.create_buffer_dict","text":"create_buffer_dict(\n    func::MathOptInterface.ScalarQuadraticFunction{Float64}\n) -> Dict{Int64, Float64}\n\n\nCreate a buffer dictionary from a ScalarQuadraticFunction.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.cut-Union{Tuple{T}, Tuple{N}, Tuple{MC{N, T}, MC{N, T}, EAGO.VariableValues, Float64, Vector{Int64}, Bool, Bool}} where {N, T<:RelaxTag}-dev-api_functions","page":"Functions","title":"EAGO.cut","text":"cut\n\nIntersects the new set valued operator with the prior and performs affine bound tightening\n\nFirst forward pass: post should be set by user option, is_intersect should be false so that the tape overwrites existing values, and the interval_intersect flag could be set to either value.\nForward CP pass (assumes same reference point): post should be set by user option, is_intersect should be true so that the tape intersects with  existing values, and the interval_intersect flag should be false.\nForward CP pass (assumes same reference point): post should be set by user option, is_intersect should be true so that the tape intersects with existing values, and the interval_intersect flag should be false.\nSubsequent forward passes at new points: postshould be set by user option,isintersectshould be true so that the tape intersects with existing values, and theintervalintersectflag should betrue` as predetermined interval bounds are valid but  the prior values may correspond to different points of evaluation.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.cut_condition-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.cut_condition","text":"cut_condition(t::ExtensionType, m::GlobalOptimizer) -> Bool\n\n\nReturns true if a cut should be added and computes a new reference point to add the cut at. By default, checks that cut_max_iterations are not exceeded and that the  improvement in the objective value associated with the previous cut is greater than both an absolute tolerance cut_ϵ_abs and a relative tolerance cut_ϵ_rel. Returns false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.default_upper_heuristic-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.default_upper_heuristic","text":"default_upper_heuristic(m::GlobalOptimizer) -> Bool\n\n\nDefault check to see if the upper bounding problem should be run. By default, The upper bounding problem is run on every node up to depth upper_bounding_depth and is triggered with a probability of 0.5^(depth - upper_bounding_depth) afterwards for continuous problems. For integral problems, the upper_bounding_depth approach is used as well as running on every node up to depth  upper_bounding_depth + cont_depth with another trigger of probability 0.5^(depth - upper_bounding_depth - cont_depth).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.diam-Union{Tuple{VariableInfo{T}}, Tuple{T}} where T<:AbstractFloat-dev-api_functions","page":"Functions","title":"EAGO.diam","text":"Return the diameter of a variable (upper bound - lower bound).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.eliminate_fixed_variables!-dev-api_functions","page":"Functions","title":"EAGO.eliminate_fixed_variables!","text":"eliminate_fixed_variables!(::T, ::Vector{VariableInfo})\n\nEliminate fixed variables by rearrangment or restructuring of the AbstractEAGOConstraint.\n\nOptions for T (all are subtypes of AbstractEAGOConstraint):\n\nAffineFunctionEq\nAffineFunctionIneq\nBufferedQuadraticIneq\nBufferedNonlinearFunction{N,T} where {N, T<:RelaxTag}\nNonlinearExpression{V,N,T} where {V, N, T<:RelaxTag}\n\n\n\n\n\n","category":"function"},{"location":"dev/api_functions/#EAGO.f_init!-Tuple{AbstractCacheAttribute, AbstractDirectedGraph, AbstractCache}-dev-api_functions","page":"Functions","title":"EAGO.f_init!","text":"Initializes information in cache c for each node in g that may be used in a forward-pass of attribute t. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.fathom!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.fathom!","text":"fathom!(t::ExtensionType, m::GlobalOptimizer)\n\n\nRemove nodes from the stack. By default, delete nodes from the stack if their lower bounds are greater than the current global upper bound.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.fbbt!-dev-api_functions","page":"Functions","title":"EAGO.fbbt!","text":"fbbt!(m::GlobalOptimizer, f::T)\n\nPerforms feasibility-based bound tightening on a back-end constraint and returns true if it is feasible or false if it is infeasible.\n\nOptions for T (all are subtypes of AbstractEAGOConstraint):\n\nAffineFunctionIneq\nAffineFunctionEq\n\n\n\n\n\n","category":"function"},{"location":"dev/api_functions/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Constant, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a constant v at index k in  cache c associated with graph g using information at index k. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Expression, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a expression v at index k in  cache c associated with graph g using information taken from the children of k. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Parameter, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a parameter v at index k in  cache c associated with graph g using information at index k. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Subexpression, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a subexpression v at index k in  cache c associated with graph g using information taken from the children of k. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.fprop!-Tuple{AbstractCacheAttribute, Variable, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.fprop!","text":"Populates information associated with attribute t for a variable v at index k in  cache c associated with graph g using information at index k. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.get_sip_optimizer-Union{Tuple{A}, Tuple{ExtensionType, A, AbstractSubproblemType}} where A<:AbstractSIPAlgo-dev-api_functions","page":"Functions","title":"EAGO.get_sip_optimizer","text":"get_sip_optimizer\n\nSpecifices the optimizer to be used in extension t::EAGO.ExtensionType with algorithm alg::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command get_sip_optimizer(t::ExtensionType, alg::AbstractSIPAlgo, s::AbstractSubproblemType).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.global_solve!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.global_solve!","text":"global_solve!(m::GlobalOptimizer)\n\n\nSolves the branch-and-bound problem with the input EAGO.GlobalOptimizer object.\n\nPseudocode description of the algorithm, as implemented here:\n\n-I) Prepare optimizers and stack for branch-and-bound\n\n-II) While no reason to terminate the algorithm has occurred:\n\n–-II.A) Fathom nodes from the stack\n\n–-II.B) Select the new \"current node\" from the stack\n\n–-II.C) Perform preprocessing on current node\n\n–-II.D) If preprocessing result is feasible:\n\n––-II.D.1) Solve lower problem for current node\n\n––-II.D.2) If lower problem result is feasible and lower/upper bounds have not converged:\n\n–––-II.D.2.a) Solve upper problem for current node\n\n–––-II.D.2.b) Update the global upper bound if necessary\n\n–––-II.D.2.c) Perform postprocessing\n\n–––-II.D.2.d) If postprocessing result is feasible:\n\n––––-II.D.2.d.α) Branch and add the nodes back to the stack\n\n–-II.E) Update the global lower bound if necessary\n\n–-II.F) Update log information\n\n-III) Set termination and result statuses\n\n-IV) Print solution\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.initial_parse!-Union{Tuple{Optimizer{R, S, T}}, Tuple{T}, Tuple{S}, Tuple{R}} where {R, S, T}-dev-api_functions","page":"Functions","title":"EAGO.initial_parse!","text":"initial_parse!(m::Optimizer{R, S, T})\n\n\nTranslate the input problem to the working problem. Any checks or optional manipulation are left to the presolve stage.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.initialize!-Tuple{AbstractCache, AbstractDirectedGraph}-dev-api_functions","page":"Functions","title":"EAGO.initialize!","text":"initialize!(_::AbstractCache, _::AbstractDirectedGraph)\n\n\nFunction used to initialize the storage cache d::AbstractCache  for a given type of directed acyclic graph g::AbstractDirectedGraph.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.initialize_stack!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.initialize_stack!","text":"initialize_stack!(t::ExtensionType, m::GlobalOptimizer)\n\n\nPrepare the stack for the branch-and-bound routine. By default, create an initial node with the variable bounds as box constraints and add it to the stack.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.interval_bound-dev-api_functions","page":"Functions","title":"EAGO.interval_bound","text":"interval_bound(::GlobalOptimizer, ::T)\n\nCompute a tuple representing the lower and upper interval bounds for an AbstractEAGOConstraint representing an equality constraint.\n\nOptions for T (all are subtypes of AbstractEAGOConstraint):\n\nAffineFunctionEq\nAffineFunctionIneq\nBufferedQuadraticEq\nBufferedQuadraticIneq\nBufferedNonlinearFunction{V,N,T} where {V,N,T}\n\n\n\n\n\n","category":"function"},{"location":"dev/api_functions/#EAGO.interval_objective_bound!-dev-api_functions","page":"Functions","title":"EAGO.interval_objective_bound!","text":"\n\n\n\n","category":"function"},{"location":"dev/api_functions/#EAGO.is_feasible-Tuple{GlobalOptimizer, Union{EAGO.AffineFunctionIneq, EAGO.BufferedQuadraticIneq}}-dev-api_functions","page":"Functions","title":"EAGO.is_feasible","text":"is_feasible(::GlobalOptimizer, ::T)\n\nCheck if a given bound is feasible.\n\nOptions for T (all are subtypes of AbstractEAGOConstraint):\n\nAffineFunctionIneq\nAffineFunctionEq\nBufferedQuadraticIneq\nBufferedQuadraticEq\nBufferedNonlinearFunction{V,N,T}\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.is_integer_feasible_local-Tuple{GlobalOptimizer, Any}-dev-api_functions","page":"Functions","title":"EAGO.is_integer_feasible_local","text":"is_integer_feasible_local(m::GlobalOptimizer, d) -> Bool\n\n\nChecks that the solution of a local solve is integer feasible to within the tolerances specified by integer_abs_tol and integer_rel_tol.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.is_integer_feasible_relaxed-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.is_integer_feasible_relaxed","text":"is_integer_feasible_relaxed(m::GlobalOptimizer) -> Bool\n\n\nCheck that the solution of the lower (relaxed problem) is integer feasible to within tolerances specified by the parameters: integer_abs_tol (absolute tolerance) and integer_rel_tol (relative tolerance).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.is_integer_subproblem-Tuple{Any}-dev-api_functions","page":"Functions","title":"EAGO.is_integer_subproblem","text":"is_integer_subproblem(m)\n\n\nReturns true that the subproblem at the current node n has participating integer variables that have not been fixed to constant valued as the branch-and-bound algorithm progresses. Returns false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.is_safe_cut!-Tuple{GlobalOptimizer, MathOptInterface.ScalarAffineFunction{Float64}}-dev-api_functions","page":"Functions","title":"EAGO.is_safe_cut!","text":"is_safe_cut!(\n    m::GlobalOptimizer,\n    f::MathOptInterface.ScalarAffineFunction{Float64}\n) -> Bool\n\n\nApplies the safe cut checks detailed in Khajavirad, 2018 [Khajavirad, Aida, and Nikolaos V. Sahinidis. \"A hybrid LP/NLP paradigm for global optimization relaxations.\" Mathematical Programming Computation 10.3 (2018): 383-421] to ensure that only numerically safe affine relaxations are added. Checks that:\n\n|b| <= safe b, \nsafe_l <= abs(ai) <= safe u, and \nsafe_l <= abs(ai/aj) <= safe_u.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.label_branch_variables!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.label_branch_variables!","text":"label_branch_variables!(m::GlobalOptimizer)\n\n\nDetect any variables participating in nonconvex terms and populate the _branch_variables storage array.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.label_fixed_variables!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.label_fixed_variables!","text":"label_fixed_variables!(m::GlobalOptimizer) -> Vector{Bool}\n\n\nDetect any variables set to a fixed value by equality or inequality constraints and populate the _fixed_variable storage array.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.load_fbbt_buffer!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.load_fbbt_buffer!","text":"load_fbbt_buffer!(m::GlobalOptimizer)\n\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.load_relaxed_problem!-Union{Tuple{GlobalOptimizer{R, S, Q}}, Tuple{Q}, Tuple{S}, Tuple{R}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.load_relaxed_problem!","text":"load_relaxed_problem!(\n    m::GlobalOptimizer{R, S, Q<:ExtensionType}\n)\n\n\nLoad variables, linear constraints, and empty storage space for the first NLP and quadratic cut into the relaxed optimizer.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.local_problem_status-Tuple{MathOptInterface.TerminationStatusCode, MathOptInterface.ResultStatusCode}-dev-api_functions","page":"Functions","title":"EAGO.local_problem_status","text":"local_problem_status(t, r)\n\n\nTakes an MOI.TerminationStatusCode and a MOI.ResultStatusCode and returns true if this corresponds to a solution that is proven to be feasible. Returns false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.log_iteration!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.log_iteration!","text":"log_iteration!(m::GlobalOptimizer)\n\n\nIf log_on is true, the global_lower_bound, global_upper_bound, run_time, and node_count are stored every log_interval. If log_subproblem_info then the lower bound, feasibility and run times of the subproblems are logged every log_interval.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.lower_interval_bound-dev-api_functions","page":"Functions","title":"EAGO.lower_interval_bound","text":"lower_interval_bound(::GlobalOptimizer, ::T)\n\nCompute the lower interval bound for an AbstractEAGOConstraint representing an inequality constraint.\n\nOptions for T (all are subtypes of AbstractEAGOConstraint):\n\nAffineFunctionIneq\nBufferedQuadraticIneq\nBufferedSOC\nBufferedNonlinearFunction{V,N,T} where {V,N,T}\n\n\n\n\n\n","category":"function"},{"location":"dev/api_functions/#EAGO.lower_problem!-Union{Tuple{Q}, Tuple{S}, Tuple{R}, Tuple{ExtensionType, GlobalOptimizer{R, S, Q}}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.lower_problem!","text":"lower_problem!(\n    t::ExtensionType,\n    m::GlobalOptimizer{R, S, Q<:ExtensionType}\n)\n\n\nConstructs a relaxation of the MINLP on node y and solves it using the default EAGO  relaxation scheme. By default, EAGO applies Kelley's algorithm (from Kelley Jr., J.E.:  The cutting-plane method for solving convex programs. J. Soc. Ind. Appl. Math. 8(4),  703 to 712 (1960)) while cut_condition(m) returns true then activates the integrality constraints of the relaxed problems and solves the resulting MILP relaxation. results are stored to the _lower_solution, _lower_termination_status, _lower_primal_status, _lower_dual_status, _lower_objective_value, and _lower_feasibility. Further, lower and upper variable duals are stored _lower_lvd and _lower_uvd, respectively, for use in duality based bound tightening. If relaxation-based bounds are weaker or cutting-planes  are numerically poorly ill-posed, then interval bounds are used instead. If the problem is dual feasible but the primal status is ambiguous the dual objective value is used for the  lower bound to avoid numerical issues.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.mc_type-Union{Tuple{EAGO.RelaxCache{V, N, T}}, Tuple{T}, Tuple{N}, Tuple{V}} where {V, N, T<:RelaxTag}-dev-api_functions","page":"Functions","title":"EAGO.mc_type","text":"mc_type(::RelaxCache{V, N, T} where {V, N, T<:RelaxTag}\nmc_type(::NonlinearExpression{V, N, T} where {V, N, T<:RelaxTag}\nmc_type(::BufferedNonlinearFunction{V, N, T} where {V, N, T<:RelaxTag}\n\nReturns a McCormick structure of type MC{N, T<:RelaxTag}.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.mid-Union{Tuple{VariableInfo{T}}, Tuple{T}} where T<:AbstractFloat-dev-api_functions","page":"Functions","title":"EAGO.mid","text":"Return the midpoint of a variable (0.5*(upper bound + lower bound)).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.node_selection!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.node_selection!","text":"node_selection!(t::ExtensionType, m::GlobalOptimizer)\n\n\nSelect the next node in the stack to evaluate. By default, perform best-first  node selection (select the node with the lowest lower bound in the stack).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.obbt!-Union{Tuple{GlobalOptimizer{R, S, Q}}, Tuple{Q}, Tuple{S}, Tuple{R}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.obbt!","text":"obbt!(m::GlobalOptimizer{R, S, Q<:ExtensionType}) -> Bool\n\n\nPerforms OBBT with filtering and greedy ordering as detailed in: Gleixner, A.M., Berthold, T., Müller, B. et al. J Glob Optim (2017) 67: 731. https://doi.org/10.1007/s10898-016-0450-4\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.objective_cut!-Tuple{GlobalOptimizer, Bool}-dev-api_functions","page":"Functions","title":"EAGO.objective_cut!","text":"objective_cut!\n\nAdd linear objective cut constraint to the m._subsolvers.relaxed_optimizer.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.optimize_hook!-Tuple{ExtensionType, Optimizer}-dev-api_functions","page":"Functions","title":"EAGO.optimize_hook!","text":"optimize_hook!(t::ExtensionType, m::Optimizer)\n\nProvide a hook for extensions to EAGO. \n\nThe user-defined extension of optimize_hook! is used in EAGO's overloading of MOI.optimize! (see EAGO.jl/src/eago_optimizer/optimize/optimize.jl). Without the optimize_hook! specified, EAGO will run initial_parse!, parse_classify_problem!, and then optimize! using the parsed problem type. The user-specified optimize_hook!  should thus take the new extension and Optimizer as inputs and will execute when the  user writes optimize!(model).\n\nExample\n\nHere, optimize_hook! is used to bypass EAGO's problem parsing and treat every problem using its branch-and-bound routine. This is done in this example by telling EAGO to treat the problem as a mixed integer nonconvex problem, which normally dispatches to branch-and-bound.\n\nstruct MyNewExtension <: EAGO.ExtensionType end\nimport EAGO: optimize_hook!\nfunction EAGO.optimize_hook!(t::MyNewExtension, m::Optimizer)\n    initial_parse!(m)\n    optimize!(EAGO.MINCVX(), m)\nend\n\nThe same functionality could be accomplished by setting the EAGOParameter field force_global_solve to be true.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.parse_classify_problem!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.parse_classify_problem!","text":"parse_classify_problem!(m::GlobalOptimizer)\n\nInterprets the type/number of constraints and the type of objective function to infer a problem type. Current possible types include:\n\nLP: Linear program; sent to optimize_lp.jl\n'MILP: Mixed integer linear program; sent tooptimize_lp.jl`\nSOCP: Second-order cone program; sent to optimize_conic.jl\nMINCVX: Mixed-integer nonconvex; sent to optimize_nonconvex.jl\n\nIf the force_global_solve parameter is set to true, parse_classify_problem! will set the problem type to MINCVX to pass the problem to optimize_nonconvex.jl.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.parse_global!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.parse_global!","text":"Basic parsing for global solutions (no extensive manipulation). By default, does nothing.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.postprocess!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.postprocess!","text":"postprocess!(t::ExtensionType, m::GlobalOptimizer)\n\n\nDefault postprocess perfoms duality-based bound tightening (Tawarmalani, M.,  Sahinidis, N.V.: Global optimization of mixed-integer nonlinear programs:  a theoretical and computational study. Math. Progr. 99, 563–591 (2004).) up to an iteration limit set by dbbt_depth.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.preprocess!-Union{Tuple{Q}, Tuple{S}, Tuple{R}, Tuple{ExtensionType, GlobalOptimizer{R, S, Q}}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.preprocess!","text":"preprocess!(\n    t::ExtensionType,\n    m::GlobalOptimizer{R, S, Q<:ExtensionType}\n)\n\n\nRuns contractor methods prior to solving lower bounding problem. By default linear and quadratic  contractor methods followed by interval constraint propagation then optimization-based bound  tightening for a specified number of iterations while the subproblem at current node n has  not been proven infeasible.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.presolve_global!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.presolve_global!","text":"presolve_global!(t::ExtensionType, m::GlobalOptimizer)\n\n\nPerform any necessary work prior to running branch-and-bound. \n\nSet subsolver configs using values in EAGOParameters;\nLoad variables, linear constraints, and empty storage space into the relaxed optimizer;\nPrepare the stack for the start of branch-and-bound;\nFill fields of the GlobalOptimizer with zeros of the proper dimensions;\nPass necessary flags from the GlobalOptimizer to the working problem.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.print_iteration!-Tuple{GlobalOptimizer, Bool}-dev-api_functions","page":"Functions","title":"EAGO.print_iteration!","text":"print_iteration!\n\nPrint status information based on iteration count. The header print frequency is based on the header_iterations setting, and the data print frequency is based on the output_iterations setting.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.print_node!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.print_node!","text":"print_node!\n\nPrint information about the current node. Includes node ID, lower bound, upper bound, and interval box.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.print_preamble!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.print_preamble!","text":"print_preamble!\n\nPrint noteworthy information prior to running branch-and-bound. Currently prints a note about flipping max(f) to -min(-f) internally, if the input is a  maximization problem and verbosity >= 3.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.print_results!-Tuple{GlobalOptimizer, Bool}-dev-api_functions","page":"Functions","title":"EAGO.print_results!","text":"print_results!(m::GlobalOptimizer, lower_flag::Bool)\n\n\nPrint the results of a single (lower or upper) bounding problem. lower_flag=true prints information for the lower problem, lower_flag=false prints information for the upper problem.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.print_solution!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.print_solution!","text":"print_solution!\n\nPrint solution information for the B&B problem. Display node with the best solution, solution value, solution, and time spent solving subproblems. This print occurs following termination of the B&B algorithm.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.r_init!-Tuple{AbstractCacheAttribute, AbstractDirectedGraph, AbstractCache}-dev-api_functions","page":"Functions","title":"EAGO.r_init!","text":"Initializes information in cache c for each node in g that may be used in a reverse-pass of attribute t. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.reform_epigraph_min!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.reform_epigraph_min!","text":"reform_epigraph_min!(m::GlobalOptimizer)\n\n\nPerform an epigraph reformulation assuming the working_problem is a minimization problem.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rel_diam-Tuple{GlobalOptimizer, Int64}-dev-api_functions","page":"Functions","title":"EAGO.rel_diam","text":"rel_diam(m::GlobalOptimizer, i::Int64) -> Float64\n\n\nReturn the relative diameter of a variable. In the case of diam(X)=Inf, rel_diam returns 0.0 to prevent \"branching\" on this variable endlessly.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.relax!-Tuple{GlobalOptimizer, EAGO.BufferedQuadraticEq, Int64, Bool}-dev-api_functions","page":"Functions","title":"EAGO.relax!","text":"relax!(\n    m::GlobalOptimizer,\n    f::EAGO.BufferedQuadraticEq,\n    i::Int64,\n    check_safe::Bool\n) -> Bool\n\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.relax!-Tuple{GlobalOptimizer, EAGO.BufferedQuadraticIneq, Int64, Bool}-dev-api_functions","page":"Functions","title":"EAGO.relax!","text":"relax!(\n    m::GlobalOptimizer,\n    f::EAGO.BufferedQuadraticIneq,\n    k::Int64,\n    check_safe::Bool\n) -> Bool\n\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.relax!-Union{Tuple{Q}, Tuple{T}, Tuple{N}, Tuple{S}, Tuple{R}, Tuple{V}, Tuple{GlobalOptimizer{R, S, Q}, EAGO.BufferedNonlinearFunction{V, N, T}, Int64, Bool}} where {V, R, S, N, T<:RelaxTag, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.relax!","text":"relax!(\n    m::GlobalOptimizer{R, S, Q<:ExtensionType},\n    f::EAGO.BufferedNonlinearFunction{V, N, T<:RelaxTag},\n    k::Int64,\n    check_safe::Bool\n) -> Tuple{Bool, Bool}\n\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.relax!-dev-api_functions","page":"Functions","title":"EAGO.relax!","text":"relax!\n\nRelax the constraint by adding an affine constraint to the model.\n\n\n\n\n\n","category":"function"},{"location":"dev/api_functions/#EAGO.relax_all_constraints!-Tuple{ExtensionType, GlobalOptimizer, Int64}-dev-api_functions","page":"Functions","title":"EAGO.relax_all_constraints!","text":"relax_all_constraints!(\n    t::ExtensionType,\n    m::GlobalOptimizer,\n    k::Int64\n) -> Tuple{Bool, Bool}\n\n\nA routine that adds relaxations for all nonlinear constraints and quadratic constraints corresponding to the current node to the relaxed problem. This adds an objective cut (if specified by objective_cut_on) and then sets the _new_eval_constraint flag to false indicating that an initial evaluation of the constraints has occurred. If the objective_cut_on flag is true then the _new_eval_objective flag is also set to false indicating that the objective expression was evaluated.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.relaxed_problem_status-Tuple{MathOptInterface.TerminationStatusCode, MathOptInterface.ResultStatusCode, MathOptInterface.ResultStatusCode}-dev-api_functions","page":"Functions","title":"EAGO.relaxed_problem_status","text":"relaxed_problem_status(t, p, d)\n\n\nTake an MOI.TerminationStatusCode and two MOI.ResultStatusCodes (one each for the primal and dual status) and return a RelaxResultStatus. Returns RRS_OPTIMAL if the codes prove that the subproblem solution was solved to global optimality. Returns RRS_INFEASIBLE if the codes prove that the subproblem solution is infeasible. Returns RRS_DUAL_FEASIBLE if subproblem solution is not optimal and not proven infeasible, but the dual status is MOI.FEASIBLE_POINT. Returns RRS_INVALID otherwise.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.repeat_check-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.repeat_check","text":"repeat_check(t::ExtensionType, m::GlobalOptimizer) -> Bool\n\n\nCheck to see if current node should be reprocessed. Without any custom extension, return false by default.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Constant, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a constant v at index k in  cache c  associated with graph g using information at index k taken from the parents of k.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Expression, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a expressions v at index k in  cache c  associated with graph g using information at index k taken from the parents of k. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Parameter, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a parameters v at index k in  cache c  associated with graph g using information at index k taken from the parents of k. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Subexpression, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a subexpressions v at index k in  cache c  associated with graph g using information at index k taken from the parents of k. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop!-Tuple{AbstractCacheAttribute, Variable, AbstractDirectedGraph, AbstractCache, Int64}-dev-api_functions","page":"Functions","title":"EAGO.rprop!","text":"Populates information associated with attribute t for a variable v at index k in  cache c  associated with graph g using information at index k taken from the parents of k. \n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop!-Union{Tuple{T}, Tuple{EAGO.RelaxInterval, Val{EAGO.MULT}, EAGO.DirectedTree, EAGO.IntervalCache{T}, Int64}} where T<:Real-dev-api_functions","page":"Functions","title":"EAGO.rprop!","text":"rprop!\n\nUpdates storage tapes with reverse evalution of node representing n = *(x,y,z...) which updates x, y, z and so on.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop!-Union{Tuple{T}, Tuple{EAGO.RelaxInterval, Val{EAGO.PLUS}, EAGO.DirectedTree, EAGO.IntervalCache{T}, Int64}} where T<:Real-dev-api_functions","page":"Functions","title":"EAGO.rprop!","text":"rprop!\n\nUpdates storage tapes with reverse evalution of node representing n = +(x,y,z...) which updates x, y, z and so on.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop_2!-Union{Tuple{T}, Tuple{N}, Tuple{V}, Tuple{EAGO.Relax, Val{EAGO.MULT}, EAGO.DirectedTree, EAGO.RelaxCache{V, N, T}, Int64}} where {V, N, T<:RelaxTag}-dev-api_functions","page":"Functions","title":"EAGO.rprop_2!","text":"rprop_2!\n\nUpdates storage tapes with reverse evalution of node representing n = x * y which updates x and y.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop_2!-Union{Tuple{T}, Tuple{N}, Tuple{V}, Tuple{EAGO.Relax, Val{EAGO.PLUS}, EAGO.DirectedTree, EAGO.RelaxCache{V, N, T}, Any}} where {V, N, T<:RelaxTag}-dev-api_functions","page":"Functions","title":"EAGO.rprop_2!","text":"rprop_2!\n\nUpdates storage tapes with reverse evalution of node representing n = x + y which updates x and y.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop_n!-Union{Tuple{T}, Tuple{N}, Tuple{V}, Tuple{EAGO.Relax, Val{EAGO.MULT}, EAGO.DirectedTree, EAGO.RelaxCache{V, N, T}, Int64}} where {V, N, T<:RelaxTag}-dev-api_functions","page":"Functions","title":"EAGO.rprop_n!","text":"rprop_n!\n\nUpdates storage tapes with reverse evalution of node representing n = *(x,y,z...) which updates x, y, z and so on.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.rprop_n!-Union{Tuple{T}, Tuple{N}, Tuple{V}, Tuple{EAGO.Relax, Val{EAGO.PLUS}, EAGO.DirectedTree, EAGO.RelaxCache{V, N, T}, Int64}} where {V, N, T<:RelaxTag}-dev-api_functions","page":"Functions","title":"EAGO.rprop_n!","text":"rprop_n!\n\nUpdates storage tapes with reverse evalution of node representing n = +(x,y,z...) which updates x, y, z and so on.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.same_box-Tuple{NodeBB, NodeBB, Float64}-dev-api_functions","page":"Functions","title":"EAGO.same_box","text":"same_box(x::NodeBB, y::NodeBB, r::Float64) -> Bool\n\n\nCheck that node x and y have equal domains within an absolute tolerance of r.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.select_branch_point-Tuple{ExtensionType, GlobalOptimizer, Any}-dev-api_functions","page":"Functions","title":"EAGO.select_branch_point","text":"select_branch_point(\n    t::ExtensionType,\n    m::GlobalOptimizer,\n    i\n) -> Float64\n\n\nSelect a point xb within the domain of the ith branching variable. By default, this point is a convex combination of the solution to the relaxation and the midpoint of the node (branch_cvx_factor*xmid + (1-branch_cvx_factor)*xsol). If the solution lies within branch_offset of a bound, then the branch point is moved to a distance of branch_offset from that bound.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.select_branch_variable-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.select_branch_variable","text":"select_branch_variable(\n    t::ExtensionType,\n    m::GlobalOptimizer\n) -> Any\n\n\nChoose a variable to branch on. A maximum relative width branching rule is used by default.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.set_constraint_propagation_fbbt!-Union{Tuple{GlobalOptimizer{R, S, Q}}, Tuple{Q}, Tuple{S}, Tuple{R}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.set_constraint_propagation_fbbt!","text":"set_constraint_propagation_fbbt!(\n    m::GlobalOptimizer{R, S, Q<:ExtensionType}\n) -> Bool\n\n\nPerforms bound tightening based on forward/reverse interval and/or McCormick passes. This routine resets the current node with new interval bounds.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.set_default_config!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.set_default_config!","text":"set_default_config!\n\nConfigures subsolver tolerances based on tolerance parameters provided to EAGO (provided that a specialized subsolver configuration routine has been provided and m.user_solver_config = false).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.set_dual!-Union{Tuple{GlobalOptimizer{R, S, Q}}, Tuple{Q}, Tuple{S}, Tuple{R}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.set_dual!","text":"set_dual!(m)\n\n\nRetrieves the lower and upper duals for variable bounds from the relaxed_optimizer and sets the appropriate values in the _lower_lvd and _lower_uvd storage fields.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.set_first_relax_point!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.set_first_relax_point!","text":"set_first_relax_point!(m::GlobalOptimizer)\n\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.set_global_lower_bound!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.set_global_lower_bound!","text":"set_global_lower_bound!(m::GlobalOptimizer)\n\n\nIf the previous best-known global lower bound is lower than the lowest lower bound in the stack, set the global lower bound equal to the lowest lower bound in the stack.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.set_node!-Tuple{Evaluator, NodeBB}-dev-api_functions","page":"Functions","title":"EAGO.set_node!","text":"set_node!\n\nSets the current node in the Evaluator structure.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.set_reference_point!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.set_reference_point!","text":"set_reference_point!(m::GlobalOptimizer)\n\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.set_result_status!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.set_result_status!","text":"set_result_status!(m::GlobalOptimizer)\n\n\nConvert EAGO's ending status code into an MOI.ResultStatusCode.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.set_termination_status!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.set_termination_status!","text":"set_termination_status!(m::GlobalOptimizer)\n\n\nConvert EAGO's ending status code into an MOI.TerminationStatusCode.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.single_storage!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.single_storage!","text":"single_storage!(t::ExtensionType, m::GlobalOptimizer)\n\n\nStore the current node to the stack, without branching, after updating lower/upper bounds.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.sip_bnd!-Union{Tuple{S}, Tuple{A}, Tuple{ExtensionType, A, S, SIPSubResult, SIPResult, SIPProblem, SIPCallback}} where {A<:AbstractSIPAlgo, S<:AbstractSubproblemType}-dev-api_functions","page":"Functions","title":"EAGO.sip_bnd!","text":"sip_bnd!\n\nSolves the bounding problem for the ith-SIP used with extension t::EAGO.ExtensionType in algorithm a::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command sip_bnd!(t::ExtensionType, a::AbstractSIPAlgo, s::AbstractSubproblemType, ..., i, tol).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.sip_llp!-Union{Tuple{S}, Tuple{A}, Tuple{EAGO.DefaultExt, A, S, SIPResult, SIPSubResult, SIPProblem, SIPCallback, Int64}, Tuple{EAGO.DefaultExt, A, S, SIPResult, SIPSubResult, SIPProblem, SIPCallback, Int64, Float64}} where {A<:AbstractSIPAlgo, S<:AbstractSubproblemType}-dev-api_functions","page":"Functions","title":"EAGO.sip_llp!","text":"sip_llp!\n\nSolves the lower level problem for the ith-SIP used with extension t::EAGO.ExtensionType in algorithm a::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command  sip_llp!(t::ExtensionType, a::AbstractSIPAlgo, s::AbstractSubproblemType, ..., i, tol).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.sip_res!-Union{Tuple{A}, Tuple{ExtensionType, A, SIPSubResult, SIPResult, SIPProblem, SIPCallback}} where A<:AbstractSIPAlgo-dev-api_functions","page":"Functions","title":"EAGO.sip_res!","text":"sip_res!\n\nSolves the restriction problem for extension t::EAGO.ExtensionType in algorithm a::AbstractSIPAlgo in subproblem s::AbstractSubproblemType via the command sip_res!(t::ExtensionType, a::AbstractSIPAlgo, ...).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.sip_solve-Union{Tuple{T}, Tuple{T, Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Function, Vector}} where T<:AbstractSIPAlgo-dev-api_functions","page":"Functions","title":"EAGO.sip_solve","text":"sip_solve\n\nSolve an SIP with decision variable bounds x_l to x_u, uncertain variable bounds p_l to p_u, an objective function of f, and gSIP seminfiniite constraint(s).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.solve_local_nlp!-Union{Tuple{GlobalOptimizer{R, S, Q}}, Tuple{Q}, Tuple{S}, Tuple{R}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.solve_local_nlp!","text":"Constructs and solves the problem locally on node y updated the upper solution informaton in the optimizer.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.store_candidate_solution!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.store_candidate_solution!","text":"store_candidate_solution!(m::GlobalOptimizer)\n\n\nIf the most recent upper problem returned a feasible result, and the upper objective value is less than the previous best-known global upper bound, set the most recent upper problem result to be the new global upper bound. Update the _feasible_solution_found, _solution_node,  _global_upper_bound, and _continuous_solution fields of the GlobalOptimizer accordingly.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.stored_adjusted_upper_bound!-Tuple{GlobalOptimizer, Float64}-dev-api_functions","page":"Functions","title":"EAGO.stored_adjusted_upper_bound!","text":"stored_adjusted_upper_bound!(d, v)\n\n\nShifts the resulting local nlp objective value f* by (1.0 + relative_tolerance/100.0)*f* + absolute_tolerance/100.0. This assumes that the local solvers relative tolerance and absolute tolerance is significantly lower than the global tolerance (local problem is minimum).\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.termination_check-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.termination_check","text":"termination_check(m::GlobalOptimizer)\ntermination_check(t::ExtensionType, m::GlobalOptimizer) -> Bool\n\nCheck for termination of the branch-and-bound algorithm.\n\nIf only the GlobalOptimizer is given as an argument, termination_check dispatches to the other form using the ExtensionType given in the SubSolvers. If there is no user-defined extension, then by default, this will check for satisfaction of absolute or relative tolerances, solution infeasibility, and other specified limits. Returns  true if any conditions are met and branch-and-bound should end, and false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.trivial_filtering!-Union{Tuple{Q}, Tuple{S}, Tuple{R}, Tuple{GlobalOptimizer{R, S, Q}, NodeBB}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.trivial_filtering!","text":"trivial_filtering!(\n    m::GlobalOptimizer{R, S, Q<:ExtensionType},\n    n::NodeBB\n)\n\n\nExcludes OBBT on variable indices that are tight for the solution of the relaxation.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.unbounded_check!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.unbounded_check!","text":"unbounded_check!(m::GlobalOptimizer) -> Union{Nothing, Bool}\n\n\nCheck the optimization problem for unbounded branching variables, which would interfere with EAGO's branch-and-bound routine since there are no well-defined branching rules for cases where the interval bounds contain -Inf or Inf. If any branching variables are missing bounds, add the missing bound at +/- 1E6 and warn the user.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.unpack_fbbt_buffer!-Tuple{GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.unpack_fbbt_buffer!","text":"unpack_fbbt_buffer!(m::GlobalOptimizer)\n\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.unpack_global_solution!-Union{Tuple{Optimizer{R, S, Q}}, Tuple{Q}, Tuple{S}, Tuple{R}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.unpack_global_solution!","text":"unpack_global_solution!(\n    m::Optimizer{R, S, Q<:ExtensionType}\n)\n\n\nIf global optimization was performed, much of the work happened within the _global_optimizer::GlobalOptimizer. The unpack_global_solution! function extracts results from the GlobalOptimizer and puts them in the correct fields of the Optimizer.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.unsafe_check_fill!-Union{Tuple{T}, Tuple{Any, Vector{T}, T, Int64}} where T-dev-api_functions","page":"Functions","title":"EAGO.unsafe_check_fill!","text":"unsafe_check_fill!(f, y::Array{T, 1}, x, n::Int64)\n\n\nPerforms map!(f, y, x) in an unsafe manner if y[i] is true, else no-op. Assumes n == length(x) == length(y). About 2x faster for small arrays (n < 1000).\n\n[Unused]\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.update_relaxed_problem_box!-Union{Tuple{GlobalOptimizer{R, S, Q}}, Tuple{Q}, Tuple{S}, Tuple{R}} where {R, S, Q<:ExtensionType}-dev-api_functions","page":"Functions","title":"EAGO.update_relaxed_problem_box!","text":"update_relaxed_problem_box!(m)\n\n\nUpdate the relaxed constraint by setting the constraint set of v == x* , xL_i <= x_i, and x_i <= xU_i for each such constraint added to the relaxed optimizer. Resets integral valued constraints to either EqualTo or Interval  constraints.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.upper_problem!-Tuple{ExtensionType, GlobalOptimizer}-dev-api_functions","page":"Functions","title":"EAGO.upper_problem!","text":"upper_problem!(t::ExtensionType, m::GlobalOptimizer)\n\n\nDefault upper bounding problem which simply calls solve_local_nlp! to solve the NLP locally.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.variable_dbbt!-Tuple{NodeBB, Vector{Float64}, Vector{Float64}, Float64, Float64, Int64}-dev-api_functions","page":"Functions","title":"EAGO.variable_dbbt!","text":"variable_dbbt!(\n    n::NodeBB,\n    mult_lo::Vector{Float64},\n    mult_hi::Vector{Float64},\n    LBD::Float64,\n    UBD::Float64,\n    nx::Int64\n)\n\n\nTighten the bounds of the _current_node using the current global upper bound and the duality information obtained from the relaxation.\n\n\n\n\n\n","category":"method"},{"location":"dev/api_functions/#EAGO.variable_load_parse!-Union{Tuple{T}, Tuple{Optimizer, Type{MathOptInterface.VariableIndex}, Type{T}}} where T-dev-api_functions","page":"Functions","title":"EAGO.variable_load_parse!","text":"variable_load_parse!\n\nParse constraint information of a given constraint type to fill in related variable information.\n\n\n\n\n\n","category":"method"},{"location":"ref/#References","page":"References","title":"References","text":"","category":"section"},{"location":"ref/#Branch-and-Bound","page":"References","title":"Branch and Bound","text":"Floudas, CA (2013). Deterministic global optimization: theory, methods and applications. Vol. 37. Springer Science & Business Media.\nHorst, R, Tuy, H (2013). Global optimization: Deterministic approaches. Springer Science & Business Media.","category":"section"},{"location":"ref/#Parametric-Interval-Techniques","page":"References","title":"Parametric Interval Techniques","text":"Hansen ER, Walster GW (2004). Global Optimization Using Interval Analysis. Marcel Dekker, New York, second edition.\nKrawczyk R (1969). Newton-algorithmen zur bestimmung con nullstellen mit fehler-schranken. Computing, 4:187–201.\nKrawczyk R (1984). Interval iterations for including a set of solutions. Computing, 32:13–31.\nMiranda C (1940). Un’osservatione su un teorema di brower. Boll. Un. Mat. Ital., 3:5–7.\nNeumaier A (1990). Interval Methods for Systems of Equations. Cambridge University Press, Cambridge.\nMoore RE (1977). A test for existence of solutions to nonlinear systems. SIAM Journal on Numerical Analysis, 14(4):611–615.","category":"section"},{"location":"ref/#Domain-Reduction","page":"References","title":"Domain Reduction","text":"Benhamou F, & Older WJ (1997). Applying interval arithmetic to real, integer, and boolean constraints. The Journal of Logic Programming, 32, 1–24.\nCaprara A, & Locatelli M (2010). Global optimization problems and domain reduction strategies. Mathematical Programming, 125, 123–137.\nGleixner AM, Berthold T, Müller B, & Weltge S (2016). Three enhancements for optimization-based bound tightening. ZIB Report, 15–16.\nRyoo HS, & Sahinidis NV (1996). A branch-and-reduce approach to global optimization. Journal of Global Optimization, 8, 107–139.\nSchichl H, & Neumaier A (2005). Interval analysis on directed acyclic graphs for global optimization. Journal of Global Optimization, 33, 541–562.\nTawarmalani, M, & Sahinidis, NV (2005). A polyhedral branch-and-cut approach to global optimization. Mathematical Programming, 103, 225–249.\nVu, X, Schichl, H, & Sam-Haroud, D (2009). Interval propagation and search on directed acyclic graphs for numerical constraint solving. Journal of Global Optimization, 45, 499–531.","category":"section"},{"location":"ref/#Generalized-McCormick-Relaxations","page":"References","title":"Generalized McCormick Relaxations","text":"Chachuat, B (2014). MC++: a toolkit for bounding factorable functions, v1.0. Retrieved 2 July 2014 https://projects.coin-or.org/MCpp\nMitsos A, Chachuat B, and Barton PI. (2009). McCormick-based relaxations of algorithms. SIAM Journal on Optimization, 20(2):573–601.\nMcCormick, GP (1976).. Computability of global solutions to factorable nonconvex programs: Part I-Convex underestimating problems. Mathematical Programming, 10:147–175.\nMcCormick, GP (1983). Nonlinear programming: Theory, Algorithms, and Applications. Wiley, New York.\nScott JK,  Stuber MD, and Barton PI. (2011). Generalized McCormick relaxations. Journal of Global Optimization, 51(4):569–606.\nStuber MD, Scott JK, Barton PI (2015). Convex and concave relaxations of implicit functions. Optim. Methods Softw. 30(3), 424–460\nTsoukalas A and Mitsos A (2014). Multivariate McCormick Relaxations. Journal of Global Optimization, 59:633–662.\nKhan KA, Watson HAJ, Barton PI (2017). Differentiable McCormick relaxations. Journal of Global Optimization, 67(4):687-729.\nWechsung A, Scott JK, Watson HAJ, and Barton PI. (2015). Reverse propagation of McCormick relaxations. Journal of Global Optimization 63(1):1-36.","category":"section"},{"location":"ref/#Semi-Infinite-Programming","page":"References","title":"Semi-Infinite Programming","text":"Mitsos A (2009). Global optimization of semi-infinite programs via restriction of the right-hand side. Optimization, 60(10-11):1291-1308.\nStuber MD and Barton PI (2015). Semi-Infinite Optimization With Implicit Functions. Industrial & Engineering Chemistry Research, 54:307-317, 2015.","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: logo)","category":"section"},{"location":"#EAGO-Easy-Advanced-Global-Optimization-in-Julia","page":"Introduction","title":"EAGO - Easy Advanced Global Optimization in Julia","text":"A development environment for robust and global optimization in Julia.","category":"section"},{"location":"#Authors","page":"Introduction","title":"Authors","text":"Matthew Wilhelm, Department of Chemical and Biomolecular Engineering, University of Connecticut (UConn)\nCurrent Position: Alexion Pharmaceuticals\nRobert Gottlieb, Department of Chemical and Biomolecular Engineering, University of Connecticut (UConn)\nDimitri Alston, Department of Chemical and Biomolecular Engineering, University of Connecticut (UConn)\nMatthew Stuber, Pratt & Whitney Associate Professor in Advanced Systems Engineering, University of Connecticut (UConn)\n\nIf you would like to contribute, contact us.","category":"section"},{"location":"#Overview","page":"Introduction","title":"Overview","text":"EAGO is a global and robust optimization platform based on McCormick relaxations. It contains the first widely accessible global optimization routine based on generalized McCormick relaxations. With the exception of calls to local solvers and linear algebra routines, EAGO is written entirely in native Julia. The solver is flexibly arranged so the end user can easily customize low-level routines.","category":"section"},{"location":"#Installing-EAGO","page":"Introduction","title":"Installing EAGO","text":"EAGO is a registered Julia package and it can be installed using the Julia package manager. From the Julia REPL, type ] to enter the Package manager (Pkg) mode and run the following command:\n\npkg> add EAGO\n\nCurrently, EAGO is compatible with version 1.12 of JuMP. This allows a replication of some of the internal features shared by EAGO and JuMP's automatic differentiation scheme, e.g., generation of Wengert Tapes, passing evaluators between JuMP and EAGO, etc.\n\npkg> add JuMP\n\nEAGO v0.8.1 is the current tagged version and requires Julia 1.6+ for full functionality (however Julia 1.0+ versions support partial functionality). Use with version 1.8 is recommended as the majority of in-house testing has occurred using this version of Julia. The user is directed to the High-Performance Configuration for instructions on how to install a high performance version of EAGO (rather than the basic entirely open-source version). If any issues are encountered when loading EAGO (or when using it), please submit an issue using the GitHub issue tracker.","category":"section"},{"location":"#Examples","page":"Introduction","title":"Examples","text":"Several examples are provided within this documentation, but additional examples are provided in the form of Jupyter Notebooks at EAGO-notebooks which can be run using IJulia. To add IJulia, run the command:\n\npkg> add IJulia\n\nThen launch the Jupyter Notebook using the following command from the Julia terminal:\n\njulia> using IJulia; notebook()\n\nAnd then simply navigate to the example directory and run the example of most interest.","category":"section"},{"location":"optimizer/domain_reduction/#Domain-Reduction","page":"Domain Reduction","title":"Domain Reduction","text":"","category":"section"},{"location":"optimizer/domain_reduction/#Duality-Based-Bound-Tightening","page":"Domain Reduction","title":"Duality-Based Bound Tightening","text":"Variable bound tightening based on the duality multipliers are supported.","category":"section"},{"location":"optimizer/domain_reduction/#Special-Forms","page":"Domain Reduction","title":"Special Forms","text":"Bound tightening for linear forms, univariate quadratic forms, and bivariate quadratic forms are also supported.","category":"section"},{"location":"optimizer/domain_reduction/#Constraint-Propagation","page":"Domain Reduction","title":"Constraint Propagation","text":"EAGO contains a constraint propagation architecture that supported forward and reverse evaluation of set-valued functions on the directed acyclic graph. The interval contractor and reverse McCormick relaxation-based contractors are currently available.","category":"section"},{"location":"optimizer/domain_reduction/#Optimization-Based-Bound-Tightening","page":"Domain Reduction","title":"Optimization-Based Bound Tightening","text":"EAGO makes use of an optimization-based bound tightening scheme using filtering and greedy ordering as detailed in [1].","category":"section"},{"location":"optimizer/domain_reduction/#References","page":"Domain Reduction","title":"References","text":"Gleixner, A.M., Berthold, T., Müller, B. et al. J Glob Optim (2017) 67: 731. https://doi.org/10.1007/s10898-016-0450-4","category":"section"},{"location":"optimizer/domain_reduction/#EAGO.variable_dbbt!","page":"Domain Reduction","title":"EAGO.variable_dbbt!","text":"variable_dbbt!(\n    n::NodeBB,\n    mult_lo::Vector{Float64},\n    mult_hi::Vector{Float64},\n    LBD::Float64,\n    UBD::Float64,\n    nx::Int64\n)\n\n\nTighten the bounds of the _current_node using the current global upper bound and the duality information obtained from the relaxation.\n\n\n\n\n\n","category":"function"},{"location":"optimizer/domain_reduction/#EAGO.fbbt!","page":"Domain Reduction","title":"EAGO.fbbt!","text":"fbbt!(m::GlobalOptimizer, f::T)\n\nPerforms feasibility-based bound tightening on a back-end constraint and returns true if it is feasible or false if it is infeasible.\n\nOptions for T (all are subtypes of AbstractEAGOConstraint):\n\nAffineFunctionIneq\nAffineFunctionEq\n\n\n\n\n\n","category":"function"},{"location":"optimizer/domain_reduction/#EAGO.set_constraint_propagation_fbbt!","page":"Domain Reduction","title":"EAGO.set_constraint_propagation_fbbt!","text":"set_constraint_propagation_fbbt!(\n    m::GlobalOptimizer{R, S, Q<:ExtensionType}\n) -> Bool\n\n\nPerforms bound tightening based on forward/reverse interval and/or McCormick passes. This routine resets the current node with new interval bounds.\n\n\n\n\n\n","category":"function"},{"location":"optimizer/domain_reduction/#EAGO.obbt!","page":"Domain Reduction","title":"EAGO.obbt!","text":"obbt!(m::GlobalOptimizer{R, S, Q<:ExtensionType}) -> Bool\n\n\nPerforms OBBT with filtering and greedy ordering as detailed in: Gleixner, A.M., Berthold, T., Müller, B. et al. J Glob Optim (2017) 67: 731. https://doi.org/10.1007/s10898-016-0450-4\n\n\n\n\n\n","category":"function"},{"location":"optimizer/domain_reduction/#EAGO.trivial_filtering!-Union{Tuple{Q}, Tuple{S}, Tuple{R}, Tuple{GlobalOptimizer{R, S, Q}, NodeBB}} where {R, S, Q<:ExtensionType}","page":"Domain Reduction","title":"EAGO.trivial_filtering!","text":"trivial_filtering!(\n    m::GlobalOptimizer{R, S, Q<:ExtensionType},\n    n::NodeBB\n)\n\n\nExcludes OBBT on variable indices that are tight for the solution of the relaxation.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/domain_reduction/#EAGO.aggressive_filtering!-Union{Tuple{Q}, Tuple{S}, Tuple{R}, Tuple{GlobalOptimizer{R, S, Q}, NodeBB}} where {R, S, Q<:ExtensionType}","page":"Domain Reduction","title":"EAGO.aggressive_filtering!","text":"aggressive_filtering!(\n    m::GlobalOptimizer{R, S, Q<:ExtensionType},\n    n::NodeBB\n) -> Bool\n\n\nExcludes OBBT on variable indices after a search in a filtering direction.\n\n\n\n\n\n","category":"method"},{"location":"optimizer/domain_reduction/#EAGO.bool_indx_diff!-Tuple{Vector{Bool}, Vector{Bool}, Vector{Bool}}","page":"Domain Reduction","title":"EAGO.bool_indx_diff!","text":"bool_indx_diff!(\n    z::Vector{Bool},\n    x::Vector{Bool},\n    y::Vector{Bool}\n) -> Vector{Bool}\n\n\nUtility function used to set vector of booleans z to x & ~y. Avoids the generation of conversion of the BitArray created by broadcasting logical operators.\n\n\n\n\n\n","category":"method"}]
}
